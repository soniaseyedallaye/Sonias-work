{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4977266850932bfc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# BLU15 - Model CSI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import io\n",
    "import json\n",
    "import pickle\n",
    "import requests\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-20ab4cc706ece288",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Alright, let's go on with the BLU and have fun doing some exercises!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a39e9c915dc5fb6b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img src=\"media/show.jpg\" width=300/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-675e349794cfade8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As a reminder:\n",
    "\n",
    "In the learning unit we received a pretrained model and a new batch of data and analyzed whether the model performs well and what to do with it.\n",
    "\n",
    "In the end, we realized that there are some unexpected changes in the data distribution and we need to retrain the model.\n",
    "\n",
    "As the new dataset was pretty small, we have to concat the old data with the new one and train a new model on the combination of 2 datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b9f04330950f72d6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 1:\n",
    "\n",
    "- Read the .csv file with the original dataframe as **df_old.**\n",
    "\n",
    "- If you take a look on the **VehicleSearchedIndicator** column, you understand that this subset represents the searched cars only, so we can drop the **VehicleSearchedIndicator** column.\n",
    "\n",
    "- As the new dataset doesn't contain **InterventionDateTime** column, we also need to drop it from the old dataset.\n",
    "\n",
    "- Read new observations as **df_new**.\n",
    "\n",
    "- Combine both the dataframes and add a new column called **is_new** that is going to have all **False** values for the old data and all **True** values for the new observations.\n",
    "\n",
    "- Call the combined dataframe **df_combined**\n",
    "\n",
    "- Drop all **NaN** values\n",
    "\n",
    "- Apply lowercase to department names and intervention location names in the combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-04ea06e1af333be0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# df_old = ...\n",
    "# df_new = ...\n",
    "# df_combined = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8c0d93b76029e43b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert df_combined.shape == (78715, 14), 'combined dataframe shape is wrong'\n",
    "assert 'VehicleSearchedIndicator' not in df_combined.columns, 'Did you drop the VehicleSearchedIndicator column?'\n",
    "assert 'is_new' in df_combined.columns, 'Did you add is_new column?'\n",
    "assert sum(df_combined['is_new']) == 2000, 'is_new column has a wrong number of True values'\n",
    "assert all([name.islower() for name in df_combined['Department Name']]), 'Department name is not lowercased'\n",
    "assert all([name.islower() or not name.isalpha() for name in df_combined['InterventionLocationName']]), 'InterventionLocationName is not lowercased'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-63bf0204b0039261",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 2:\n",
    "\n",
    "**Split the created dataset on train and test parts in the following way:**\n",
    "\n",
    "- Firstly create train and test set. Call them **df_train** and **df_test**.\n",
    "> We'll need them in the future exercises. \n",
    "- Then, split **train** and **test** into **X_train**, **X_test**, **y_train** and **y_test**.\n",
    "- Test sets shape should be 25% of df_combined shape\n",
    "- Make sure to have 25% of new values in the test size.\n",
    "- Use random state 42 while splitting the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7f3b30be400bcb4f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-38a33c6dedc5abe8",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert df_train.shape == (59036, 14), 'df_train shape is wrong. Are you sure test size is 25%?'\n",
    "assert df_test.shape == (19679, 14), 'df_test shape is wrong. Are you sure test size is 25%?'\n",
    "assert X_train.shape == (59036, 13), 'X_train shape is wrong. Are you sure test size is 25%?'\n",
    "assert X_test.shape == (19679, 13), 'X_test shape is wrong. Are you sure test size is 25%?'\n",
    "assert y_train.shape == (59036,), 'X_train shape is wrong. Are you sure test size is 25%?'\n",
    "assert y_test.shape == (19679,), 'X_train shape is wrong. Are you sure test size is 25%?'\n",
    "assert sum(X_train['is_new']) == 1500, 'is_new column in Training set has a wrong number of True values. Make sure to have 25% of new values'\n",
    "assert sum(X_test['is_new']) == 500, 'is_new column in Test set has a wrong number of True values. Make sure to have 25% of new values'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5ce46b652d62760d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we need to retrain the model.\n",
    "\n",
    "If we simply load the pipeline and retrain it, it's going to ignore our new feature.\n",
    "\n",
    "So let's create the same pipeline as in the original notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = df_combined.columns.drop(['ContrabandIndicator', 'SubjectAge'])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    preprocessor,\n",
    "    LGBMClassifier(n_jobs=-1, random_state=42),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3:\n",
    "\n",
    "Now let's test how the model performs:\n",
    "\n",
    "- Make model binary predictions and save them to an array **preds**. \n",
    "- Make model probability predictions and save them to an array called **preds_proba**. Keep only True class probabilities (by default probability prediction returns you both False and True classes probabilities)\n",
    "- Create a variable called **precision** with the model precision score.\n",
    "- Create a variable called **recall** with the model recall score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9be477a1561648b5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_recall = 'a2cffa866c48b997372a62104161ba89e68fb439c418fc2559e2a32c44987ce8'\n",
    "hash_recall = hashlib.sha256(bytes(str(round(recall, 2)), encoding='utf8')).hexdigest()\n",
    "assert hash_recall == expected_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-134d5512471b46a5",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(preds) == 19679, 'Are you sure you made predictions for test set only?'\n",
    "assert len(preds_proba) == 19679, 'Are you sure you made predictions for test set only?'\n",
    "assert not isinstance(preds_proba[0], np.ndarray), 'Are you sure you kept only the True class predictions?'\n",
    "assert round(sum(preds_proba)) == 6563\n",
    "np.testing.assert_almost_equal(precision, 0.64966, decimal=2)\n",
    "np.testing.assert_almost_equal(recall, 0.546027, decimal=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-00ba0926557db298",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "## Exercise 4: \n",
    "\n",
    "It's already not bad, but let's now try to calculate the optimal threshold.\n",
    "\n",
    "By threshold I mean the minimal probability of a prediction that we're going to call \"True\". \n",
    "\n",
    "By default, any prediction with probability > 0.5 is called True, but we might find a better value. \n",
    "\n",
    "The metric is the same: our success rate (precision) needs to be at least 50%, and the recall should be as big as possible. \n",
    "\n",
    "Save the result to a variable called **threshold**. Round the result to 2 decimal points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9f436f48cd5a5f33",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# threshold = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-326014262a2ffeb9",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert round(threshold, 2) == threshold, 'Did you round the value?'\n",
    "ans_threshold = hashlib.sha256(bytes(str(threshold), encoding='utf8')).hexdigest()\n",
    "assert ans_threshold == \"6382e07f9de0c85293aee2a45b88c61c28589419682ecc2f8c097f750e861a24\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-189130f10b806acf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 5:\n",
    "\n",
    "- Now create a list of predictions. \n",
    "\n",
    "> All the values from the **preds_proba** list that have a value > threshold should be True. The rest should be False.\n",
    "\n",
    "> Save the result to a variable called **best_preds**\n",
    "\n",
    "- Calculate the precision and recall and save them to variables **precision** and **recall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-11c3a5f9bbcc11ff",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# best_preds = ...\n",
    "# precision = ...\n",
    "# recall = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1b53ef9739686af6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(precision, 0.50290256, decimal=2)\n",
    "np.testing.assert_almost_equal(recall, 0.84422789, decimal=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a38fa1224ab86e3c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 6:\n",
    "\n",
    "Now let's find out whether removing rare values is going to help. \n",
    "\n",
    "**Filter *df_train* (the one you created in the Exercise 2) the following way:** \n",
    "\n",
    "- Remove rows with **Department Name** that appear <= 50 times\n",
    "- Remove rows with **InterventionLocationName** that appear <= 50 times\n",
    "- Remove rows with **ReportingOfficerIdentificationID** that appear <= 30 times\n",
    "- Remove rows with **StatuteReason** that appear <= 10 times\n",
    "- Note: it's better to keep the original dataframe not touched. Create a copy of the original dataframe and save the results to a variable **train_filtered**\n",
    "\n",
    "> We have to filter the values after we split the dataset into training and test, because by filtering the test set we also affect the score. If we filtered everything besides the examples that are the easiest to predict, we'd have a super nice score, but in production we're going to expect both the filtered values and unfiltered ones. \n",
    "\n",
    "> We shouldn't worry about the fact, that some values in the test set will not be present in the training set, because the pipeline is simply going to ignore them.\n",
    "\n",
    "> (you might use the logic from the original model's notebook, but I suggest trying to implement it by yourself, it's a good exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b7b6cf4076907562",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# train_filtered = df_train.copy()\n",
    "# train_filtered = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-204c92ef82321cee",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert train_filtered.shape == (30502, 14), 'Make sure to filter rare values. Make sure to filter only train set.'\n",
    "assert 'middlebury' not in train_filtered['Department Name'], 'Did you filter department names?'\n",
    "assert 'hampton' not in train_filtered['InterventionLocationName'], 'Did you filter InterventionLocationName ?'\n",
    "assert 'DACYR048' not in train_filtered['ReportingOfficerIdentificationID'], 'Did you filter officer ids?'\n",
    "assert 'Stop Sign ' not in train_filtered['StatuteReason'], 'Did you filter statute reasons?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4bf528ed9d629b95",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 7:\n",
    "\n",
    "**Let's split *train_filtered* into *X* and *Y* parts and do the same thing once again:**\n",
    "\n",
    "- Fit the model on the training set (this time filtered one)\n",
    "\n",
    "- Predict probabilities for the test set (untouched one).\n",
    "\n",
    "- Select the best threshold for the specified requirements (precision >= 0.5, max possible recall).\n",
    "\n",
    "- Round up the threshold up to 2 decimal points.\n",
    "\n",
    "- Transform probabilities to binary answers: probability above the threshold = True, False otherwise.\n",
    "\n",
    "- Calculate the precision and recall scores for these predictions. \n",
    "\n",
    "I believe you need no exact instructions, as you did exactly same things in Exercises 2, 3 and 4.\n",
    "\n",
    "Save the score results to variables called **filtered_precision** and **filtered_recall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-48912f8accf051fd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-299a6d55c56a74f0",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(filtered_precision, 0.501309, decimal=2)\n",
    "np.testing.assert_almost_equal(filtered_recall, 0.83238, decimal=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-db9b3e8c447f4bb9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Okay, so it seems like the original notebook had a mistake of evaluating the model on filtered test set. In fact, filtering features with these frequency limits decreased the recall (0.844 -> 0.832). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1ea1fea30e3c1e9b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 8:\n",
    "    \n",
    "Now I'll let you use your fantasy and try to filter the categorical values differently. \n",
    "\n",
    "You're free to do whatever you want, but here are a few ideas you can use:\n",
    "\n",
    "- Instead of dropping rare categories, create a new value for them\n",
    "\n",
    "- Adjust the frequency values (e.g. keep a part of departments we just filtered or filter even more). You can try to search all the possible combinations of frequency values if you want. \n",
    "\n",
    "Your task is to create a list of *True/False* predictions for the **X_test** and call them **best_preds**. These predictions have to have precision >= 0.5 and recall > 0.84422789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ed6aa7a2151ccf89",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# predictions = ...\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0b0af8b253851b65",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "precision = precision_score(y_test, best_preds)\n",
    "recall = recall_score(y_test, best_preds)\n",
    "assert precision >= 0.5\n",
    "assert recall > 0.84422789"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-397df43952bc83d6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 9:\n",
    "\n",
    "So, we got the model. It's usually a good idea to retrain the model on the whole dataset, so now I want you to:\n",
    "- Apply the filters that you just created in the Exercise 7 to **df_combined**\n",
    "- Train the same model on the whole dataset\n",
    "- Export the model, train columns and data types to **/tmp/<file_name>**, where files are called **new_pipeline.pickle**, **new_dtypes.pickle** and **new_columns.json**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b200c367cf7c4646",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1277da522704d17d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "with open('/tmp/new_columns.json') as fh:\n",
    "    columns = json.load(fh)\n",
    "\n",
    "\n",
    "with open('/tmp/new_pipeline.pickle', 'rb') as fh:\n",
    "    pipeline = joblib.load(fh)\n",
    "\n",
    "\n",
    "with open('/tmp/new_dtypes.pickle', 'rb') as fh:\n",
    "    dtypes = pickle.load(fh)\n",
    "\n",
    "assert isinstance(columns, list), 'columns need to be a list of training features'\n",
    "assert 'ContrabandIndicator' not in columns, 'there should be only training features in columns. You got target there.'\n",
    "assert 'is_new' in columns, \"your columns don't contain is_new feature. Are you you updated the columns file?\"\n",
    "assert isinstance(pipeline, Pipeline), 'new_pipeline.pickle does not seem it be an instance of Pipeline class.'\n",
    "assert isinstance(dtypes, pd.core.series.Series)\n",
    "assert all([column in dtypes.index for column in columns]), 'some columns from new_columns file are not in the new_dtypes file'\n",
    "assert all([dtype in columns for dtype in dtypes.index]), 'some dtypes from new_dtypes file are not in the new_columns file'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e661d30ecca08667",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 10:\n",
    "\n",
    "And now it's time to change the server! I know you missed this part :) \n",
    "\n",
    "Before we do it, I want to remind you, that in this exercise we didn't cover the ethics topic.\n",
    "\n",
    "Our model is trained on sensible features like race, sex and ethnicity. \n",
    "\n",
    "In real situation you'd need to make sure that your model is not discriminating anyone. \n",
    "\n",
    "Now, go and create a copy of the **protected_server.py** file. Call it **new_server.py**\n",
    "\n",
    "In that file:\n",
    "- Change the **check_valid_column** function to have the new added columns\n",
    "\n",
    "> You can also automate it by reading the columns file, it's even better!\n",
    "\n",
    "- Change the **check_categorical_values** function:\n",
    "\n",
    "> We didn't really affect any of the checked columns there besides **StatuteReason** (of course, if you didn't change it in your best solution). Remove the values that should not be in this column anymore.\n",
    "\n",
    "> We also add one more categorical feature to the dataframe (**is_new**). Go and add possible values to the check.\n",
    "\n",
    "- As soon as it's done, go ahead and start the server. \n",
    "\n",
    "- Play with the predictions. Make sure that the server checks the **is_new** feature values. Try to send requests without **is_new** or with a different value (not True or False). \n",
    "\n",
    "- After you're done, change the value of **done** to **True** to pass the exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-177c733bbad2ee14",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-af1fc9c2780fcf2a",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert done == True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-61c0054fb792c42e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Aaaaaand...we're done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c836f75fc6b45559",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img src=\"media/congrats.png\" width=300/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
