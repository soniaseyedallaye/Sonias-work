{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4977266850932bfc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# BLU15 - Model CSI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import io\n",
    "import json\n",
    "import pickle\n",
    "import requests\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-20ab4cc706ece288",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Alright, let's go on with the BLU and have fun doing some exercises!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a39e9c915dc5fb6b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img src=\"media/show.jpg\" width=300/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-675e349794cfade8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As a reminder:\n",
    "\n",
    "In the learning unit we received a pretrained model and a new batch of data and analyzed whether the model performs well and what to do with it.\n",
    "\n",
    "In the end, we realized that there are some unexpected changes in the data distribution and we need to retrain the model.\n",
    "\n",
    "As the new dataset was pretty small, we have to concat the old data with the new one and train a new model on the combination of 2 datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b9f04330950f72d6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 1:\n",
    "\n",
    "- Read the .csv file with the original dataframe as **df_old.**\n",
    "\n",
    "- If you take a look on the **VehicleSearchedIndicator** column, you understand that this subset represents the searched cars only, so we can drop the **VehicleSearchedIndicator** column.\n",
    "\n",
    "- As the new dataset doesn't contain **InterventionDateTime** column, we also need to drop it from the old dataset.\n",
    "\n",
    "- Read new observations as **df_new**.\n",
    "\n",
    "- Combine both the dataframes and add a new column called **is_new** that is going to have all **False** values for the old data and all **True** values for the new observations.\n",
    "\n",
    "- Call the combined dataframe **df_combined**\n",
    "\n",
    "- Drop all **NaN** values\n",
    "\n",
    "- Apply lowercase to department names and intervention location names in the combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-04ea06e1af333be0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ContrabandIndicator</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>InterventionLocationName</th>\n",
       "      <th>InterventionReasonCode</th>\n",
       "      <th>ReportingOfficerIdentificationID</th>\n",
       "      <th>ResidentIndicator</th>\n",
       "      <th>SearchAuthorizationCode</th>\n",
       "      <th>StatuteReason</th>\n",
       "      <th>SubjectAge</th>\n",
       "      <th>SubjectEthnicityCode</th>\n",
       "      <th>SubjectRaceCode</th>\n",
       "      <th>SubjectSexCode</th>\n",
       "      <th>TownResidentIndicator</th>\n",
       "      <th>is_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>bridgeport</td>\n",
       "      <td>bridgeport</td>\n",
       "      <td>V</td>\n",
       "      <td>1207</td>\n",
       "      <td>True</td>\n",
       "      <td>I</td>\n",
       "      <td>Speed Related</td>\n",
       "      <td>37.0</td>\n",
       "      <td>H</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>milford</td>\n",
       "      <td>milford</td>\n",
       "      <td>E</td>\n",
       "      <td>2325</td>\n",
       "      <td>True</td>\n",
       "      <td>I</td>\n",
       "      <td>Defective Lights</td>\n",
       "      <td>30.0</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ContrabandIndicator Department Name InterventionLocationName  \\\n",
       "0                False      bridgeport               bridgeport   \n",
       "1                 True         milford                  milford   \n",
       "\n",
       "  InterventionReasonCode ReportingOfficerIdentificationID  ResidentIndicator  \\\n",
       "0                      V                             1207               True   \n",
       "1                      E                             2325               True   \n",
       "\n",
       "  SearchAuthorizationCode     StatuteReason  SubjectAge SubjectEthnicityCode  \\\n",
       "0                       I     Speed Related        37.0                    H   \n",
       "1                       I  Defective Lights        30.0                    N   \n",
       "\n",
       "  SubjectRaceCode SubjectSexCode  TownResidentIndicator  is_new  \n",
       "0               W              M                   True   False  \n",
       "1               W              M                   True   False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_old = pd.read_csv(os.path.join('data','train_searched.csv'))\n",
    "df_old = df_old.drop(['VehicleSearchedIndicator','InterventionDateTime'],axis = 1)\n",
    "df_old['is_new'] =False\n",
    "df_new = pd.read_csv(os.path.join('data','new_observations.csv'))\n",
    "df_new['is_new']=True\n",
    "df_combined = df_old.append(df_new).dropna()\n",
    "df_combined['Department Name'] = df_combined['Department Name'].apply(lambda x:str(x).lower())\n",
    "df_combined['InterventionLocationName'] = df_combined['InterventionLocationName'].apply(lambda x:str(x).lower())\n",
    "# YOUR CODE HERE\n",
    "df_combined.head(n=2)\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8c0d93b76029e43b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert df_combined.shape == (78715, 14), 'combined dataframe shape is wrong'\n",
    "assert 'VehicleSearchedIndicator' not in df_combined.columns, 'Did you drop the VehicleSearchedIndicator column?'\n",
    "assert 'is_new' in df_combined.columns, 'Did you add is_new column?'\n",
    "assert sum(df_combined['is_new']) == 2000, 'is_new column has a wrong number of True values'\n",
    "assert all([name.islower() for name in df_combined['Department Name']]), 'Department name is not lowercased'\n",
    "assert all([name.islower() or not name.isalpha() for name in df_combined['InterventionLocationName']]), 'InterventionLocationName is not lowercased'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-63bf0204b0039261",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 2:\n",
    "\n",
    "**Split the created dataset on train and test parts in the following way:**\n",
    "\n",
    "- Firstly create train and test set. Call them **df_train** and **df_test**.\n",
    "> We'll need them in the future exercises. \n",
    "- Then, split **train** and **test** into **X_train**, **X_test**, **y_train** and **y_test**.\n",
    "- Test sets shape should be 25% of df_combined shape\n",
    "- Make sure to have 25% of new values in the test size.\n",
    "- Use random state 42 while splitting the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7f3b30be400bcb4f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "target = 'ContrabandIndicator'\n",
    "\n",
    "df_train,df_test = train_test_split(df_combined,test_size = 0.25,random_state = 42,stratify = df_combined['is_new'])\n",
    "X_train = df_train.drop('ContrabandIndicator',axis = 1)\n",
    "X_test = df_test.drop('ContrabandIndicator',axis = 1)\n",
    "y_train =df_train['ContrabandIndicator']\n",
    "y_test = df_test['ContrabandIndicator']\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59036, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-38a33c6dedc5abe8",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert df_train.shape == (59036, 14), 'df_train shape is wrong. Are you sure test size is 25%?'\n",
    "assert df_test.shape == (19679, 14), 'df_test shape is wrong. Are you sure test size is 25%?'\n",
    "assert X_train.shape == (59036, 13), 'X_train shape is wrong. Are you sure test size is 25%?'\n",
    "assert X_test.shape == (19679, 13), 'X_test shape is wrong. Are you sure test size is 25%?'\n",
    "assert y_train.shape == (59036,), 'X_train shape is wrong. Are you sure test size is 25%?'\n",
    "assert y_test.shape == (19679,), 'X_train shape is wrong. Are you sure test size is 25%?'\n",
    "assert sum(X_train['is_new']) == 1500, 'is_new column in Training set has a wrong number of True values. Make sure to have 25% of new values'\n",
    "assert sum(X_test['is_new']) == 500, 'is_new column in Test set has a wrong number of True values. Make sure to have 25% of new values'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5ce46b652d62760d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we need to retrain the model.\n",
    "\n",
    "If we simply load the pipeline and retrain it, it's going to ignore our new feature.\n",
    "\n",
    "So let's create the same pipeline as in the original notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = df_combined.columns.drop(['ContrabandIndicator', 'SubjectAge'])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    preprocessor,\n",
    "    LGBMClassifier(n_jobs=-1, random_state=42),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('cat',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  Index(['Department Name', 'InterventionLocationName', 'InterventionReasonCode',\n",
       "       'ReportingOfficerIdentificationID', 'ResidentIndicator',\n",
       "       'SearchAuthorizationCode', 'StatuteReason', 'SubjectEthnicityCode',\n",
       "       'SubjectRaceCode', 'SubjectSexCode', 'TownResidentIndicator', 'is_new'],\n",
       "      dtype='object'))])),\n",
       "                ('lgbmclassifier', LGBMClassifier(random_state=42))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3:\n",
    "\n",
    "Now let's test how the model performs:\n",
    "\n",
    "- Make model binary predictions and save them to an array **preds**. \n",
    "- Make model probability predictions and save them to an array called **preds_proba**. Keep only True class probabilities (by default probability prediction returns you both False and True classes probabilities)\n",
    "- Create a variable called **precision** with the model precision score.\n",
    "- Create a variable called **recall** with the model recall score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9be477a1561648b5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5460269865067466"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "preds = pipeline.predict(X_test)\n",
    "preds = preds.astype(int)\n",
    "preds_proba = pipeline.predict_proba(X_test)\n",
    "preds_proba = preds_proba[:,1]\n",
    "precision = precision_score(y_test,preds)\n",
    "recall = recall_score(y_test,preds)\n",
    "#raise NotImplementedError()\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_recall = 'a2cffa866c48b997372a62104161ba89e68fb439c418fc2559e2a32c44987ce8'\n",
    "hash_recall = hashlib.sha256(bytes(str(round(recall, 2)), encoding='utf8')).hexdigest()\n",
    "assert hash_recall == expected_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-134d5512471b46a5",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(preds) == 19679, 'Are you sure you made predictions for test set only?'\n",
    "assert len(preds_proba) == 19679, 'Are you sure you made predictions for test set only?'\n",
    "assert not isinstance(preds_proba[0], np.ndarray), 'Are you sure you kept only the True class predictions?'\n",
    "assert round(sum(preds_proba)) == 6563\n",
    "np.testing.assert_almost_equal(precision, 0.64966, decimal=2)\n",
    "np.testing.assert_almost_equal(recall, 0.546027, decimal=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-00ba0926557db298",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "## Exercise 4: \n",
    "\n",
    "It's already not bad, but let's now try to calculate the optimal threshold.\n",
    "\n",
    "By threshold I mean the minimal probability of a prediction that we're going to call \"True\". \n",
    "\n",
    "By default, any prediction with probability > 0.5 is called True, but we might find a better value. \n",
    "\n",
    "The metric is the same: our success rate (precision) needs to be at least 50%, and the recall should be as big as possible. \n",
    "\n",
    "Save the result to a variable called **threshold**. Round the result to 2 decimal points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9f436f48cd5a5f33",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8493253373313343"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test, preds_proba)\n",
    "precision = precision[:-1]\n",
    "recall = recall[:-1]\n",
    "min_index = [i for i, prec in enumerate(precision) if prec >= 0.5][0]\n",
    "precision[min_index]\n",
    "recall[min_index]\n",
    "round(thresholds[min_index],2)\n",
    "threshold = round(thresholds[min_index],2)\n",
    "recall[min_index]\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-326014262a2ffeb9",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert round(threshold, 2) == threshold, 'Did you round the value?'\n",
    "ans_threshold = hashlib.sha256(bytes(str(threshold), encoding='utf8')).hexdigest()\n",
    "assert ans_threshold == \"6382e07f9de0c85293aee2a45b88c61c28589419682ecc2f8c097f750e861a24\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-189130f10b806acf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 5:\n",
    "\n",
    "- Now create a list of predictions. \n",
    "\n",
    "> All the values from the **preds_proba** list that have a value > threshold should be True. The rest should be False.\n",
    "\n",
    "> Save the result to a variable called **best_preds**\n",
    "\n",
    "- Calculate the precision and recall and save them to variables **precision** and **recall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-11c3a5f9bbcc11ff",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8442278860569715"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_preds =[True if pred > threshold else False for pred in preds_proba]\n",
    "precision = precision_score(y_test,best_preds)\n",
    "recall = recall_score(y_test,best_preds)\n",
    "recall\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1b53ef9739686af6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(precision, 0.50290256, decimal=2)\n",
    "np.testing.assert_almost_equal(recall, 0.84422789, decimal=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a38fa1224ab86e3c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 6:\n",
    "\n",
    "Now let's find out whether removing rare values is going to help. \n",
    "\n",
    "**Filter *df_train* (the one you created in the Exercise 2) the following way:** \n",
    "\n",
    "- Remove rows with **Department Name** that appear <= 50 times\n",
    "- Remove rows with **InterventionLocationName** that appear <= 50 times\n",
    "- Remove rows with **ReportingOfficerIdentificationID** that appear <= 30 times\n",
    "- Remove rows with **StatuteReason** that appear <= 10 times\n",
    "- Note: it's better to keep the original dataframe not touched. Create a copy of the original dataframe and save the results to a variable **train_filtered**\n",
    "\n",
    "> We have to filter the values after we split the dataset into training and test, because by filtering the test set we also affect the score. If we filtered everything besides the examples that are the easiest to predict, we'd have a super nice score, but in production we're going to expect both the filtered values and unfiltered ones. \n",
    "\n",
    "> We shouldn't worry about the fact, that some values in the test set will not be present in the training set, because the pipeline is simply going to ignore them.\n",
    "\n",
    "> (you might use the logic from the original model's notebook, but I suggest trying to implement it by yourself, it's a good exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b7b6cf4076907562",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "min_frequency = {\n",
    "    \"Department Name\": 50,\n",
    "    \"InterventionLocationName\": 50,\n",
    "    \"ReportingOfficerIdentificationID\": 30,\n",
    "    \"StatuteReason\": 10\n",
    "}\n",
    "def filter_values(df: pd.DataFrame, column_name: str, threshold: int):\n",
    "    value_counts = df[column_name].value_counts()\n",
    "    to_keep = value_counts[value_counts > threshold].index\n",
    "    filtered = df[df[column_name].isin(to_keep)]\n",
    "    return filtered\n",
    "train_filtered = df_train.copy()\n",
    "for feature, threshold in min_frequency.items():\n",
    "    train_filtered=filter_values(train_filtered, feature, threshold)\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-204c92ef82321cee",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert train_filtered.shape == (30502, 14), 'Make sure to filter rare values. Make sure to filter only train set.'\n",
    "assert 'middlebury' not in train_filtered['Department Name'], 'Did you filter department names?'\n",
    "assert 'hampton' not in train_filtered['InterventionLocationName'], 'Did you filter InterventionLocationName ?'\n",
    "assert 'DACYR048' not in train_filtered['ReportingOfficerIdentificationID'], 'Did you filter officer ids?'\n",
    "assert 'Stop Sign ' not in train_filtered['StatuteReason'], 'Did you filter statute reasons?'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4bf528ed9d629b95",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 7:\n",
    "\n",
    "**Let's split *train_filtered* into *X* and *Y* parts and do the same thing once again:**\n",
    "\n",
    "- Fit the model on the training set (this time filtered one)\n",
    "\n",
    "- Predict probabilities for the test set (untouched one).\n",
    "\n",
    "- Select the best threshold for the specified requirements (precision >= 0.5, max possible recall).\n",
    "\n",
    "- Round up the threshold up to 2 decimal points.\n",
    "\n",
    "- Transform probabilities to binary answers: probability above the threshold = True, False otherwise.\n",
    "\n",
    "- Calculate the precision and recall scores for these predictions. \n",
    "\n",
    "I believe you need no exact instructions, as you did exactly same things in Exercises 2, 3 and 4.\n",
    "\n",
    "Save the score results to variables called **filtered_precision** and **filtered_recall**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-48912f8accf051fd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8344827586206897"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_filtered = train_filtered.drop('ContrabandIndicator',axis = 1)\n",
    "y_train_filtered =train_filtered['ContrabandIndicator']\n",
    "pipeline.fit(X_train_filtered, y_train_filtered)\n",
    "preds = pipeline.predict(X_test)\n",
    "preds = preds.astype(int)\n",
    "preds_proba = pipeline.predict_proba(X_test)\n",
    "preds_proba = preds_proba[:,1]\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, preds_proba)\n",
    "precision = precision[:-1]\n",
    "recall = recall[:-1]\n",
    "min_index = [i for i, prec in enumerate(precision) if prec >= 0.5][0]\n",
    "filtered_precision = precision[min_index]\n",
    "filtered_recall = recall[min_index]\n",
    "round(thresholds[min_index],2)\n",
    "threshold = round(thresholds[min_index],2)\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "filtered_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-299a6d55c56a74f0",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(filtered_precision, 0.501309, decimal=2)\n",
    "np.testing.assert_almost_equal(filtered_recall, 0.83238, decimal=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-db9b3e8c447f4bb9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Okay, so it seems like the original notebook had a mistake of evaluating the model on filtered test set. In fact, filtering features with these frequency limits decreased the recall (0.844 -> 0.832). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1ea1fea30e3c1e9b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 8:\n",
    "    \n",
    "Now I'll let you use your fantasy and try to filter the categorical values differently. \n",
    "\n",
    "You're free to do whatever you want, but here are a few ideas you can use:\n",
    "\n",
    "- Instead of dropping rare categories, create a new value for them\n",
    "\n",
    "- Adjust the frequency values (e.g. keep a part of departments we just filtered or filter even more). You can try to search all the possible combinations of frequency values if you want. \n",
    "\n",
    "Your task is to create a list of *True/False* predictions for the **X_test** and call them **best_preds**. These predictions have to have precision >= 0.5 and recall > 0.84422789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3281, 3233, 3191, 3184, 3153, 3126, 2714, 2527, 2471, 2369, 2319,\n",
       "       1935, 1926, 1564, 1561, 1464, 1409, 1395, 1129, 1054,  995,  920,\n",
       "        832,  793,  772,  660,  628,  605,  595,  586,  575,  514,  506,\n",
       "        455,  428,  408,  401,  387,  367,  300,  254,  248,  235,  232,\n",
       "        193,  160,  118,  113,   95,   92,   67,   53,   47,   47,   47,\n",
       "         43,   38,   28,   20,   18,   14,   13,   13,   12,   10,    9,\n",
       "          8,    8,    8,    7,    6,    6,    5,    5,    4,    4,    4,\n",
       "          3,    3,    3,    2,    2,    2,    1,    1,    1,    1,    1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['SubjectAge'].value_counts().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ContrabandIndicator</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>InterventionLocationName</th>\n",
       "      <th>InterventionReasonCode</th>\n",
       "      <th>ReportingOfficerIdentificationID</th>\n",
       "      <th>ResidentIndicator</th>\n",
       "      <th>SearchAuthorizationCode</th>\n",
       "      <th>StatuteReason</th>\n",
       "      <th>SubjectAge</th>\n",
       "      <th>SubjectEthnicityCode</th>\n",
       "      <th>SubjectRaceCode</th>\n",
       "      <th>SubjectSexCode</th>\n",
       "      <th>TownResidentIndicator</th>\n",
       "      <th>is_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59156</th>\n",
       "      <td>False</td>\n",
       "      <td>glastonbury</td>\n",
       "      <td>glastonbury</td>\n",
       "      <td>V</td>\n",
       "      <td>SAS0410</td>\n",
       "      <td>True</td>\n",
       "      <td>C</td>\n",
       "      <td>Administrative Offense</td>\n",
       "      <td>29.0</td>\n",
       "      <td>H</td>\n",
       "      <td>B</td>\n",
       "      <td>M</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39492</th>\n",
       "      <td>False</td>\n",
       "      <td>csp troop i</td>\n",
       "      <td>shelton</td>\n",
       "      <td>V</td>\n",
       "      <td>1000002761</td>\n",
       "      <td>True</td>\n",
       "      <td>C</td>\n",
       "      <td>Moving Violation</td>\n",
       "      <td>25.0</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43199</th>\n",
       "      <td>True</td>\n",
       "      <td>csp troop c</td>\n",
       "      <td>tolland</td>\n",
       "      <td>V</td>\n",
       "      <td>1000002352</td>\n",
       "      <td>True</td>\n",
       "      <td>I</td>\n",
       "      <td>Other</td>\n",
       "      <td>26.0</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50400</th>\n",
       "      <td>False</td>\n",
       "      <td>new haven</td>\n",
       "      <td>new haven</td>\n",
       "      <td>E</td>\n",
       "      <td>137</td>\n",
       "      <td>True</td>\n",
       "      <td>C</td>\n",
       "      <td>Defective Lights</td>\n",
       "      <td>28.0</td>\n",
       "      <td>N</td>\n",
       "      <td>B</td>\n",
       "      <td>M</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60632</th>\n",
       "      <td>False</td>\n",
       "      <td>stratford</td>\n",
       "      <td>stratford</td>\n",
       "      <td>E</td>\n",
       "      <td>30252</td>\n",
       "      <td>True</td>\n",
       "      <td>C</td>\n",
       "      <td>Display of Plates</td>\n",
       "      <td>26.0</td>\n",
       "      <td>N</td>\n",
       "      <td>B</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36837</th>\n",
       "      <td>True</td>\n",
       "      <td>middletown</td>\n",
       "      <td>middletown</td>\n",
       "      <td>I</td>\n",
       "      <td>231</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Other</td>\n",
       "      <td>22.0</td>\n",
       "      <td>H</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>True</td>\n",
       "      <td>westport</td>\n",
       "      <td>westport</td>\n",
       "      <td>I</td>\n",
       "      <td>PSC20044</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>Other</td>\n",
       "      <td>24.0</td>\n",
       "      <td>N</td>\n",
       "      <td>B</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12268</th>\n",
       "      <td>False</td>\n",
       "      <td>rocky hill</td>\n",
       "      <td>rocky hill</td>\n",
       "      <td>V</td>\n",
       "      <td>EAG0167</td>\n",
       "      <td>True</td>\n",
       "      <td>O</td>\n",
       "      <td>Suspended License</td>\n",
       "      <td>26.0</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36443</th>\n",
       "      <td>True</td>\n",
       "      <td>csp troop g</td>\n",
       "      <td>westport</td>\n",
       "      <td>V</td>\n",
       "      <td>119974171</td>\n",
       "      <td>False</td>\n",
       "      <td>O</td>\n",
       "      <td>Speed Related</td>\n",
       "      <td>20.0</td>\n",
       "      <td>N</td>\n",
       "      <td>B</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56553</th>\n",
       "      <td>False</td>\n",
       "      <td>csp troop g</td>\n",
       "      <td>milford</td>\n",
       "      <td>V</td>\n",
       "      <td>493242003</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Speed Related</td>\n",
       "      <td>27.0</td>\n",
       "      <td>H</td>\n",
       "      <td>B</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59036 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ContrabandIndicator Department Name InterventionLocationName  \\\n",
       "59156                False     glastonbury              glastonbury   \n",
       "39492                False     csp troop i                  shelton   \n",
       "43199                 True     csp troop c                  tolland   \n",
       "50400                False       new haven                new haven   \n",
       "60632                False       stratford                stratford   \n",
       "...                    ...             ...                      ...   \n",
       "36837                 True      middletown               middletown   \n",
       "1818                  True        westport                 westport   \n",
       "12268                False      rocky hill               rocky hill   \n",
       "36443                 True     csp troop g                 westport   \n",
       "56553                False     csp troop g                  milford   \n",
       "\n",
       "      InterventionReasonCode ReportingOfficerIdentificationID  \\\n",
       "59156                      V                          SAS0410   \n",
       "39492                      V                       1000002761   \n",
       "43199                      V                       1000002352   \n",
       "50400                      E                              137   \n",
       "60632                      E                            30252   \n",
       "...                      ...                              ...   \n",
       "36837                      I                              231   \n",
       "1818                       I                         PSC20044   \n",
       "12268                      V                          EAG0167   \n",
       "36443                      V                        119974171   \n",
       "56553                      V                        493242003   \n",
       "\n",
       "       ResidentIndicator SearchAuthorizationCode           StatuteReason  \\\n",
       "59156               True                       C  Administrative Offense   \n",
       "39492               True                       C        Moving Violation   \n",
       "43199               True                       I                   Other   \n",
       "50400               True                       C        Defective Lights   \n",
       "60632               True                       C       Display of Plates   \n",
       "...                  ...                     ...                     ...   \n",
       "36837              False                       C                   Other   \n",
       "1818               False                       O                   Other   \n",
       "12268               True                       O       Suspended License   \n",
       "36443              False                       O           Speed Related   \n",
       "56553              False                       C           Speed Related   \n",
       "\n",
       "       SubjectAge SubjectEthnicityCode SubjectRaceCode SubjectSexCode  \\\n",
       "59156        29.0                    H               B              M   \n",
       "39492        25.0                    N               W              M   \n",
       "43199        26.0                    N               W              M   \n",
       "50400        28.0                    N               B              M   \n",
       "60632        26.0                    N               B              M   \n",
       "...           ...                  ...             ...            ...   \n",
       "36837        22.0                    H               W              M   \n",
       "1818         24.0                    N               B              M   \n",
       "12268        26.0                    N               W              M   \n",
       "36443        20.0                    N               B              M   \n",
       "56553        27.0                    H               B              F   \n",
       "\n",
       "       TownResidentIndicator  is_new  \n",
       "59156                   True   False  \n",
       "39492                  False   False  \n",
       "43199                  False   False  \n",
       "50400                   True   False  \n",
       "60632                  False   False  \n",
       "...                      ...     ...  \n",
       "36837                   True   False  \n",
       "1818                   False    True  \n",
       "12268                  False   False  \n",
       "36443                  False   False  \n",
       "56553                  False   False  \n",
       "\n",
       "[59036 rows x 14 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ed6aa7a2151ccf89",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000448068823371"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_frequency = {\n",
    "    \"Department Name\": 50,\n",
    "    #\"InterventionLocationName\": 50,\n",
    "    #\"ReportingOfficerIdentificationID\": 30,\n",
    "    #\"StatuteReason\": 10\n",
    "    #\"SubjectAge\" : 10\n",
    "}\n",
    "def filter_values(df: pd.DataFrame, column_name: str, threshold: int):\n",
    "    value_counts = df[column_name].value_counts()\n",
    "    to_keep = value_counts[value_counts > threshold].index\n",
    "    filtered = df[df[column_name].isin(to_keep)]\n",
    "    return filtered\n",
    "for feature, threshold in min_frequency.items():\n",
    "    train_filtered=filter_values(train_filtered, feature, threshold)   \n",
    "X_train_filtered = train_filtered.drop('ContrabandIndicator',axis = 1)\n",
    "y_train_filtered =train_filtered['ContrabandIndicator']\n",
    "pipeline.fit(X_train_filtered, y_train_filtered)\n",
    "preds = pipeline.predict(X_test)\n",
    "preds = preds.astype(int)\n",
    "preds_proba = pipeline.predict_proba(X_test)\n",
    "preds_proba = preds_proba[:,1]\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, preds_proba)\n",
    "precision = precision[:-1]\n",
    "recall = recall[:-1]\n",
    "min_index = [i for i, prec in enumerate(precision) if prec >= 0.5][0]\n",
    "filtered_precision = precision[min_index]\n",
    "filtered_recall = recall[min_index]\n",
    "round(thresholds[min_index],2)\n",
    "threshold = round(thresholds[min_index],2)\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "filtered_recall\n",
    "\n",
    "# predictions = ...\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "filtered_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0b0af8b253851b65",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-62a62466de8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mrecall\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.84422789\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_test, best_preds)\n",
    "recall = recall_score(y_test, best_preds)\n",
    "assert precision >= 0.5\n",
    "assert recall > 0.84422789"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-397df43952bc83d6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 9:\n",
    "\n",
    "So, we got the model. It's usually a good idea to retrain the model on the whole dataset, so now I want you to:\n",
    "- Apply the filters that you just created in the Exercise 7 to **df_combined**\n",
    "- Train the same model on the whole dataset\n",
    "- Export the model, train columns and data types to **/tmp/<file_name>**, where files are called **new_pipeline.pickle**, **new_dtypes.pickle** and **new_columns.json**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b200c367cf7c4646",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "min_frequency = {\n",
    "    \"Department Name\": 50,\n",
    "    \"InterventionLocationName\": 50,\n",
    "    \"ReportingOfficerIdentificationID\": 30,\n",
    "    \"StatuteReason\": 10\n",
    "}\n",
    "df_combined_filtered = df_combined.copy()\n",
    "for feature, threshold in min_frequency.items():\n",
    "    df_combined_filtered=filter_values(df_combined_filtered, feature, threshold)\n",
    "df_combined_filtered_X = df_combined_filtered.drop('ContrabandIndicator',axis = 1)\n",
    "df_combined_filtered_y =df_combined_filtered['ContrabandIndicator']\n",
    "categorical_features = df_combined.columns.drop(['ContrabandIndicator', 'SubjectAge'])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    preprocessor,\n",
    "    LGBMClassifier(n_jobs=-1, random_state=42),\n",
    ")\n",
    "pipeline.fit(df_combined_filtered_X,df_combined_filtered_y)\n",
    "with open('/tmp/new_columns.json','w') as fh:\n",
    "    json.dump(df_combined_filtered_X.columns.tolist(),fh)\n",
    "\n",
    "with open('/tmp/new_dtypes.pickle','wb') as fh:\n",
    "    pickle.dump(df_combined_filtered_X.dtypes,fh)\n",
    "    \n",
    "joblib.dump(pipeline, '/tmp/new_pipeline.pickle');\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1277da522704d17d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "with open('/tmp/new_columns.json') as fh:\n",
    "    columns = json.load(fh)\n",
    "\n",
    "\n",
    "with open('/tmp/new_pipeline.pickle', 'rb') as fh:\n",
    "    pipeline = joblib.load(fh)\n",
    "\n",
    "\n",
    "with open('/tmp/new_dtypes.pickle', 'rb') as fh:\n",
    "    dtypes = pickle.load(fh)\n",
    "\n",
    "assert isinstance(columns, list), 'columns need to be a list of training features'\n",
    "assert 'ContrabandIndicator' not in columns, 'there should be only training features in columns. You got target there.'\n",
    "assert 'is_new' in columns, \"your columns don't contain is_new feature. Are you you updated the columns file?\"\n",
    "assert isinstance(pipeline, Pipeline), 'new_pipeline.pickle does not seem it be an instance of Pipeline class.'\n",
    "assert isinstance(dtypes, pd.core.series.Series)\n",
    "assert all([column in dtypes.index for column in columns]), 'some columns from new_columns file are not in the new_dtypes file'\n",
    "assert all([dtype in columns for dtype in dtypes.index]), 'some dtypes from new_dtypes file are not in the new_columns file'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e661d30ecca08667",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 10:\n",
    "\n",
    "And now it's time to change the server! I know you missed this part :) \n",
    "\n",
    "Before we do it, I want to remind you, that in this exercise we didn't cover the ethics topic.\n",
    "\n",
    "Our model is trained on sensible features like race, sex and ethnicity. \n",
    "\n",
    "In real situation you'd need to make sure that your model is not discriminating anyone. \n",
    "\n",
    "Now, go and create a copy of the **protected_server.py** file. Call it **new_server.py**\n",
    "\n",
    "In that file:\n",
    "- Change the **check_valid_column** function to have the new added columns\n",
    "\n",
    "> You can also automate it by reading the columns file, it's even better!\n",
    "\n",
    "- Change the **check_categorical_values** function:\n",
    "\n",
    "> We didn't really affect any of the checked columns there besides **StatuteReason** (of course, if you didn't change it in your best solution). Remove the values that should not be in this column anymore.\n",
    "\n",
    "> We also add one more categorical feature to the dataframe (**is_new**). Go and add possible values to the check.\n",
    "\n",
    "- As soon as it's done, go ahead and start the server. \n",
    "\n",
    "- Play with the predictions. Make sure that the server checks the **is_new** feature values. Try to send requests without **is_new** or with a different value (not True or False). \n",
    "\n",
    "- After you're done, change the value of **done** to **True** to pass the exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-177c733bbad2ee14",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-af1fc9c2780fcf2a",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert done == True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-61c0054fb792c42e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Aaaaaand...we're done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c836f75fc6b45559",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img src=\"media/congrats.png\" width=300/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
