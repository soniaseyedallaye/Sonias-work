{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import numpy as np\n",
    "\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "\n",
    "# Perform Dickey-Fuller test:\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "import pmdarima as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data is the series with (date) index, X is a new index (0,1,2,...) we append to series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ...\n",
    "X = data.reset_index().index.values.reshape(-1, 1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trend :Linear Regression that maps time steps to time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slr = LinearRegression(fit_intercept=True)\n",
    "\n",
    "slr.fit(X, data)\n",
    "\n",
    "linear_trend = pd.Series(slr.predict(X), index=data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R^2 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slr.score(X, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trend estimation by moving average(6month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## choosing rolling wingows by any size we want this help to choose rows with the number \n",
    "#of rolling size and copute agregation function on that and write the value on the last row on that specific window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_avg_6_months = data.rolling(6,min_periods = 0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trend Plot(all together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(label=\"original data\")\n",
    "linear_trend.plot(label=\"linear trend\")\n",
    "moving_avg_6_months_.plot(label=\"moving average (6 months) trend\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of missing data\n",
    "df['col'].isnull().sum()\n",
    "#fill the missing data\n",
    "#'MS' means monthly we use it if the data recorder monthly if it s recorded daily or weekly or yearly this option will change!\n",
    "df['col'] = df['col'].resample('MS').asfreq()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shift the column in the df up and down and add that shifted col to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['new_col'] = data['col'].shift(-1 or +1 or any number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['col'], data.new_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation of shifted coumn with the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()['column we want to shift']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chack the varience to choose the modell\n",
    "\n",
    "#Multiplicitive modell: when the varience is increasing\n",
    "#Aditive modell: when the variance doese not change with time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col'].rolling(6).std().plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = seasonal_decompose(df['col'], model='multiplicative') #can be aditive according to the previous plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot trend seasenical irregular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Correlation Function ACF Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col'].corr(df['col'].shift(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the correlation with different lags (shift) and plot them ACF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acf(df['col'])\n",
    "\n",
    "#plot\n",
    "#alpha give the confidence interval so in the case alpha = 0.05 the confidence interval is 95 percent\n",
    "# note: when ACF plot doese not have structure we have noise(The way to recognize noise)\n",
    "plot_acf(df['col'], alpha=.05,lags = 50)\n",
    "plt.xlabel('lag')\n",
    "plt.ylabel('Autocorrelation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the correlation with different lags (shift) and plot them PACF it removes seasonality from ACF to see better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacf(df['col'])\n",
    "\n",
    "#plot\n",
    "#alpha give the confidence interval so in the case alpha = 0.05 the confidence interval is 95 percent\n",
    "# note: The ACF and PACF both are in the interval -1 and 1\n",
    "plot_acf(df['col'], alpha=.05,lags = 50,method='ols') #method is so important otherwise the answers will be wrong and tha range will not be between -1 and 1\n",
    "plt.xlabel('lag')\n",
    "plt.ylabel('Autocorrelation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! explorer.exe ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dickey-Fuller test for evaluating stationary\n",
    "#this test contain the H_0 which is zero hypothesis which is the characteristic polynomial of corresponding difference #equations contains root = 1 which means the difference equation or our time series is not stationary so we need to reject \n",
    "#zero hypothesis to accept the H_1. For rejecting the p_value must be less than some threshold that threshold can be obtained by the value of alpha in ACF test. for alpha = 0.05 the p-value must be less than this in order to be able to reject H_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adfstat, pvalue, usedlag, nobs, critvalues, icbest = adfuller(airlines_logged_diff.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before doing this model we need to first load or read the data in the form of series then split the train and test set which is reasonable\n",
    "#for the time series according to the time frequency for example if time freq is month we need to put 24 month 2 years for the test \n",
    "#and the rest for the train\n",
    "\n",
    "#load or read the data   data = ...\n",
    "#making it stationary by removing trend by diff(model will do this part for us) and make the\n",
    "#variance stable by using log of the data (we must do this)\n",
    "#data_log = np.log(data)  or data.map(np.log)\n",
    "#train = data_log[:-24]\n",
    "#test = data_log[-24:]\n",
    "\n",
    "\n",
    "#Autoregressive model of order p is of the form\n",
    "#X_t = c + phi_1*X_{t-1} + phi_2*X_{t-2} + ... + phi_p*X_{t-p} + epsilon_t where epsilon is white noise\n",
    "#moving average model of order q is pf the form\n",
    "#X_t = mu+epsilon_t + theta_1*epsilon_{t-1}+theta_2*epsilon_{t-2}+...+theta_q*epsilon_{t-q}\n",
    "\n",
    "arima = SARIMAX(train, order=(2, 1, 1),trend='c') # these have been previously found via an automatic method\n",
    "arima_results = arima.fit()\n",
    "arima_predictions = np.exp(arima_results.predict())[1:] #Â grab the prediction from our model and undo the log transform using exp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Plot\n",
    "plt.plot(np.exp(train), label='original')\n",
    "plt.plot(arima_predictions, label='arima')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarimax = SARIMAX(train,     trend='c',        \n",
    "                          order=(2, 0, 0),              # <-- keeping same params as before\n",
    "                          seasonal_order=(0, 1, 1, 12)) # <-- We'll get into how we found these hyper params later\n",
    "sarimax_results = sarimax.fit(maxiter=1000)\n",
    "sarimax_predictions = np.exp(sarimax_results.predict())[24:] #Â grab the prediction from our model and undo the log transform using exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.exp(train), label='original')\n",
    "plt.plot(arima_predictions, label='arima')\n",
    "plt.plot(sarimax_predictions, label='sarimax')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-Sample Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smaller is better\n",
    "arima_results.aic\n",
    "sarimax_results.aic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the one step forcasting means we're just predicting the next step, the multi step forcasting means we're predicintg multiple steps\n",
    "arima_forecast = arima_results.get_forecast(24)#ARIMA FORCAST\n",
    "sarimax_forecast = sarimax_results.get_forecast(24) # SARIMA FORCAST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PMDARIMA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is for tuning the parameters in ARIMA and SARIMAX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Automatically search for the best Arima model(we can give seasonality\n",
    "#m=12 or we can wait for the autoarima to choose one for us but in this case it takes more time to choose the best modell)\n",
    "#we must use the log data but not the detrend one because this model automatically detrend the data\n",
    "sarimax = pm.AutoARIMA(trace=True, supress_warnings=True, m=12)\n",
    "sarimax.fit(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After choosing the best modell now we can predict\n",
    "sarimax_forecast = sarimax.predict(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After predicting we can find the mean absolute error of our prediction as a measure of goodness or badness of the model\n",
    "mean_absolute_error(np.exp(sarimax_forecast),np.exp(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In_Sample_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sarimax = pm.AutoARIMA(trace=True, supress_warnings=True, m=12, method='nm', maxiter=20)\n",
    "sarimax.fit(emissions_train_log)\n",
    "predictions =np.exp(sarimax.predict_in_sample())\n",
    "mae =mean_absolute_error(predictions,np.exp(emissions_train_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to prepare data frame which has date column for time series modelling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-read the data(data frame)\n",
    "exog = pd.read_csv('data/radiation.csv')\n",
    "#2-change the Datetime column into the Datetime format\n",
    "exog.Datetime = pd.to_datetime(exog.Datetime)\n",
    "#3-put the Datetime columns as an index\n",
    "exog = exog.set_index('Datetime')\n",
    "#4- sort index\n",
    "exog = exog.sort_index()\n",
    "#5-seperate train and test set\n",
    "exog_train = exog['2016-01-01 07':'2016-01-31']\n",
    "exog_test = exog['2016-02']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
