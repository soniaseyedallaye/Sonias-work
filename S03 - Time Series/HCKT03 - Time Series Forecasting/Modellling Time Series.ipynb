{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib import pyplot as plt \n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "%matplotlib inline \n",
    "import numpy as np\n",
    "plt.rcParams['figure.figsize'] = (16, 4)\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "warnings.filterwarnings(action=\"ignore\", module=\"scipy\", message=\"^internal gelsd\")\n",
    "\n",
    "#from utils import * # We've added all the functions from the last BLU to the utils.py \n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "from random import gauss\n",
    "from random import seed\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import itertools\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa import stattools\n",
    "from pandas.plotting import lag_plot\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16, 4)\n",
    "import pmdarima as pm\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "idx = pd.IndexSlice\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)   \n",
    "from random import seed\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import itertools\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa import stattools\n",
    "import hashlib # for grading purposes\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import pmdarima as pm\n",
    "from pmdarima.pipeline import Pipeline\n",
    "from pmdarima.preprocessing import BoxCoxEndogTransformer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wp</th>\n",
       "      <th>ws</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>rolling_max</th>\n",
       "      <th>rolling_min</th>\n",
       "      <th>rolling_mean</th>\n",
       "      <th>rolling_std</th>\n",
       "      <th>df_logg_wp</th>\n",
       "      <th>df_logg_ws</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-07-01 01:00:00</th>\n",
       "      <td>0.0850</td>\n",
       "      <td>2.47</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0850</td>\n",
       "      <td>0.0850</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.465104</td>\n",
       "      <td>0.904218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-01 02:00:00</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0850</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.052500</td>\n",
       "      <td>0.045962</td>\n",
       "      <td>-3.912023</td>\n",
       "      <td>0.875469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-01 03:00:00</th>\n",
       "      <td>0.0600</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0850</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>-2.813411</td>\n",
       "      <td>0.920283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-01 04:00:00</th>\n",
       "      <td>0.0450</td>\n",
       "      <td>2.73</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0850</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.052500</td>\n",
       "      <td>0.027234</td>\n",
       "      <td>-3.101093</td>\n",
       "      <td>1.004302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-01 05:00:00</th>\n",
       "      <td>0.0350</td>\n",
       "      <td>2.93</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0850</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.024850</td>\n",
       "      <td>-3.352407</td>\n",
       "      <td>1.075002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30 19:00:00</th>\n",
       "      <td>0.3960</td>\n",
       "      <td>7.25</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>0.8370</td>\n",
       "      <td>0.1082</td>\n",
       "      <td>0.427900</td>\n",
       "      <td>0.236670</td>\n",
       "      <td>-0.926341</td>\n",
       "      <td>1.981001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30 20:00:00</th>\n",
       "      <td>0.6646</td>\n",
       "      <td>7.09</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0.8370</td>\n",
       "      <td>0.1082</td>\n",
       "      <td>0.422175</td>\n",
       "      <td>0.228757</td>\n",
       "      <td>-0.408570</td>\n",
       "      <td>1.958685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30 21:00:00</th>\n",
       "      <td>0.4480</td>\n",
       "      <td>6.63</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>0.8370</td>\n",
       "      <td>0.1082</td>\n",
       "      <td>0.406383</td>\n",
       "      <td>0.212069</td>\n",
       "      <td>-0.802962</td>\n",
       "      <td>1.891605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30 22:00:00</th>\n",
       "      <td>0.2806</td>\n",
       "      <td>5.74</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>0.7420</td>\n",
       "      <td>0.1082</td>\n",
       "      <td>0.383200</td>\n",
       "      <td>0.192453</td>\n",
       "      <td>-1.270825</td>\n",
       "      <td>1.747459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30 23:00:00</th>\n",
       "      <td>0.0832</td>\n",
       "      <td>4.64</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>0.6646</td>\n",
       "      <td>0.0832</td>\n",
       "      <td>0.355750</td>\n",
       "      <td>0.185924</td>\n",
       "      <td>-2.486508</td>\n",
       "      <td>1.534714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8759 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         wp    ws  day  month  hour  rolling_max  rolling_min  \\\n",
       "date                                                                            \n",
       "2009-07-01 01:00:00  0.0850  2.47    1      7     1       0.0850       0.0850   \n",
       "2009-07-01 02:00:00  0.0200  2.40    1      7     2       0.0850       0.0200   \n",
       "2009-07-01 03:00:00  0.0600  2.51    1      7     3       0.0850       0.0200   \n",
       "2009-07-01 04:00:00  0.0450  2.73    1      7     4       0.0850       0.0200   \n",
       "2009-07-01 05:00:00  0.0350  2.93    1      7     5       0.0850       0.0200   \n",
       "...                     ...   ...  ...    ...   ...          ...          ...   \n",
       "2010-06-30 19:00:00  0.3960  7.25   30      6    19       0.8370       0.1082   \n",
       "2010-06-30 20:00:00  0.6646  7.09   30      6    20       0.8370       0.1082   \n",
       "2010-06-30 21:00:00  0.4480  6.63   30      6    21       0.8370       0.1082   \n",
       "2010-06-30 22:00:00  0.2806  5.74   30      6    22       0.7420       0.1082   \n",
       "2010-06-30 23:00:00  0.0832  4.64   30      6    23       0.6646       0.0832   \n",
       "\n",
       "                     rolling_mean  rolling_std  df_logg_wp  df_logg_ws  \n",
       "date                                                                    \n",
       "2009-07-01 01:00:00      0.085000     0.000000   -2.465104    0.904218  \n",
       "2009-07-01 02:00:00      0.052500     0.045962   -3.912023    0.875469  \n",
       "2009-07-01 03:00:00      0.055000     0.032787   -2.813411    0.920283  \n",
       "2009-07-01 04:00:00      0.052500     0.027234   -3.101093    1.004302  \n",
       "2009-07-01 05:00:00      0.049000     0.024850   -3.352407    1.075002  \n",
       "...                           ...          ...         ...         ...  \n",
       "2010-06-30 19:00:00      0.427900     0.236670   -0.926341    1.981001  \n",
       "2010-06-30 20:00:00      0.422175     0.228757   -0.408570    1.958685  \n",
       "2010-06-30 21:00:00      0.406383     0.212069   -0.802962    1.891605  \n",
       "2010-06-30 22:00:00      0.383200     0.192453   -1.270825    1.747459  \n",
       "2010-06-30 23:00:00      0.355750     0.185924   -2.486508    1.534714  \n",
       "\n",
       "[8759 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ = pd.read_csv('data/df_wf1_out.csv')\n",
    "df = df_.copy()\n",
    "df = df.set_index('date')\n",
    "df = df.sort_index()\n",
    "df.isnull().sum()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wp</th>\n",
       "      <th>ws</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>rolling_max</th>\n",
       "      <th>rolling_min</th>\n",
       "      <th>rolling_mean</th>\n",
       "      <th>rolling_std</th>\n",
       "      <th>df_logg_wp</th>\n",
       "      <th>df_logg_ws</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-07-01 01:00:00</th>\n",
       "      <td>0.085</td>\n",
       "      <td>2.47</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.0850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.465104</td>\n",
       "      <td>0.904218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-01 02:00:00</th>\n",
       "      <td>0.020</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>0.045962</td>\n",
       "      <td>-3.912023</td>\n",
       "      <td>0.875469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-01 03:00:00</th>\n",
       "      <td>0.060</td>\n",
       "      <td>2.51</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>-2.813411</td>\n",
       "      <td>0.920283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-01 04:00:00</th>\n",
       "      <td>0.045</td>\n",
       "      <td>2.73</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>0.027234</td>\n",
       "      <td>-3.101093</td>\n",
       "      <td>1.004302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-01 05:00:00</th>\n",
       "      <td>0.035</td>\n",
       "      <td>2.93</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.024850</td>\n",
       "      <td>-3.352407</td>\n",
       "      <td>1.075002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        wp    ws  day  month  hour  rolling_max  rolling_min  \\\n",
       "date                                                                           \n",
       "2009-07-01 01:00:00  0.085  2.47    1      7     1        0.085        0.085   \n",
       "2009-07-01 02:00:00  0.020  2.40    1      7     2        0.085        0.020   \n",
       "2009-07-01 03:00:00  0.060  2.51    1      7     3        0.085        0.020   \n",
       "2009-07-01 04:00:00  0.045  2.73    1      7     4        0.085        0.020   \n",
       "2009-07-01 05:00:00  0.035  2.93    1      7     5        0.085        0.020   \n",
       "\n",
       "                     rolling_mean  rolling_std  df_logg_wp  df_logg_ws  \n",
       "date                                                                    \n",
       "2009-07-01 01:00:00        0.0850     0.000000   -2.465104    0.904218  \n",
       "2009-07-01 02:00:00        0.0525     0.045962   -3.912023    0.875469  \n",
       "2009-07-01 03:00:00        0.0550     0.032787   -2.813411    0.920283  \n",
       "2009-07-01 04:00:00        0.0525     0.027234   -3.101093    1.004302  \n",
       "2009-07-01 05:00:00        0.0490     0.024850   -3.352407    1.075002  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ws</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-06-30 00:00:00</th>\n",
       "      <td>6.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30 01:00:00</th>\n",
       "      <td>5.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30 02:00:00</th>\n",
       "      <td>4.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30 03:00:00</th>\n",
       "      <td>3.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30 04:00:00</th>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30 05:00:00</th>\n",
       "      <td>3.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30 06:00:00</th>\n",
       "      <td>3.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30 07:00:00</th>\n",
       "      <td>3.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30 08:00:00</th>\n",
       "      <td>3.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30 09:00:00</th>\n",
       "      <td>3.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30 10:00:00</th>\n",
       "      <td>4.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30 11:00:00</th>\n",
       "      <td>5.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30 12:00:00</th>\n",
       "      <td>6.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30 13:00:00</th>\n",
       "      <td>6.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30 14:00:00</th>\n",
       "      <td>7.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30 15:00:00</th>\n",
       "      <td>7.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30 16:00:00</th>\n",
       "      <td>7.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30 17:00:00</th>\n",
       "      <td>7.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30 18:00:00</th>\n",
       "      <td>7.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30 19:00:00</th>\n",
       "      <td>7.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30 20:00:00</th>\n",
       "      <td>7.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30 21:00:00</th>\n",
       "      <td>6.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30 22:00:00</th>\n",
       "      <td>5.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30 23:00:00</th>\n",
       "      <td>4.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ws\n",
       "date                     \n",
       "2010-06-30 00:00:00  6.59\n",
       "2010-06-30 01:00:00  5.50\n",
       "2010-06-30 02:00:00  4.51\n",
       "2010-06-30 03:00:00  3.82\n",
       "2010-06-30 04:00:00  3.55\n",
       "2010-06-30 05:00:00  3.52\n",
       "2010-06-30 06:00:00  3.54\n",
       "2010-06-30 07:00:00  3.47\n",
       "2010-06-30 08:00:00  3.44\n",
       "2010-06-30 09:00:00  3.67\n",
       "2010-06-30 10:00:00  4.28\n",
       "2010-06-30 11:00:00  5.14\n",
       "2010-06-30 12:00:00  6.05\n",
       "2010-06-30 13:00:00  6.85\n",
       "2010-06-30 14:00:00  7.47\n",
       "2010-06-30 15:00:00  7.82\n",
       "2010-06-30 16:00:00  7.81\n",
       "2010-06-30 17:00:00  7.59\n",
       "2010-06-30 18:00:00  7.36\n",
       "2010-06-30 19:00:00  7.25\n",
       "2010-06-30 20:00:00  7.09\n",
       "2010-06-30 21:00:00  6.63\n",
       "2010-06-30 22:00:00  5.74\n",
       "2010-06-30 23:00:00  4.64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train and test split for both wp ans ws columns\n",
    "train_wp = df.iloc[-49::-1,:].sort_index().drop('ws',axis =1)\n",
    "train_ws_exog = df.iloc[-49::-1,1].sort_index().to_frame()\n",
    "#test split\n",
    "test_wp = df.iloc[-1:-25:-1,:].sort_index().drop('ws',axis = 1)\n",
    "val_wp = df.iloc[-25:-49:-1,:].sort_index().drop('ws',axis = 1)\n",
    "test_ws_exog = df.iloc[-1:-25:-1,1].sort_index().to_frame()\n",
    "val_ws_exog = df.iloc[-25:-49:-1,1].sort_index().to_frame()\n",
    "\n",
    "test_ws_exog "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Befor modelling we do need to make time series stationary(we do log part but diff part will be done in the model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-07-01 01:00:00</th>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-01 02:00:00</th>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-01 03:00:00</th>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-01 04:00:00</th>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-01 05:00:00</th>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-29 19:00:00</th>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-29 20:00:00</th>\n",
       "      <td>0.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-29 21:00:00</th>\n",
       "      <td>0.827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-29 22:00:00</th>\n",
       "      <td>0.837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-29 23:00:00</th>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8735 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        wp\n",
       "date                      \n",
       "2009-07-01 01:00:00  0.085\n",
       "2009-07-01 02:00:00  0.020\n",
       "2009-07-01 03:00:00  0.060\n",
       "2009-07-01 04:00:00  0.045\n",
       "2009-07-01 05:00:00  0.035\n",
       "...                    ...\n",
       "2010-06-29 19:00:00  0.737\n",
       "2010-06-29 20:00:00  0.802\n",
       "2010-06-29 21:00:00  0.827\n",
       "2010-06-29 22:00:00  0.837\n",
       "2010-06-29 23:00:00  0.742\n",
       "\n",
       "[8735 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_wp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#sarimax = pm.AutoARIMA(trace=True, supress_warnings=True,m=24)#m=12 because of seasonality we need to change according to that\n",
    "#sarimax.fit(train_wp.values)\n",
    "#sarimax_forecast = sarimax.predict(24)#24 is len(test). This model predict 24 times after training set which is test set\n",
    "#sf = np.exp(sarimax_forecast)\n",
    "#In sample prediction \n",
    "#predictions =np.exp(sarimax.predict_in_sample())\n",
    "#mae =mean_absolute_error(np.exp(sarimax_forecast),np.exp(test_wp))\n",
    "sarimax_pipeline_exog = Pipeline([  #The boxcox transform has been removed because it messes with the exogenous input\n",
    "    ('arima', pm.AutoARIMA(trace=True,\n",
    "                           suppress_warnings=True,\n",
    "                           m=24, \n",
    "                           method='nm',\n",
    "                           maxiter=1,\n",
    "                           \n",
    "                          )\n",
    "    )\n",
    "])\n",
    "\n",
    "sarimax_pipeline_exog.fit(train_wp,train_ws_exog) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple one-step forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sarimax_forecast_one_step_refit = []\n",
    "#sarimax.fit(train)        # Note that we're fitting the autoArima again. This is to make sure you always \n",
    "#for i in np.arange(0,24): # run it before the rest of the loop\n",
    "    #next_step_forecast = sarimax.predict(1)[0]\n",
    "    #sarimax_forecast_one_step_refit.append(next_step_forecast)\n",
    "    #sarimax = sarimax.update(test[i:i+1])\n",
    "#mean_absolute_error(np.exp(sarimax_forecast_one_step_refit),np.exp(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi step forcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#orecast = np.exp(sarimax.predict(3*12,emissions_test[:]))#3*12 is the size of test considering seasonality\n",
    "#mae = mean_absolute_error(forecast,emissions_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multiple one-step forecasts with exog input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sarimax_forecast_one_step_refit = []\n",
    "sarimax.fit(train_wp,train_ws_exog) \n",
    "for i in np.arange(0,len(test_ws_exog)): \n",
    "    next_step_forecast = sarimax.predict(1,test_ws_exog[i:i+1])[0]\n",
    "    sarimax_forecast_one_step_refit.append(next_step_forecast)\n",
    "    sarimax = sarimax.update(test_wp[i:i+1],test_ws_exog[i:i+1])\n",
    "#MAE\n",
    "sarimax_forecast_one_step_refit_exp = np.exp(sarimax_forecast_one_step_refit)\n",
    "mae = mean_absolute_error(sarimax_forecast_one_step_refit_exp,test_ws_exog)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boxcox Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-07-01 01:00:00</th>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-01 02:00:00</th>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-01 03:00:00</th>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-01 04:00:00</th>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-01 05:00:00</th>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-29 19:00:00</th>\n",
       "      <td>0.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-29 20:00:00</th>\n",
       "      <td>0.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-29 21:00:00</th>\n",
       "      <td>0.827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-29 22:00:00</th>\n",
       "      <td>0.837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-29 23:00:00</th>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8735 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        wp\n",
       "date                      \n",
       "2009-07-01 01:00:00  0.085\n",
       "2009-07-01 02:00:00  0.020\n",
       "2009-07-01 03:00:00  0.060\n",
       "2009-07-01 04:00:00  0.045\n",
       "2009-07-01 05:00:00  0.035\n",
       "...                    ...\n",
       "2010-06-29 19:00:00  0.737\n",
       "2010-06-29 20:00:00  0.802\n",
       "2010-06-29 21:00:00  0.827\n",
       "2010-06-29 22:00:00  0.837\n",
       "2010-06-29 23:00:00  0.742\n",
       "\n",
       "[8735 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima.pipeline import Pipeline\n",
    "from pmdarima.preprocessing import BoxCoxEndogTransformer\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "mod = SARIMAX(train_wp, exog=train_ws_exog, trend='n', order=(0,1,0), seasonal_order=(1,1,1,52))\n",
    "results = mod.fit()\n",
    "\n",
    "#sarimax_predictions = np.exp(sarimax_results.predict())[24:] # grab the prediction from our model and undo the log transform using exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = results.predict(test_wp, exog=test_ws_exog, dynamic= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing stepwise search to minimize aic\n",
      " ARIMA(2,1,2)(1,0,1)[24] intercept   : AIC=-19328.475, Time=21.29 sec\n",
      " ARIMA(0,1,0)(0,0,0)[24] intercept   : AIC=-19056.328, Time=0.96 sec\n",
      " ARIMA(1,1,0)(1,0,0)[24] intercept   : AIC=-19095.212, Time=18.39 sec\n",
      " ARIMA(0,1,1)(0,0,1)[24] intercept   : AIC=-19097.923, Time=18.92 sec\n",
      " ARIMA(0,1,0)(0,0,0)[24]             : AIC=-18817.984, Time=1.55 sec\n",
      " ARIMA(2,1,2)(0,0,1)[24] intercept   : AIC=-19348.811, Time=19.57 sec\n",
      " ARIMA(2,1,2)(0,0,0)[24] intercept   : AIC=-19349.902, Time=2.30 sec\n",
      " ARIMA(2,1,2)(1,0,0)[24] intercept   : AIC=-19348.967, Time=20.78 sec\n",
      " ARIMA(1,1,2)(0,0,0)[24] intercept   : AIC=-19164.396, Time=2.25 sec\n",
      " ARIMA(2,1,1)(0,0,0)[24] intercept   : AIC=-19137.295, Time=1.74 sec\n",
      " ARIMA(3,1,2)(0,0,0)[24] intercept   : AIC=-19047.790, Time=2.39 sec\n",
      " ARIMA(2,1,3)(0,0,0)[24] intercept   : AIC=-19365.308, Time=2.97 sec\n",
      " ARIMA(2,1,3)(1,0,0)[24] intercept   : AIC=-19372.398, Time=21.65 sec\n",
      " ARIMA(2,1,3)(2,0,0)[24] intercept   : AIC=-19383.409, Time=95.66 sec\n",
      " ARIMA(2,1,3)(2,0,1)[24] intercept   : AIC=-19383.406, Time=96.57 sec\n",
      " ARIMA(2,1,3)(1,0,1)[24] intercept   : AIC=-19375.725, Time=26.58 sec\n",
      " ARIMA(1,1,3)(2,0,0)[24] intercept   : AIC=-19190.298, Time=96.98 sec\n",
      " ARIMA(2,1,2)(2,0,0)[24] intercept   : AIC=-19339.337, Time=95.42 sec\n",
      " ARIMA(3,1,3)(2,0,0)[24] intercept   : AIC=-19378.616, Time=105.52 sec\n",
      " ARIMA(2,1,4)(2,0,0)[24] intercept   : AIC=-19397.434, Time=108.02 sec\n",
      " ARIMA(2,1,4)(1,0,0)[24] intercept   : AIC=-19398.420, Time=22.65 sec\n",
      " ARIMA(2,1,4)(0,0,0)[24] intercept   : AIC=-19396.444, Time=3.80 sec\n",
      " ARIMA(2,1,4)(1,0,1)[24] intercept   : AIC=-19393.923, Time=29.14 sec\n",
      " ARIMA(2,1,4)(0,0,1)[24] intercept   : AIC=-19398.370, Time=25.98 sec\n",
      " ARIMA(2,1,4)(2,0,1)[24] intercept   : AIC=-19396.531, Time=108.82 sec\n",
      " ARIMA(1,1,4)(1,0,0)[24] intercept   : AIC=-19253.618, Time=19.92 sec\n",
      " ARIMA(3,1,4)(1,0,0)[24] intercept   : AIC=-19418.274, Time=24.88 sec\n",
      " ARIMA(3,1,4)(0,0,0)[24] intercept   : AIC=-19415.980, Time=4.42 sec\n",
      " ARIMA(3,1,4)(2,0,0)[24] intercept   : AIC=-19422.230, Time=112.21 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-195b9e609e4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m ])\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0msarimax_pipeline_exog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_wp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_ws_exog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;31m#predict in sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0msarimax_pipeline_exog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_in_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ws_exog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/pmdarima/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y, exogenous, **fit_kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;31m# Now fit the final estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnamed_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexogenous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/pmdarima/arima/auto.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y, exogenous, **fit_args)\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mout_of_sample_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_of_sample_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0mscoring_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscoring_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_intercept\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             sarimax_kwargs=sarimax_kwargs, **fit_args)\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/pmdarima/arima/auto.py\u001b[0m in \u001b[0;36mauto_arima\u001b[0;34m(y, exogenous, start_p, d, start_q, max_p, max_d, max_q, start_P, D, start_Q, max_P, max_D, max_Q, max_order, m, seasonal, stationary, information_criterion, alpha, test, seasonal_test, stepwise, n_jobs, start_params, trend, method, maxiter, offset_test_args, seasonal_test_args, suppress_warnings, error_action, trace, random, random_state, n_fits, return_valid_fits, out_of_sample_size, scoring, scoring_args, with_intercept, sarimax_kwargs, **fit_args)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;31m# do the step-through...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m         \u001b[0msorted_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstepwise_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve_stepwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_return_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_valid_fits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/pmdarima/arima/_auto_solvers.py\u001b[0m in \u001b[0;36msolve_stepwise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mQ\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_Q\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_k\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m                 \u001b[0mQ\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/pmdarima/arima/_auto_solvers.py\u001b[0m in \u001b[0;36m_do_fit\u001b[0;34m(self, order, seasonal_order, constant)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mseasonal_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseasonal_order\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                 with_intercept=constant)\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;31m# use the orders as a key to be hashed for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/pmdarima/arima/_auto_solvers.py\u001b[0m in \u001b[0;36m_fit_candidate_model\u001b[0;34m(x, xreg, order, seasonal_order, start_params, trend, method, maxiter, fit_params, suppress_warnings, trace, error_action, out_of_sample_size, scoring, scoring_args, with_intercept, information_criterion, do_root_test, **kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexogenous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;31m# for non-stationarity errors or singular matrices, return None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/pmdarima/arima/arima.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y, exogenous, **fit_args)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;31m# Internal call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexogenous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;31m# now make a forecast if we're validating to compute the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/pmdarima/arima/arima.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, y, exogenous, **fit_args)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m                 \u001b[0mfit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marima_res_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fit_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0mfit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marima_res_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fit_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/pmdarima/arima/arima.py\u001b[0m in \u001b[0;36m_fit_wrapper\u001b[0;34m()\u001b[0m\n\u001b[1;32m    387\u001b[0m                                     \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_maxiter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                                     \u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m                                     **fit_args)\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;31m# sometimes too many warnings...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, start_params, transformed, includes_fixed, cov_type, cov_kwds, method, maxiter, full_output, disp, callback, return_params, optim_score, optim_complex_step, optim_hessian, flags, low_memory, **kwargs)\u001b[0m\n\u001b[1;32m    677\u001b[0m                 \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmooth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             res = func(mlefit.params, transformed=False, includes_fixed=False,\n\u001b[0;32m--> 679\u001b[0;31m                        cov_type=cov_type, cov_kwds=cov_kwds)\n\u001b[0m\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\u001b[0m in \u001b[0;36msmooth\u001b[0;34m(self, params, transformed, includes_fixed, complex_step, cov_type, cov_kwds, return_ssm, results_class, results_wrapper_class, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m         return self._wrap_results(params, result, return_ssm, cov_type,\n\u001b[1;32m    840\u001b[0m                                   \u001b[0mcov_kwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m                                   results_wrapper_class)\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m     \u001b[0m_loglike_param_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'transformed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'includes_fixed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'complex_step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\u001b[0m in \u001b[0;36m_wrap_results\u001b[0;34m(self, params, result, return_raw, cov_type, cov_kwds, results_class, wrapper_class)\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0mwrapper_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_res_classes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mresult_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/statsmodels/tsa/statespace/sarimax.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, params, filter_results, cov_type, **kwargs)\u001b[0m\n\u001b[1;32m   1796\u001b[0m                  **kwargs):\n\u001b[1;32m   1797\u001b[0m         super(SARIMAXResults, self).__init__(model, params, filter_results,\n\u001b[0;32m-> 1798\u001b[0;31m                                              cov_type, **kwargs)\n\u001b[0m\u001b[1;32m   1799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1800\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf_resid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m  \u001b[0;31m# attribute required for wald tests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, params, results, cov_type, cov_kwds, **kwargs)\u001b[0m\n\u001b[1;32m   2249\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2250\u001b[0m             self._get_robustcov_results(cov_type=cov_type, use_self=True,\n\u001b[0;32m-> 2251\u001b[0;31m                                         **cov_kwds)\n\u001b[0m\u001b[1;32m   2252\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinAlgError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2253\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\u001b[0m in \u001b[0;36m_get_robustcov_results\u001b[0;34m(self, cov_type, **kwargs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m                                                 approx_type=approx_type_str)\n\u001b[1;32m   2481\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'opg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2482\u001b[0;31m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov_params_default\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcov_params_opg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2483\u001b[0m             res.cov_kwds['description'] = descriptions['OPG'].format(\n\u001b[1;32m   2484\u001b[0m                                                 approx_type=approx_type_str)\n",
      "\u001b[0;32mpandas/_libs/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\u001b[0m in \u001b[0;36mcov_params_opg\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2602\u001b[0m         \"\"\"\n\u001b[1;32m   2603\u001b[0m         return self._cov_params_opg(self._cov_approx_complex_step,\n\u001b[0;32m-> 2604\u001b[0;31m                                     self._cov_approx_centered)\n\u001b[0m\u001b[1;32m   2605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2606\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcache_readonly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\u001b[0m in \u001b[0;36m_cov_params_opg\u001b[0;34m(self, approx_complex_step, approx_centered)\u001b[0m\n\u001b[1;32m   2580\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincludes_fixed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2581\u001b[0m             \u001b[0mapprox_complex_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapprox_complex_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2582\u001b[0;31m             approx_centered=approx_centered)\n\u001b[0m\u001b[1;32m   2583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_params\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\u001b[0m in \u001b[0;36m_hessian_opg\u001b[0;34m(self, params, **kwargs)\u001b[0m\n\u001b[1;32m   1488\u001b[0m         \u001b[0minformation\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m         \"\"\"\n\u001b[0;32m-> 1490\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopg_information_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m     def _hessian_finite_difference(self, params, approx_centered=False,\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\u001b[0m in \u001b[0;36mopg_information_matrix\u001b[0;34m(self, params, transformed, includes_fixed, approx_complex_step, **kwargs)\u001b[0m\n\u001b[1;32m   1180\u001b[0m                                    \u001b[0mincludes_fixed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mincludes_fixed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                                    \u001b[0mapprox_complex_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapprox_complex_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m                                    **kwargs).transpose()\n\u001b[0m\u001b[1;32m   1183\u001b[0m         return (\n\u001b[1;32m   1184\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_obs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\u001b[0m in \u001b[0;36mscore_obs\u001b[0;34m(self, params, method, transformed, includes_fixed, approx_complex_step, approx_centered, **kwargs)\u001b[0m\n\u001b[1;32m   1395\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'complex_step'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m             score = approx_fprime_cs(params, self.loglikeobs, epsilon=epsilon,\n\u001b[0;32m-> 1397\u001b[0;31m                                      kwargs=kwargs)\n\u001b[0m\u001b[1;32m   1398\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'approx'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m             score = approx_fprime(params, self.loglikeobs, kwargs=kwargs,\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/statsmodels/tools/numdiff.py\u001b[0m in \u001b[0;36mapprox_fprime_cs\u001b[0;34m(x, f, epsilon, args, kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;31m# TODO: see if this can be vectorized, but usually dim is small\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     partials = [f(x+ih, *args, **kwargs).imag / epsilon[i]\n\u001b[0;32m--> 202\u001b[0;31m                 for i, ih in enumerate(increments)]\n\u001b[0m\u001b[1;32m    203\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/statsmodels/tools/numdiff.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;31m# TODO: see if this can be vectorized, but usually dim is small\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     partials = [f(x+ih, *args, **kwargs).imag / epsilon[i]\n\u001b[0;32m--> 202\u001b[0;31m                 for i, ih in enumerate(increments)]\n\u001b[0m\u001b[1;32m    203\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/statsmodels/tsa/statespace/mlemodel.py\u001b[0m in \u001b[0;36mloglikeobs\u001b[0;34m(self, params, transformed, includes_fixed, complex_step, **kwargs)\u001b[0m\n\u001b[1;32m    936\u001b[0m                     complex_step=complex_step)\n\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mssm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloglikeobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplex_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcomplex_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msimulation_smoother\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimulation_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/statsmodels/tsa/statespace/kalman_filter.py\u001b[0m in \u001b[0;36mloglikeobs\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0;34m'conserve_memory'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m                 MEMORY_CONSERVE ^ (MEMORY_NO_FORECAST | MEMORY_NO_LIKELIHOOD))\n\u001b[0;32m-> 1044\u001b[0;31m         \u001b[0mkfilter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0mllf_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkfilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloglikelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         loglikelihood_burn = kwargs.get('loglikelihood_burn',\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/statsmodels/tsa/statespace/kalman_filter.py\u001b[0m in \u001b[0;36m_filter\u001b[0;34m(self, filter_method, inversion_method, stability_method, conserve_memory, filter_timing, tolerance, loglikelihood_burn, complex_step)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0;31m# Run the filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m         \u001b[0mkfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkfilter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# find the best transformation to unskew our distribution.\n",
    "from pmdarima.pipeline import Pipeline\n",
    "from pmdarima.preprocessing import BoxCoxEndogTransformer\n",
    "\n",
    "#sarimax_pipeline = Pipeline([\n",
    " #   ('boxcox', BoxCoxEndogTransformer(lmbda2=1)),\n",
    "  #  ('arima', pm.AutoARIMA(trace=True,\n",
    "   #                        suppress_warnings=True,\n",
    "    #                       m=24, \n",
    "     #                      method='nm', # More data means longer let's use 'nm' to make it faster\n",
    "      #                     maxiter=20, # Let's also reduce maxiter to make it faster.\n",
    "       #                    \n",
    "        #                  )\n",
    "    #)\n",
    "#])\n",
    "\n",
    "#sarimax_pipeline.fit(train)\n",
    "#mean_absolute_error(sarimax_pipeline.predict(24),test)\n",
    "\n",
    "#find the best transformation to unskew our distribution but with exogenous data\n",
    "#(we need to do same preprocessing for exogenous data)\n",
    "\n",
    "sarimax_pipeline_exog = Pipeline([  #The boxcox transform has been removed because it messes with the exogenous input\n",
    "    ('arima', pm.AutoARIMA(trace=True,\n",
    "                           suppress_warnings=True,\n",
    "                           m=24,\n",
    "                           method='nm',\n",
    "                           maxiter=20,\n",
    "                           \n",
    "                          )\n",
    "    )\n",
    "])\n",
    "\n",
    "sarimax_pipeline_exog.fit(train_wp,train_ws_exog)\n",
    "#predict in sample\n",
    "sarimax_pipeline_exog.predict_in_sample(train_ws_exog)\n",
    "#predict test\n",
    "sarimax_pipeline_exog.predict(24,test_ws_exog)\n",
    "#predict test with confident interval\n",
    "preds = sarimax_pipeline_exog.predict(24,test_ws_exog[:24], return_conf_int=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't use starred expression here (<ipython-input-31-a32bbec234b3>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-31-a32bbec234b3>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't use starred expression here\n"
     ]
    }
   ],
   "source": [
    "from numpy import asarray\n",
    "from numpy import savetxt\n",
    "pred_test = sarimax_pipeline_exog.predict(24,test_ws_exog[:24], return_conf_int=True)\n",
    "pred_test[0]\n",
    "savetxt('pred_wf2.csv', pred_test[0], delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f21c202c7b8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(test_wp, label='original')\n",
    "plt.plot(test_wp.index, pred_test[0], label='sarimax_exog')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some functions usefull for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_target(series_, number_of_periods_ahead):\n",
    "    \"\"\" \n",
    "    takes a series, turned it into a dataframe, and adds a new column called target\n",
    "    This column is the input series, lagged number_of_periods_ahead into the future\n",
    "    \"\"\"\n",
    "    \n",
    "    # make a copy \n",
    "    series_ = series_.copy()\n",
    "    series_.name = 'customers'\n",
    "    \n",
    "    # make a dataframe from the series\n",
    "    df_ = pd.DataFrame(series_)\n",
    "    \n",
    "    # the target column will be the input series, lagged into the future\n",
    "    df_['target'] = series_.shift(-number_of_periods_ahead)\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_last_day(df_):\n",
    "    \n",
    "    \"\"\"\n",
    "    takes a dataset which has the target and features built \n",
    "    and separates it into the last day\n",
    "    \"\"\"\n",
    "    # take the last period \n",
    "    last_period = df_.iloc[-1]\n",
    "    \n",
    "    # the last period is now a series, so it's name will be the timestamp\n",
    "    training_data = df_.loc[df_.index < last_period.name]\n",
    "\n",
    "    return last_period, training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_some_features(df_, num_periods_lagged=1, num_periods_diffed=0, weekday=False, month=False, rolling=[], holidays=False): \n",
    "    \"\"\"\n",
    "    Builds some features by calculating differences between periods  \n",
    "    \"\"\"\n",
    "    # make a copy \n",
    "    df_ = df_.copy()\n",
    "        \n",
    "    # for a few values, get the lags  \n",
    "    for i in range(1, num_periods_lagged+1):\n",
    "        # make a new feature, with the lags in the observed values column\n",
    "        df_['lagged_%s' % str(i)] = df_['customers'].shift(i)\n",
    "        \n",
    "    # for a few values, get the diffs  \n",
    "    for i in range(1, num_periods_diffed+1):\n",
    "        # make a new feature, with the lags in the observed values column\n",
    "        df_['diff_%s' % str(i)] = df_['customers'].diff(i)\n",
    "    \n",
    "    for stat in rolling:\n",
    "        df_['rolling_%s'%str(stat)] = df_['customers'].rolling('7D').aggregate(stat)\n",
    "        \n",
    "    if weekday == True:\n",
    "        df_['sin_weekday'] = np.sin(2*np.pi*df_.index.weekday/7)\n",
    "        df_['cos_weekday'] = np.sin(2*np.pi*df_.index.weekday/7)\n",
    "        \n",
    "    if month == True:\n",
    "        df_['sin_month'] = np.sin(2*np.pi*df_.index.month/12)\n",
    "        df_['cos_month'] = np.sin(2*np.pi*df_.index.month/12)\n",
    "        \n",
    "    if holidays == True:\n",
    "        holidays = df_[((df_.index.month==12) & (df_.index.day==25))\n",
    "              |((df_.index.month==1) & (df_.index.day==1))].customers\n",
    "        df_['holidays'] = holidays + 1\n",
    "        df_['holidays'] = df_['holidays'].fillna(0)\n",
    "    \n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_train_and_test_set(last_period_, training_data_, target='target'): \n",
    "    \n",
    "    \"\"\" \n",
    "    separates training and test set (clue was in the name, really... )\n",
    "    Ok, we were lazy and left the target hardcoded as 'target'. Shame on us. \n",
    "    \"\"\"\n",
    "    \n",
    "    # anything that isn't a target is a feature \n",
    "    features = [feature for feature in training_data_.columns if feature != target]\n",
    "    \n",
    "    # adding a sneaky little dropna to avoid the missing data problem above \n",
    "    X_train = training_data_.dropna()[features]\n",
    "    y_train = training_data_.dropna()[target]\n",
    "    \n",
    "    X_last_period = last_period_[features]\n",
    "    \n",
    "    return X_train, y_train, X_last_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_prediction(series_, number_of_periods_ahead, num_periods_lagged, num_periods_diffed, weekday, month, rolling, holidays):\n",
    "    \n",
    "    \"\"\" \n",
    "    Wrapper to go from the original series to X_train, y_train, X_last_period \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # build the target \n",
    "    data_with_target = build_target(series_, \n",
    "                                    number_of_periods_ahead)\n",
    "    \n",
    "    # build the features \n",
    "    data_with_target_and_features = build_some_features(data_with_target, \n",
    "                                                        num_periods_lagged=num_periods_lagged,\n",
    "                                                       num_periods_diffed=num_periods_diffed,\n",
    "                                                       weekday=weekday,\n",
    "                                                       month=month,\n",
    "                                                       rolling=rolling,\n",
    "                                                       holidays=holidays)\n",
    "    # separate train and test data \n",
    "    last_period, training_data = separate_last_day(data_with_target_and_features)\n",
    "\n",
    "    # separate X_train, y_train, and X_test \n",
    "    X_train, y_train, X_last_period = separate_train_and_test_set(last_period, \n",
    "                                                           training_data, \n",
    "                                                           target='target')\n",
    "    \n",
    "    # return ALL OF THE THINGS! (well, actually just the ones we need)\n",
    "    return X_train, y_train, X_last_period "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_period_n(series_, model, number_of_periods_ahead, num_periods_lagged, num_periods_diffed, weekday, month, rolling, holidays): \n",
    "    \n",
    "        X_train, y_train, X_last_period = prepare_for_prediction(series_, \n",
    "                                                             number_of_periods_ahead, \n",
    "                                                             num_periods_lagged,\n",
    "                                                             num_periods_diffed,\n",
    "                                                             weekday,\n",
    "                                                             month,\n",
    "                                                             rolling,\n",
    "                                                             holidays)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        return model.predict(X_last_period.values.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_n_periods(series_, n_periods, model, num_periods_lagged, num_periods_diffed=0, weekday=False, month=False,rolling=[], holidays=False): \n",
    "    predictions = []\n",
    "\n",
    "    for period_ahead in range(1, n_periods+1):\n",
    "        pred = predict_period_n(series_=series_, \n",
    "                                model=model, \n",
    "                                number_of_periods_ahead=period_ahead, \n",
    "                                num_periods_lagged=num_periods_lagged,\n",
    "                                num_periods_diffed=num_periods_diffed,\n",
    "                                weekday=weekday,\n",
    "                                month=month,\n",
    "                                rolling=rolling,\n",
    "                                holidays=holidays)\n",
    "        \n",
    "        predictions.append(pred[0])\n",
    "        \n",
    "    return predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation, which model parameters are better "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "788dccd388ca4b398ef3dc0c22bb1916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Wrong number of items passed 10, placement implies 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2888\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2889\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2890\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'target'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3565\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3566\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2890\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2891\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'target'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d057ff9a20f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m                       \u001b[0mweekday\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weekday'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                       \u001b[0mmonth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'month'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                       \u001b[0mrolling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                     )\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-4d938cbc7011>\u001b[0m in \u001b[0;36mpredict_n_periods\u001b[0;34m(series_, n_periods, model, num_periods_lagged, num_periods_diffed, weekday, month, rolling, holidays)\u001b[0m\n\u001b[1;32m     11\u001b[0m                                 \u001b[0mmonth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                 \u001b[0mrolling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrolling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                                 holidays=holidays)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-09da119b2078>\u001b[0m in \u001b[0;36mpredict_period_n\u001b[0;34m(series_, model, number_of_periods_ahead, num_periods_lagged, num_periods_diffed, weekday, month, rolling, holidays)\u001b[0m\n\u001b[1;32m      8\u001b[0m                                                              \u001b[0mmonth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                                              \u001b[0mrolling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                                                              holidays)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-3f07af540cec>\u001b[0m in \u001b[0;36mprepare_for_prediction\u001b[0;34m(series_, number_of_periods_ahead, num_periods_lagged, num_periods_diffed, weekday, month, rolling, holidays)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# build the target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     data_with_target = build_target(series_, \n\u001b[0;32m---> 10\u001b[0;31m                                     number_of_periods_ahead)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# build the features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-4f539331a4f2>\u001b[0m in \u001b[0;36mbuild_target\u001b[0;34m(series_, number_of_periods_ahead)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# the target column will be the input series, lagged into the future\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mdf_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseries_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnumber_of_periods_ahead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3038\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3039\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3040\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3116\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3117\u001b[0;31m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3119\u001b[0m         \u001b[0;31m# check if we are modifying a copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3566\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3567\u001b[0m             \u001b[0;31m# This item wasn't present, just insert at end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3568\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3569\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_reshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m         \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblkno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_fast_count_smallints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblknos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[1;32m   2712\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatetimeArray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2714\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/hack03/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_ndim\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             raise ValueError(\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0;34mf\"Wrong number of items passed {len(self.values)}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0;34mf\"placement implies {len(self.mgr_locs)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: Wrong number of items passed 10, placement implies 1"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "param_grid = {'model': [ GradientBoostingRegressor()], \n",
    "              'num_periods_lagged':np.arange(1,3),\n",
    "              'num_periods_diffed':[0],\n",
    "              'weekday':[True,False],\n",
    "              'month':[True,False],\n",
    "              'holidays': [True],\n",
    "              'rolling' : [[np.mean,np.min,np.max,np.std]]\n",
    "             }\n",
    "\n",
    "grid = ParameterGrid(param_grid)\n",
    "\n",
    "###Seperate train test and validation\n",
    "error_lst = []\n",
    "\n",
    "for params in tqdm(grid):\n",
    "    predictions = predict_n_periods(series_=train_wp, \n",
    "                    n_periods=24, \n",
    "                      model=params['model'], \n",
    "                      num_periods_lagged=params['num_periods_lagged'],\n",
    "                      num_periods_diffed=params['num_periods_diffed'],\n",
    "                      weekday=params['weekday'],\n",
    "                      month=params['month'],\n",
    "                      rolling=[np.mean,np.max,np.min]\n",
    "                    )\n",
    "\n",
    "    error_lst.append(mean_absolute_error(val,predictions))\n",
    "pd.Series(error_lst).idxmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding train and validation\n",
    "train = train.append(val)\n",
    "\n",
    "predictions = predict_n_periods(series_=train, \n",
    "                  n_periods=len(test), \n",
    "                  model=GradientBoostingRegressor(), \n",
    "                  num_periods_lagged=2,\n",
    "                  num_periods_diffed=0,\n",
    "                  weekday=True,\n",
    "                  month=False,\n",
    "                  rolling=[np.mean,np.min,np.max,np.std],\n",
    "                  holidays=True\n",
    "                  )\n",
    "mean_absolute_error(test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is not good at all. We will have data lekage with this kind of cross validation we need to use other methods \n",
    "#Import TimeSeriesSplit\n",
    "#from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Create time-series cross-validation object\n",
    "#cv = KFold(n_splits=10)\n",
    "\n",
    "# Iterate through CV splits\n",
    "#fig, ax = plt.subplots()\n",
    "#for ii, (tr, tt) in enumerate(cv.split(store_train/store_train.max())):\n",
    "    # Plot the training data on each iteration, to see the behavior of the CV\n",
    "    #ax.plot(store_train.index[tr], ii + store_train[tr]/store_train.max(), color='green')\n",
    "    #ax.plot(store_train.index[tt], ii + store_train[tt]/store_train.max(), color='orange')\n",
    "\n",
    "#ax.set(title='Training data on each CV iteration', ylabel='CV iteration')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expanding Window cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the fold for validation are similar to k-fold cross validation but it doese not consider the training set after the validation\n",
    "#set so we do not have data lekage in this case\n",
    "#This is better than k-fold...\n",
    "\n",
    "# Import TimeSeriesSplit\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Create time-series cross-validation object\n",
    "cv = TimeSeriesSplit(n_splits=20)\n",
    "\n",
    "# Iterate through CV splits\n",
    "fig, ax = plt.subplots()\n",
    "for ii, (tr, tt) in enumerate(cv.split(store_train/store_train.max())):\n",
    "    # Plot the training data on each iteration, to see the behavior of the CV\n",
    "    ax.plot(store_train.index[tr], ii + store_train[tr]/store_train.max(), color='green')\n",
    "    ax.plot(store_train.index[tt], ii + store_train[tt]/store_train.max(), color='orange')\n",
    "\n",
    "ax.set(title='Training data on each CV iteration', ylabel='CV iteration')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the modell using expandig windows cross validation and see with different train and validation this cross validation consider,\n",
    "#what happend to the mean absolute error\n",
    "X = store_train\n",
    "\n",
    "# Iterate through CV splits\n",
    "n_splits = 20\n",
    "cv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "idx_lst = []\n",
    "values_lst = []\n",
    "\n",
    "for ii, (tr, tt) in tqdm(enumerate(cv.split(X))):\n",
    "    # Fit the model on training data and collect the coefficients\n",
    "    train = X[tr]\n",
    "    test = X[tt]\n",
    "    idx_lst.append(X.index[tt][0])\n",
    "    error_lst = []\n",
    "    predictions = predict_n_periods(series_=train, \n",
    "                    n_periods=len(test), \n",
    "                    model=GradientBoostingRegressor(n_estimators=20, learning_rate=0.5), \n",
    "                    num_periods_lagged=2,\n",
    "                    num_periods_diffed=0,\n",
    "                    weekday=True,\n",
    "                    month=False)\n",
    "    values_lst.append(mean_absolute_error(test,predictions))\n",
    "    pd.Series(values_lst, index=idx_lst).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: explorer.exe.: command not found\r\n"
     ]
    }
   ],
   "source": [
    "! explorer.exe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!explorer.exe ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
