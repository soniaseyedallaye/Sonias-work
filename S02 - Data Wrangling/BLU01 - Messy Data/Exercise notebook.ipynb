{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1b6b75485105e36c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# BLU01 - Exercises Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Note**\n",
    "\n",
    "Attention Windows users: The grader will run on Linux, and using power shell statements will not work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0240afddd4fae69d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import chardet\n",
    "import hashlib # for grading purposes\n",
    "import math\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-93e0b4e1a40ebaaa",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Q1: Use a shell command to count lines\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-05a3d2245d57305d",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\r\n"
     ]
    }
   ],
   "source": [
    "# Use the file data/exercises/surfing.txt\n",
    "# Start by counting the total lines and add the total to the variable count_total.\n",
    "! wc -l < data/exercises/surfing.txt\n",
    "count_total = 33\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2e69c6137e73d90c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = 'c6f3ac57944a531490cd39902d0f777715fd005efac9a30622d5f5205e7f6894'\n",
    "assert hashlib.sha256(str(count_total).encode()).hexdigest() == expected_hash, \"count_total is wrong\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now store in 2 variables the first third and the last third of the lines existent on that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-14cf2619322a8763",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# NOT GRADED optional exercise!!\n",
    "# Now add the first third and the last third of the lines to the variables first_third and last_third. \n",
    "# Make it work to any files using count_total/3 for instance in the bash commands\n",
    "first_third = ! head -11 data/exercises/surfing.txt\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "last_third = ! tail -11 data/exercises/surfing.txt\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "assert first_third[-1][0] == 's'\n",
    "assert last_third[0][0] == 'l'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a6556340d1db98d7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Test the `first_third` and `last_third` exercise by running the following (ungraded) asserts.\n",
    "\n",
    "```\n",
    "assert first_third[-1][0] == 's'\n",
    "assert last_third[0][0] == 'l'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e27cb8588bb5fd40",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Q2: Read a file with specific delimiter\n",
    "\n",
    "Read file **data/exercises/surfing_sessions.csv** into a pandas DataFrame.\n",
    "\n",
    "First, you should preview the file using a shell command in order to find out the used delimiter, and other properties of this file.\n",
    "\n",
    "Then, you should use function read_csv to read the data into a DataFrame. The resulting DataFrame should have the last column as index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-942e0590467e20d9",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "surfer;wave_power;location;visit_id\n",
      "3;37,6;Rocky Point;146097\n",
      "3;5,7;Chuns;146087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of           surfer  wave_power            location\n",
       "visit_id                                        \n",
       "146097         3       37.60         Rocky Point\n",
       "146087         3        5.70               Chuns\n",
       "130395         3        5.00    Noronha(Cacimba)\n",
       "130363         3        5.00         Rocky Point\n",
       "130362         3       11.30  Noronha(Conceicao)\n",
       "...          ...         ...                 ...\n",
       "157350         2       20.10             Poily’s\n",
       "157348         2       15.10         Rocky Point\n",
       "153466         2        7.43             Poily’s\n",
       "153464         2       45.10             Haleiwa\n",
       "153463         2       31.90          Army Beach\n",
       "\n",
       "[108 rows x 3 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a shell command to preview the data\n",
    "! wc -l < data/exercises/surfing_sessions.csv\n",
    "! head -3 data/exercises/surfing_sessions.csv\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "\n",
    "# Use function read_csv to read the data into a DataFrame\n",
    "df2 = pd.read_csv(\"data/exercises/surfing_sessions.csv\",sep = ';',decimal = ',',index_col = 'visit_id')\n",
    "#df2 = df2.reset_index().set_index('visit_id',drop = True)\n",
    "df2.head\n",
    "#df2.loc[126903, 'location']\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0c275c9acaa9c74d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert df2.loc[126903, 'location'] == 'Pupukea', \"df3 data is wrong\"\n",
    "assert set(df2.columns) == {'location', 'surfer', 'wave_power'}, \"df3 data is wrong\"\n",
    "assert len(df2) == 108, \"df3 data is wrong\"\n",
    "assert df2.index[0] == 146097, \"df3 data is wrong\"\n",
    "\n",
    "expected_hash = 'a27dd8b953f484c0d74059da102e4b8e513630292de5d17ff5585fc6743d62f0'\n",
    "assert hashlib.sha256(df2.index.name.encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f6f9efef818e4a83",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Q3: Read a csv file with problems\n",
    "\n",
    "Read file **data/exercises/surfing_sessions_w_problems.csv** using function `read_csv`. Pay attention to the following:\n",
    "* you might find some trouble when reading the file, at first, then just ignore the problems ;)\n",
    "* use the first column as index\n",
    "* there are some inputs in the file that should be interpreted as NaN, make sure you select the right one when reading the file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2771b707556c08d2",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 9: expected 4 fields, saw 6\\nSkipping line 13: expected 4 fields, saw 5\\nSkipping line 18: expected 4 fields, saw 5\\nSkipping line 19: expected 4 fields, saw 6\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surfer</th>\n",
       "      <th>wave_power</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146097</th>\n",
       "      <td>3</td>\n",
       "      <td>37.6</td>\n",
       "      <td>Rocky Point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146087</th>\n",
       "      <td>3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>Chuns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130395</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Noronha(Cacimba)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130363</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Rocky Point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130362</th>\n",
       "      <td>3</td>\n",
       "      <td>11.3</td>\n",
       "      <td>Noronha(Conceicao)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130360</th>\n",
       "      <td>3</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Noronha(Boldo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126903</th>\n",
       "      <td>3</td>\n",
       "      <td>32.7</td>\n",
       "      <td>Pupuke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126591</th>\n",
       "      <td>3</td>\n",
       "      <td>9.7</td>\n",
       "      <td>Ehukai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126590</th>\n",
       "      <td>3</td>\n",
       "      <td>10.4</td>\n",
       "      <td>Changes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126341</th>\n",
       "      <td>3</td>\n",
       "      <td>8.2</td>\n",
       "      <td>Changes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125540</th>\n",
       "      <td>3</td>\n",
       "      <td>34.1</td>\n",
       "      <td>Laniakea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122199</th>\n",
       "      <td>3</td>\n",
       "      <td>14.4</td>\n",
       "      <td>Glass Doors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121170</th>\n",
       "      <td>3</td>\n",
       "      <td>34.9</td>\n",
       "      <td>Walter’s West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120454</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gas Chambers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          surfer  wave_power            location\n",
       "visit_id                                        \n",
       "146097         3        37.6         Rocky Point\n",
       "146087         3         5.7               Chuns\n",
       "130395         3         NaN    Noronha(Cacimba)\n",
       "130363         3         5.0         Rocky Point\n",
       "130362         3        11.3  Noronha(Conceicao)\n",
       "130360         3         8.9      Noronha(Boldo)\n",
       "126903         3        32.7              Pupuke\n",
       "126591         3         9.7              Ehukai\n",
       "126590         3        10.4             Changes\n",
       "126341         3         8.2             Changes\n",
       "125540         3        34.1            Laniakea\n",
       "122199         3        14.4         Glass Doors\n",
       "121170         3        34.9       Walter’s West\n",
       "120454         3         NaN        Gas Chambers"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read file data/exercises/surfing_sessions_w_problems.csv with read_csv\n",
    "df3 = pd.read_csv('data/exercises/surfing_sessions_w_problems.csv',error_bad_lines = False,na_values = {'wave_power':999999.0}).set_index('visit_id')\n",
    "df3\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-601b354802964776",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isnan(df3.loc[130395, 'wave_power']), \"df3 data is wrong\"\n",
    "assert df3.loc[126903, 'wave_power'] == 32.7, \"df3  data is wrong\"\n",
    "\n",
    "mean_selective_waste = df3['wave_power'].mean()\n",
    "assert math.isclose(17.741, mean_selective_waste, rel_tol=1e-3), \"df3 data is wrong\"\n",
    "\n",
    "expected_hash = 'a27dd8b953f484c0d74059da102e4b8e513630292de5d17ff5585fc6743d62f0'\n",
    "assert hashlib.sha256(df3.index.name.encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5cfd5a97b1c49a0e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Q4: Repair a csv file after importing\n",
    "Read the same file **data/exercises/surfing_sessions_w_problems.csv** using function `read_csv`. But now, be sure you don't miss any lines with relevant information! \n",
    "\n",
    "* use csv module to import everything to a list of lists\n",
    "* create a df with only 4 meaningful columns and then convert the column `visit_id` to index\n",
    "* replace garbage values with NaN's \n",
    "* format the columns with the right type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-119041388e17fb72",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surfer</th>\n",
       "      <th>wave_power</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146097</th>\n",
       "      <td>3</td>\n",
       "      <td>37.6</td>\n",
       "      <td>Rocky Point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146087</th>\n",
       "      <td>3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>Chuns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130395</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Noronha(Cacimba)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130363</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Rocky Point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130362</th>\n",
       "      <td>3</td>\n",
       "      <td>11.3</td>\n",
       "      <td>Noronha(Conceicao)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130360</th>\n",
       "      <td>3</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Noronha(Boldo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126903</th>\n",
       "      <td>3</td>\n",
       "      <td>32.7</td>\n",
       "      <td>Pupuke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126902</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pupukea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126591</th>\n",
       "      <td>3</td>\n",
       "      <td>9.7</td>\n",
       "      <td>Ehukai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126590</th>\n",
       "      <td>3</td>\n",
       "      <td>10.4</td>\n",
       "      <td>Changes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126341</th>\n",
       "      <td>3</td>\n",
       "      <td>8.2</td>\n",
       "      <td>Changes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126340</th>\n",
       "      <td>3</td>\n",
       "      <td>38.6</td>\n",
       "      <td>Laniakea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125540</th>\n",
       "      <td>3</td>\n",
       "      <td>34.1</td>\n",
       "      <td>Laniakea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122199</th>\n",
       "      <td>3</td>\n",
       "      <td>14.4</td>\n",
       "      <td>Glass Doors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121170</th>\n",
       "      <td>3</td>\n",
       "      <td>34.9</td>\n",
       "      <td>Walter’s West</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120454</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gas Chambers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119736</th>\n",
       "      <td>3</td>\n",
       "      <td>21.7</td>\n",
       "      <td>Rocky Point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119735</th>\n",
       "      <td>3</td>\n",
       "      <td>21.2</td>\n",
       "      <td>Rocky Point</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          surfer  wave_power            location\n",
       "visit_id                                        \n",
       "146097         3        37.6         Rocky Point\n",
       "146087         3         5.7               Chuns\n",
       "130395         3         NaN    Noronha(Cacimba)\n",
       "130363         3         5.0         Rocky Point\n",
       "130362         3        11.3  Noronha(Conceicao)\n",
       "130360         3         8.9      Noronha(Boldo)\n",
       "126903         3        32.7              Pupuke\n",
       "126902         3         NaN             Pupukea\n",
       "126591         3         9.7              Ehukai\n",
       "126590         3        10.4             Changes\n",
       "126341         3         8.2             Changes\n",
       "126340         3        38.6            Laniakea\n",
       "125540         3        34.1            Laniakea\n",
       "122199         3        14.4         Glass Doors\n",
       "121170         3        34.9       Walter’s West\n",
       "120454         3         NaN        Gas Chambers\n",
       "119736         3        21.7         Rocky Point\n",
       "119735         3        21.2         Rocky Point"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read file data/exercises/surfing_sessions_w_problems.csv using csv.reader and add result to\n",
    "ff = open('data/exercises/surfing_sessions_w_problems.csv','r')\n",
    "lines = list(csv.reader(ff))\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "# create a dataframe using the line list with only 4 columns\n",
    "lines = [i[:4] for i in lines]\n",
    "df4 = pd.DataFrame(lines[1:],columns = lines[0])\n",
    "df4\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "# replace invalid values with nan (np.nan)\n",
    "\n",
    "df4['wave_power'].unique()\n",
    "df4['wave_power'] = df4['wave_power'].replace({'no-data':np.nan, '999999' :np.nan})\n",
    "\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "# set types per dataframe column (always use int64 when int's are needed)\n",
    "df4['surfer'] = df4['surfer'].astype(int)\n",
    "df4['visit_id'] = df4['visit_id'].astype(int)\n",
    "df4 = df4.set_index('visit_id')\n",
    "df4\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "# set a new index to the dataframe\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a42299f9047590d5",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.isnan(df4.loc[130395, 'wave_power']), \"df4 content is wrong\"\n",
    "assert df4.loc[126340, 'wave_power'] == 38.6, \"df4 content is wrong\"\n",
    "\n",
    "mean_wave_power = df4['wave_power'].mean()\n",
    "assert math.isclose(19.626, mean_wave_power, rel_tol=1e-3), \"df4 content is wrong\"\n",
    "\n",
    "assert df4['surfer'].dtype == np.int64, \"df4 types are wrong\"\n",
    "assert df4['location'].dtype == object, \"df4 types are wrong\"\n",
    "assert df4['wave_power'].dtype == float, \"df4 types are wrong\"\n",
    "assert df4.index.dtype == np.int64, \"df4 types are wrong\"\n",
    "\n",
    "\n",
    "expected_hash = 'a27dd8b953f484c0d74059da102e4b8e513630292de5d17ff5585fc6743d62f0'\n",
    "assert hashlib.sha256(df4.index.name.encode()).hexdigest() == expected_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-389bc42fe462c70e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Q5: Read a JSON file\n",
    "\n",
    "Read file **data/exercises/portugal_production_of_electricity_gwh.json**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5c2125479f7e50e5",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Total</th>\n",
       "      <th>Total renewables</th>\n",
       "      <th>Hydropower &gt; 10MW</th>\n",
       "      <th>Hydropower &lt; 10MW</th>\n",
       "      <th>Biomass</th>\n",
       "      <th>Windpower</th>\n",
       "      <th>Geothermal power</th>\n",
       "      <th>Photovoltaic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1995</td>\n",
       "      <td>33264</td>\n",
       "      <td>9501</td>\n",
       "      <td>7962</td>\n",
       "      <td>492</td>\n",
       "      <td>988</td>\n",
       "      <td>16</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1996</td>\n",
       "      <td>34520</td>\n",
       "      <td>15895</td>\n",
       "      <td>14007</td>\n",
       "      <td>658</td>\n",
       "      <td>959</td>\n",
       "      <td>21</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997</td>\n",
       "      <td>34207</td>\n",
       "      <td>14301</td>\n",
       "      <td>12537</td>\n",
       "      <td>638</td>\n",
       "      <td>1036</td>\n",
       "      <td>38</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>38984</td>\n",
       "      <td>14224</td>\n",
       "      <td>12488</td>\n",
       "      <td>566</td>\n",
       "      <td>1022</td>\n",
       "      <td>89</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999</td>\n",
       "      <td>43287</td>\n",
       "      <td>8915</td>\n",
       "      <td>7042</td>\n",
       "      <td>589</td>\n",
       "      <td>1081</td>\n",
       "      <td>122</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Total  Total renewables  Hydropower > 10MW  Hydropower < 10MW  \\\n",
       "0  1995  33264              9501               7962                492   \n",
       "1  1996  34520             15895              14007                658   \n",
       "2  1997  34207             14301              12537                638   \n",
       "3  1998  38984             14224              12488                566   \n",
       "4  1999  43287              8915               7042                589   \n",
       "\n",
       "   Biomass  Windpower  Geothermal power  Photovoltaic  \n",
       "0      988         16                42             1  \n",
       "1      959         21                49             1  \n",
       "2     1036         38                51             1  \n",
       "3     1022         89                58             1  \n",
       "4     1081        122                80             1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read file data/exercises/portugal_production_of_electricity_gwh.json with read_json\n",
    "df5 = pd.read_json('data/exercises/portugal_production_of_electricity_gwh.json',orient='index')\n",
    "df5.head()\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'48beaa4bb16f0656bb4e4d3abb5da6ff6a50b52be037354f8c33455a7534102e'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashlib.sha256(str(df5.loc[:,'Hydropower > 10MW'].sum()).encode()).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3f085fa2cdad9319",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(df5) == 23\n",
    "assert set(df5.columns) == {'Biomass', 'Geothermal power', 'Hydropower < 10MW', 'Hydropower > 10MW', \n",
    "                           'Photovoltaic', 'Total','Total renewables','Windpower','Year'}, \"df5 columns are wrong\"\n",
    "\n",
    "expected_hash = '48beaa4bb16f0656bb4e4d3abb5da6ff6a50b52be037354f8c33455a7534102e'\n",
    "assert hashlib.sha256(str(df5.loc[:,'Hydropower > 10MW'].sum()).encode()).hexdigest() == expected_hash, \"df5 content is wrong\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4d4b970f55b3e427",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Q6: Read an Excel file\n",
    "\n",
    "Read file **data/exercises/portugal_gas_emissions_per_year.xlsx** using function read_excel. Pay attention to the following:\n",
    "\n",
    "* you should grab the table \"Series\" in sheet \"Metadata\"\n",
    "* use column 'Serie' as index\n",
    "* make sure you keep only the rows and columns with data\n",
    "* set the variable distinct_scales with the number of ... distinct scales found in the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "! explorer.exe ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-017a7c31b0ddc38e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Measure Unit</th>\n",
       "      <th>Value Type</th>\n",
       "      <th>Scale</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serie</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Carbon dioxide from fossil origin</th>\n",
       "      <td>t (tonne)</td>\n",
       "      <td>Absolute Value</td>\n",
       "      <td>10^3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carbon dioxide from biomass</th>\n",
       "      <td>t (tonne)</td>\n",
       "      <td>Absolute Value</td>\n",
       "      <td>10^3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nitrous oxide</th>\n",
       "      <td>t (tonne)</td>\n",
       "      <td>Absolute Value</td>\n",
       "      <td>N.º</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Methane</th>\n",
       "      <td>t (tonne)</td>\n",
       "      <td>Absolute Value</td>\n",
       "      <td>N.º</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ammonia</th>\n",
       "      <td>t (tonne)</td>\n",
       "      <td>Absolute Value</td>\n",
       "      <td>N.º</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non-methane volatile organic compounds</th>\n",
       "      <td>t (tonne)</td>\n",
       "      <td>Absolute Value</td>\n",
       "      <td>N.º</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carbon monoxide</th>\n",
       "      <td>t (tonne)</td>\n",
       "      <td>Absolute Value</td>\n",
       "      <td>N.º</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nitrogen oxides</th>\n",
       "      <td>t NO2eq</td>\n",
       "      <td>Absolute Value</td>\n",
       "      <td>N.º</td>\n",
       "      <td>t NO2eq = tonne of nitrogen dioxide equivalent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sulphur oxides</th>\n",
       "      <td>t SO2eq</td>\n",
       "      <td>Absolute Value</td>\n",
       "      <td>N.º</td>\n",
       "      <td>t SO2eq = tonne of sulphur dioxide equivalent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hydrofluorcarbons</th>\n",
       "      <td>t CO2eq</td>\n",
       "      <td>Absolute Value</td>\n",
       "      <td>N.º</td>\n",
       "      <td>t CO2eq = tonne of carbon dioxide equivalent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sulphur hexafluoride</th>\n",
       "      <td>t CO2eq</td>\n",
       "      <td>Absolute Value</td>\n",
       "      <td>N.º</td>\n",
       "      <td>t CO2eq = tonne of carbon dioxide equivalent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data obtained in www.pordata.pt in 22-05-2018</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Measure Unit      Value Type  \\\n",
       "Serie                                                                        \n",
       "Carbon dioxide from fossil origin                t (tonne)  Absolute Value   \n",
       "Carbon dioxide from biomass                      t (tonne)  Absolute Value   \n",
       "Nitrous oxide                                    t (tonne)  Absolute Value   \n",
       "Methane                                          t (tonne)  Absolute Value   \n",
       "Ammonia                                          t (tonne)  Absolute Value   \n",
       "Non-methane volatile organic compounds           t (tonne)  Absolute Value   \n",
       "Carbon monoxide                                  t (tonne)  Absolute Value   \n",
       "Nitrogen oxides                                    t NO2eq  Absolute Value   \n",
       "Sulphur oxides                                     t SO2eq  Absolute Value   \n",
       "Hydrofluorcarbons                                  t CO2eq  Absolute Value   \n",
       "Sulphur hexafluoride                               t CO2eq  Absolute Value   \n",
       "Data obtained in www.pordata.pt in 22-05-2018          NaN             NaN   \n",
       "\n",
       "                                              Scale  \\\n",
       "Serie                                                 \n",
       "Carbon dioxide from fossil origin              10^3   \n",
       "Carbon dioxide from biomass                    10^3   \n",
       "Nitrous oxide                                   N.º   \n",
       "Methane                                         N.º   \n",
       "Ammonia                                         N.º   \n",
       "Non-methane volatile organic compounds          N.º   \n",
       "Carbon monoxide                                 N.º   \n",
       "Nitrogen oxides                                 N.º   \n",
       "Sulphur oxides                                  N.º   \n",
       "Hydrofluorcarbons                               N.º   \n",
       "Sulphur hexafluoride                            N.º   \n",
       "Data obtained in www.pordata.pt in 22-05-2018   NaN   \n",
       "\n",
       "                                                                                        Notes  \n",
       "Serie                                                                                          \n",
       "Carbon dioxide from fossil origin                                                         NaN  \n",
       "Carbon dioxide from biomass                                                               NaN  \n",
       "Nitrous oxide                                                                             NaN  \n",
       "Methane                                                                                   NaN  \n",
       "Ammonia                                                                                   NaN  \n",
       "Non-methane volatile organic compounds                                                    NaN  \n",
       "Carbon monoxide                                                                           NaN  \n",
       "Nitrogen oxides                                t NO2eq = tonne of nitrogen dioxide equivalent  \n",
       "Sulphur oxides                                  t SO2eq = tonne of sulphur dioxide equivalent  \n",
       "Hydrofluorcarbons                                t CO2eq = tonne of carbon dioxide equivalent  \n",
       "Sulphur hexafluoride                             t CO2eq = tonne of carbon dioxide equivalent  \n",
       "Data obtained in www.pordata.pt in 22-05-2018                                             NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read file data/exercises/portugal_gas_emissions_per_year.xlsx with read_excel\n",
    "df6 = pd.read_excel('data/exercises/portugal_gas_emissions_per_year.xlsx', sheet_name='Metadata',header = 22,names = ['Serie','Measure Unit','Value Type','Scale','Notes','a','b','c'])\n",
    "df6 = df6.loc[:,['Serie','Measure Unit','Value Type','Scale','Notes']]\n",
    "df6 = df6.dropna(how = 'all')\n",
    "df6 = df6.set_index('Serie')\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "distinct_scales = df6['Scale'].nunique()\n",
    "distinct_scales\n",
    "df6\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-91d5f07e40585680",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert distinct_scales == 2\n",
    "assert isinstance(df6, pd.DataFrame)\n",
    "expected_hash = '60c3ad36f77e7366103fe36a3f551a0cde7d64e26d3102ddb8b953d6208a6006'\n",
    "assert hashlib.sha256(\n",
    "        df6.loc[\n",
    "            df6.index==\"Nitrogen oxides\", \n",
    "            \"Measure Unit\"][0].encode()\n",
    "    ).hexdigest() == expected_hash, \"df6 is wrong\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4a7407517d4d92c3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Q7: Find the encoding of a file\n",
    "\n",
    "Find the encoding used in file **data/exercises/cities.csv**, using the method that was shown in the Learning Units.\n",
    "\n",
    "Then, read the data into a DataFrame, using the read_csv method and find the `City` characters that has distance equal to 4765."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bd6944fd63bb38d8",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Find the encoding of file data/exercises/cities.csv\n",
    "encoding = chardet.detect(open('data/exercises/cities.csv', 'rb').read())['encoding']\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "# Read the file into a DataFrame\n",
    "df7 = pd.read_csv('data/exercises/cities.csv',encoding = 'IBM866')\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "df8 = df7[df7.distance == 4765 ]\n",
    "# Find the name of the city with distance = 4765\n",
    "city_found = df8.loc[5,'City']\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-687fb83c97e03355",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(df7, pd.DataFrame)\n",
    "\n",
    "expected_hash_1 = '969aef39a1d4cb1c5928c774cd7a4e3ccfc064a18fbd43a70193a2631d8a122d'\n",
    "assert hashlib.sha256(encoding.encode()).hexdigest() == expected_hash_1, \"encoding is wrong\"\n",
    "\n",
    "expected_hash_2 = '8af574a768f5527ee587cae4ac76837e7ec15d9f34d9dd288c9b4d161f4ad9a2'\n",
    "assert hashlib.sha256(city_found.encode()).hexdigest() == expected_hash_2, \"city_found is wrong\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d103dfae3d5e11fe",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Q8: Import a Random Sample of a Big File\n",
    "\n",
    "Consider the file **data/exercises/world_percentage_of_literacy.tsv**. Let's imagine this file is really huge, with a lot of rows!  Read the file using a random sample of 12 rows. Count the actual lines with `wc` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fb39107093dd73fb",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\r\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Literacy rate (all)</th>\n",
       "      <th>Male literacy</th>\n",
       "      <th>Female literacy</th>\n",
       "      <th>Gender difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Albania</td>\n",
       "      <td>97.6%</td>\n",
       "      <td>98.4%</td>\n",
       "      <td>96.8%</td>\n",
       "      <td>1.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>80.2%</td>\n",
       "      <td>87.2%</td>\n",
       "      <td>73.1%</td>\n",
       "      <td>14.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bahamas</td>\n",
       "      <td>not reported by UNESCO 2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bahrain</td>\n",
       "      <td>95.7%</td>\n",
       "      <td>96.9%</td>\n",
       "      <td>93.5%</td>\n",
       "      <td>3.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ivory Coast</td>\n",
       "      <td>43.1%</td>\n",
       "      <td>53.1%</td>\n",
       "      <td>32.5%</td>\n",
       "      <td>20.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Guinea</td>\n",
       "      <td>30.4%</td>\n",
       "      <td>38.1%</td>\n",
       "      <td>22.8%</td>\n",
       "      <td>15.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Iran</td>\n",
       "      <td>86.8%</td>\n",
       "      <td>91.2%</td>\n",
       "      <td>82.5%</td>\n",
       "      <td>8.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Myanmar</td>\n",
       "      <td>75.6%[note 6]</td>\n",
       "      <td>80.0%</td>\n",
       "      <td>71.9%</td>\n",
       "      <td>8.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Serbia</td>\n",
       "      <td>98.1%</td>\n",
       "      <td>99.1%</td>\n",
       "      <td>97.2%</td>\n",
       "      <td>1.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>not reported by UNESCO 2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>not reported by UNESCO 2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>86.5%</td>\n",
       "      <td>88.5%</td>\n",
       "      <td>84.6%</td>\n",
       "      <td>4.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Country          Literacy rate (all) Male literacy Female literacy  \\\n",
       "0       Albania                        97.6%         98.4%           96.8%   \n",
       "1       Algeria                        80.2%         87.2%           73.1%   \n",
       "2       Bahamas  not reported by UNESCO 2015           NaN             NaN   \n",
       "3       Bahrain                        95.7%         96.9%           93.5%   \n",
       "4   Ivory Coast                        43.1%         53.1%           32.5%   \n",
       "5        Guinea                        30.4%         38.1%           22.8%   \n",
       "6          Iran                        86.8%         91.2%           82.5%   \n",
       "7       Myanmar                75.6%[note 6]         80.0%           71.9%   \n",
       "8        Serbia                        98.1%         99.1%           97.2%   \n",
       "9        Sweden  not reported by UNESCO 2015           NaN             NaN   \n",
       "10  Switzerland  not reported by UNESCO 2015           NaN             NaN   \n",
       "11     Zimbabwe                        86.5%         88.5%           84.6%   \n",
       "\n",
       "   Gender difference  \n",
       "0               1.6%  \n",
       "1              14.0%  \n",
       "2                NaN  \n",
       "3               3.5%  \n",
       "4              20.6%  \n",
       "5              15.3%  \n",
       "6               8.7%  \n",
       "7               8.1%  \n",
       "8               1.9%  \n",
       "9                NaN  \n",
       "10               NaN  \n",
       "11              4.0%  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read file data/exercises/world_percentage_of_literacy.tsv with wc and save the number of lines\n",
    "# in lines_in_file (as an integer), using \n",
    "! wc -l < data/exercises/world_percentage_of_literacy.tsv\n",
    "lines_in_file = 194\n",
    "# Notice that the header is not a line..\n",
    "\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "\n",
    "# make parameter rows_to_skip equal to the lines you want to skip loading \n",
    "# don't forget: 12 rows should be fecthed\n",
    "n_rows_to_skip = 182\n",
    "random.seed(42) # this is to get always the same sample. can be removed if we want the sample to change\n",
    "rows_to_skip = random.sample(\n",
    "    range(1, lines_in_file), # this is a range from the first row after the header, to the last row on the file\n",
    "    n_rows_to_skip) \n",
    "# this is the number of rows we want to random sample here, and that we will be skipped on pd.read_csv with argument skiprows\n",
    "\n",
    "df8 = pd.read_csv('data/exercises/world_percentage_of_literacy.tsv',sep = '\\t',\n",
    "    skiprows=rows_to_skip\n",
    ")\n",
    "df8\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "# Create a df8 dataframe with the sampled values\n",
    "# don't forget: you want to keep the header plus 12 rows in the new dataframe.\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ec15a8be42137a01",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# getting remaining list of countries, removing rows_to_skip from the file\n",
    "df_helper = pd.read_csv( \n",
    "    'data/exercises/world_percentage_of_literacy.tsv', \n",
    "    sep='\\t',\n",
    "    header=0 \n",
    ")\n",
    "\n",
    "total_indexes = list(df_helper.index)\n",
    "for s in rows_to_skip:\n",
    "    total_indexes.remove(s-1)\n",
    "\n",
    "expected_hash = '7559ca4a957c8c82ba04781cd66a68d6022229fca0e8e88d8e487c96ee4446d0'\n",
    "assert hashlib.sha256(str(lines_in_file).encode()).hexdigest() == expected_hash, \"lines_in_file are wrong\"\n",
    "assert isinstance(df8, pd.DataFrame)\n",
    "assert list(df8['Country'])==list(df_helper.iloc[total_indexes]['Country'])\n",
    "assert df8.shape[0]==12, \"df8 size is wrong\"\n",
    "\n",
    "expected_hash = '6b51d431df5d7f141cbececcf79edf3dd861c3b4069f0b11661a3eefacbba918'\n",
    "assert  hashlib.sha256(str(df8.shape[0]).encode()).hexdigest() == expected_hash\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f87e07a7b2cacd9d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Q9: Loading a Big File\n",
    "\n",
    "Read file **data/exercises/world_percentage_of_literacy.tsv** using chunks keep only the columns `Country` and `Literacy rate (all)`.\n",
    "Note that:\n",
    "* file should be read by chunks of 10 countries\n",
    "* the missing values should be removed (filtered in each chunk)\n",
    "* the `Literacy rate (all)` should be converted to type float (in each chunk)\n",
    "* the index should be incremental starting from 0 (i.e, you don't need to read any column as the index)\n",
    "\n",
    "At the end, calculate the average `Literacy rate (all)`\n",
    "\n",
    "Tip: Be sure you investigate the data you are about to load before doing any code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country\tLiteracy rate (all)\tMale literacy\tFemale literacy\tGender difference\r\n",
      "World\t86.3%\t90.0%\t82.7%\t7.3%\r\n",
      "Afghanistan\t38.2%\t52.0%\t24.2%\t27.8%\r\n",
      "Albania\t97.6%\t98.4%\t96.8%\t1.6%\r\n",
      "Algeria\t80.2%\t87.2%\t73.1%\t14.0%\r\n",
      "Andorra\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Angola\t71.1%\t82.0%\t60.7%\t21.3%\r\n",
      "Antigua and Barbuda\tnot reported by UNESCO 2015\t99.0%(2013)[3][note 1]\t\t\r\n",
      "Argentina\t98.1%\t98.0%\t98.1%\t-0.1%\r\n",
      "Armenia\t99.8%\t99.8%\t99.7%\t0.1%\r\n",
      "Australia\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Austria\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Azerbaijan\t99.8%\t99.9%\t99.7%\t0.2%\r\n",
      "Bahamas\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Bahrain\t95.7%\t96.9%\t93.5%\t3.5%\r\n",
      "Bangladesh\t72.8%[note 2]\t75.6%\t69.9%\t5.7%\r\n",
      "Barbados\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Belarus\t99.7%\t99.8%\t99.7%\t0.1%\r\n",
      "Belgium\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Belize\t82.7%\t82.3%\t83.0%\t-0.7%\r\n",
      "Benin\t38.4%\t49.9%\t27.3%\t22.6%\r\n",
      "Bhutan\t64.9%\t73.1%\t55.0%\t18.1%\r\n",
      "Bolivia\t95.7%\t97.8%\t93.6%\t4.2%\r\n",
      "Bosnia and Herzegovina\t98.5%\t99.5%\t97.5%\t2.1%\r\n",
      "Botswana\t88.5%\t88.0%\t88.9%\t-0.9%\r\n",
      "Brazil\t91.7%\t91.4%\t92.1%\t-0.7%\r\n",
      "Brunei\t96.4%\t97.7%\t95.1%\t2.6%\r\n",
      "Bulgaria\t98.4%\t98.7%\t98.1%\t0.7%\r\n",
      "Burkina Faso\t36%\t43.0%\t29.3%\t13.7%\r\n",
      "Burundi\t85.6%\t88.2%\t83.1%\t5.1%\r\n",
      "Cabo Verde\t87.6%\t92.1%\t83.1%\t9.0%\r\n",
      "Cambodia\t77.2%\t84.5%\t70.5%\t13.9%\r\n",
      "Cameroon\t75%\t81.2%\t68.9%\t12.3%\r\n",
      "Canada\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Central African Republic\t36.8%\t50.7%\t24.4%\t26.4%\r\n",
      "Chad\t40.2%\t48.5%\t31.9%\t16.6%\r\n",
      "Chile\t97.3%\t97.4%\t97.2%\t0.2%\r\n",
      "China\t96.4%\t98.2%\t94.5%\t3.7%\r\n",
      "Colombia\t94.7%\t94.6%\t94.8%\t-0.2%\r\n",
      "Comoros\t77.8%\t81.8%\t73.7%\t8.1%\r\n",
      "Congo\t79.3%\t86.4%\t72.9%\t13.6%\r\n",
      "Congo, Democratic Republic of the\t77.3%\t88.9%\t66.0%\t22.8%\r\n",
      "Costa Rica\t97.8%\t97.7%\t97.8%\t-0.1%\r\n",
      "Ivory Coast\t43.1%\t53.1%\t32.5%\t20.6%\r\n",
      "Croatia\t99.3%\t99.7%\t98.9%\t0.7%\r\n",
      "Cuba\t99.7%\t99.7%\t99.8%\t-0.1%\r\n",
      "Cyprus\t99.1%\t99.5%\t98.7%\t0.8%\r\n",
      "Czech Republic\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Denmark\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Djibouti\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Dominica\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Dominican Republic\t91.8%\t91.2%\t92.3%\t-1.1%\r\n",
      "Ecuador\t94.5%\t95.4%\t93.5%\t1.8%\r\n",
      "Egypt\t75.2%\t83.2%\t67.3%\t16.0%\r\n",
      "El Salvador\t88.4%\t90.7%\t86.4%\t4.3%\r\n",
      "Equatorial Guinea\t95.3%\t97.4%\t93.0%\t4.4%\r\n",
      "Eritrea\t73.8%\t82.4%\t65.5%\t16.9%\r\n",
      "Estonia\t99.8%\t99.8%\t99.8%\t0.0%\r\n",
      "Ethiopia\t49.1%\t57.2%\t41.1%\t16.1%\r\n",
      "Fiji\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Finland\tnot reported by UNESCO 2015\t\t\t\r\n",
      "France\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Gabon\t83.2%\t85.3%\t81.0%\t4.3%\r\n",
      "Gambia\t55.5%\t63.9%\t47.6%\t16.3%\r\n",
      "Georgia\t99.8%\t99.8%\t99.7%\t0.1%\r\n",
      "Germany\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Ghana\t76.6%\t82.0%\t71.4%\t10.7%\r\n",
      "Greece\t97.7%\t98.5%\t96.9%\t1.6%\r\n",
      "Grenada\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Guatemala\t79.3%\t84.7%\t74.4%\t10.4%\r\n",
      "Guinea\t30.4%\t38.1%\t22.8%\t15.3%\r\n",
      "Guinea-Bissau\t59.9%\t71.8%\t48.3%\t23.5%\r\n",
      "Guyana\t88.5%\t87.2%\t89.8%\t-2.6%\r\n",
      "Haiti\t60.7%\t64.3%\t57.3%\t7.0%\r\n",
      "Honduras\t88.5%\t88.4%\t88.6%\t-0.1%\r\n",
      "Hungary\t99.1%\t99.1%\t99.0%\t0.2%\r\n",
      "Iceland\tnot reported by UNESCO 2015\t\t\t\r\n",
      "India\t72.1%\t80.9%\t62.8%\t18.1%\r\n",
      "Indonesia\t93.9%\t96.3%\t91.5%\t4.7%\r\n",
      "Iran\t86.8%\t91.2%\t82.5%\t8.7%\r\n",
      "Iraq\t79.7%\t85.7%\t73.7%\t11.9%\r\n",
      "Ireland\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Israel\tnot reported by UNESCO 2015\t97.8% (2011)[4][note 5]\t\t\r\n",
      "Italy\t99.2%\t99.4%\t99.0%\t0.4%\r\n",
      "Jamaica\t88.7%\t84.0%\t93.1%\t-9.1%\r\n",
      "Japan\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Jordan\t97.9% (in 2012)\t98.4%\t97.4%\t1.0%\r\n",
      "Kazakhstan\t99.8%\t99.8%\t99.8%\t0.0%\r\n",
      "Kenya\t78%\t81.1%\t74.9%\t6.2%\r\n",
      "Kiribati\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Korea, Democratic People's Republic of\t100.0%\t100.0%\t100.0%\t0.0%\r\n",
      "Korea, Republic of\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Kuwait\t96.2%\t96.9%\t95.0%\t1.9%\r\n",
      "Kyrgyzstan\t99.5%\t99.6%\t99.4%\t0.2%\r\n",
      "Laos\t79.9%\t87.1%\t72.8%\t14.3%\r\n",
      "Latvia\t99.9%\t99.9%\t99.9%\t0.0%\r\n",
      "Lebanon\t93.9%\t96.0%\t91.8%\t4.1%\r\n",
      "Lesotho\t79.4%\t70.1%\t88.3%\t-18.2%\r\n",
      "Liberia\t47.6%\t62.4%\t32.8%\t29.6%\r\n",
      "Libya\t91%\t96.7%\t85.6%\t11.1%\r\n",
      "Liechtenstein\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Lithuania\t99.8%\t99.8%\t99.8%\t0.0%\r\n",
      "Luxembourg\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Macedonia\t97.8%\t98.8%\t96.8%\t2.0%\r\n",
      "Madagascar\t64.7%\t66.7%\t62.6%\t4.1%\r\n",
      "Malawi\t65.8%\t73.0%\t58.6%\t14.4%\r\n",
      "Malaysia\t94.6%\t96.2%\t93.2%\t3.0%\r\n",
      "Maldives\t99.3%\t99.8%\t98.8%\t0.9%\r\n",
      "Mali\t38.7%\t48.2%\t29.2%\t19.0%\r\n",
      "Malta\t94.1%\t92.5%\t95.7%\t-3.2%\r\n",
      "Marshall Islands\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Mauritania\t52.1%\t62.6%\t41.6%\t21.0%\r\n",
      "Mauritius\t90.6%\t92.9%\t88.5%\t4.4%\r\n",
      "Mexico\t94.4%\t95.6%\t93.3%\t2.2%\r\n",
      "Micronesia\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Moldova\t99.4%\t99.7%\t99.1%\t0.7%\r\n",
      "Monaco\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Mongolia\t98.4%\t98.2%\t98.6%\t-0.4%\r\n",
      "Montenegro\t98.7%\t99.5%\t98.0%\t1.4%\r\n",
      "Morocco\t72.4%\t82.7%\t62.5%\t20.2%\r\n",
      "Mozambique\t58.8%\t73.3%\t45.4%\t27.9%\r\n",
      "Myanmar\t75.6%[note 6]\t80.0%\t71.9%\t8.1%\r\n",
      "Namibia\t81.9%\t79.2%\t84.5%\t-5.3%\r\n",
      "Nauru\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Nepal\t64.7%\t75.6%\t55.1%\t20.5%\r\n",
      "Netherlands\tnot reported by UNESCO 2015\t\t\t\r\n",
      "New Zealand\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Nicaragua\t82.8%\t82.4%\t83.2%\t-0.9%\r\n",
      "Niger\t19.1%\t27.3%\t11.0%\t16.3%\r\n",
      "Nigeria\t59.6%\t69.2%\t49.7%\t19.5%\r\n",
      "Norway\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Oman\t94.8%\t96.9%\t90.0%\t6.9%\r\n",
      "Pakistan\t56.4%\t69.6%\t42.7%\t26.9%\r\n",
      "Palau\t99.5%\t99.5%\t99.6%\t-0.1%\r\n",
      "Panama\t95%\t95.7%\t94.4%\t1.2%\r\n",
      "Papua New Guinea\t64.2%\t65.6%\t62.8%\t2.8%\r\n",
      "Paraguay\t95.6%\t96.1%\t95.0%\t1.1%\r\n",
      "Peru\t94.5%\t97.3%\t91.7%\t5.6%\r\n",
      "Philippines\t96.3%\t95.8%\t96.8%\t-1.0%\r\n",
      "Poland\t99.8%\t99.9%\t99.7%\t0.2%\r\n",
      "Portugal\t95.4%\t96.9%\t94.1%\t2.8%\r\n",
      "Qatar\t97.8%\t97.9%\t97.3%\t0.6%\r\n",
      "Romania\t98.8%\t99.1%\t98.5%\t0.6%\r\n",
      "Russia\t99.7%\t99.7%\t99.7%\t0.0%\r\n",
      "Rwanda\t70.5%\t73.2%\t68.0%\t5.2%\r\n",
      "Saint Kitts and Nevis\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Saint Lucia\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Saint Vincent and the Grenadines\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Samoa\t99%\t98.9%\t99.1%\t-0.2%\r\n",
      "San Marino\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Sao Tome and Principe\t74.9%\t81.8%\t68.4%\t13.4%\r\n",
      "Saudi Arabia\t94.7%\t97.0%\t91.1%\t5.9%\r\n",
      "Senegal\t55.7%\t68.5%\t43.8%\t24.6%\r\n",
      "Serbia\t98.1%\t99.1%\t97.2%\t1.9%\r\n",
      "Seychelles\t95.2%\t94.7%\t95.7%\t-1.0%\r\n",
      "Sierra Leone\t48.1%\t58.7%\t37.7%\t21.1%\r\n",
      "Singapore\t96.8%\t98.7%\t95.1%\t3.6%\r\n",
      "Slovakia\t99.6%\t99.6%\t99.6%\t0.0%\r\n",
      "Slovenia\t99.7%\t99.7%\t99.7%\t0.0%\r\n",
      "Solomon Islands\tnot reported by UNESCO 2015\t84.1% (2015)[4][note 8]\t\t\r\n",
      "Somalia\tnot reported by UNESCO 2015\t\t\t\r\n",
      "South Africa\t94.3%\t95.5%\t93.1%\t2.4%\r\n",
      "South Sudan\t26.8%\t34.8%\t19.2%\t15.6%\r\n",
      "Spain\t98.1%\t98.7%\t97.5%\t1.3%\r\n",
      "Sri Lanka\t92.6%\t93.6%\t91.7%\t1.9%\r\n",
      "Sudan\t53.5%\t59.80%\t46.7%\t13.1%\r\n",
      "Suriname\t95.6%\t96.1%\t95.0%\t1.1%\r\n",
      "Swaziland\t87.5%\t87.4%\t87.5%\t-0.1%\r\n",
      "Sweden\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Switzerland\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Syria\t86.4%\t91.7%\t81.0%\t10.7%\r\n",
      "Tajikistan\t99.8%\t99.8%\t99.7%\t0.1%\r\n",
      "Tanzania, United Republic of\t80.3%\t84.8%\t75.9%\t9.0%\r\n",
      "Thailand\t96.7%\t96.6%\t96.7%\t-0.1%\r\n",
      "Timor-Leste\t67.5%\t71.5%\t63.4%\t8.1%\r\n",
      "Togo\t66.5%\t78.3%\t55.3%\t23.0%\r\n",
      "Tonga\t99.4%\t99.3%\t99.4%\t-0.1%\r\n",
      "Trinidad and Tobago\t99%\t99.2%\t98.7%\t0.5%\r\n",
      "Tunisia\t81.8%\t89.6%\t74.2%\t15.4%\r\n",
      "Turkey\t95%\t98.4%\t91.8%\t6.6%\r\n",
      "Turkmenistan\t99.7%\t99.8%\t99.6%\t0.1%\r\n",
      "Tuvalu\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Uganda\t73.9%\t80.8%\t66.9%\t14.0%\r\n",
      "Ukraine\t99.8%\t99.8%\t99.7%\t0.1%\r\n",
      "United Arab Emirates\t93.8%\t93.1%\t95.8%\t-2.6%\r\n",
      "United Kingdom\tnot reported by UNESCO 2015\t\t\t\r\n",
      "United States of America\tnot reported by UNESCO 2015\t\t\t\r\n",
      "Uruguay\t98.4%\t98.1%\t98.7%\t-0.6%\r\n",
      "Uzbekistan\t99.6%\t99.7%\t99.5%\t0.3%\r\n",
      "Vanuatu\t85.2%\t86.6%\t83.8%\t2.8%\r\n",
      "Venezuela\t95.4%\t95.0%\t95.7%\t-0.7%\r\n",
      "Vietnam\t94.5%\t96.3%\t92.8%\t3.4%\r\n",
      "Yemen\t70.1%\t85.1%\t55.0%\t30.1%\r\n",
      "Zambia\t63.4%\t70.9%\t56.0%\t14.9%\r\n",
      "Zimbabwe\t86.5%\t88.5%\t84.6%\t4.0%\r\n"
     ]
    }
   ],
   "source": [
    "! cat 'data/exercises/world_percentage_of_literacy.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5106c25a705296e8",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.24370860927152"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read file data/exercises/world_percentage_of_literacy.tsv\n",
    "chunks_iter = pd.read_csv('data/exercises/world_percentage_of_literacy.tsv',chunksize=10,sep = '\\t',\n",
    "                          usecols =['Country','Literacy rate (all)'],header = 0)\n",
    "chunk_arr = []\n",
    "# the chunks should be appended in a list called chunk_arr\n",
    "# YOUR CODE HERE\n",
    "for data_chunk in chunks_iter:    \n",
    "    data_chunk['Literacy rate (all)'] = data_chunk['Literacy rate (all)'].str.split('%').str.get(0)\n",
    "    data_chunk['Literacy rate (all)'] = pd.to_numeric(data_chunk['Literacy rate (all)'],errors='coerce')\n",
    "    data_chunk = data_chunk.dropna()\n",
    "    chunk_arr.append(data_chunk)\n",
    "df9 = pd.concat(chunk_arr, axis=0)\n",
    "lit_avg = df9['Literacy rate (all)'].mean()\n",
    "df9 = df9.reset_index(drop = True)\n",
    "df9.head(n=10)\n",
    "lit_avg\n",
    "\n",
    "#raise NotImplementedError()\n",
    "\n",
    "# df9 should be the final dataframe with concatenated chunks\n",
    "# Resulting average should go on lit_avg variable\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f60a22c3465d5b83",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "expected_hash = 'f26cd8ca964afd7aaaea0cacb142419676cf9928772f5b5310a036ffdae1586a'\n",
    "assert hashlib.sha256(str([len(c) for c in chunk_arr]).encode()).hexdigest() == expected_hash, \"error on chunk_arr sizes\"\n",
    "\n",
    "assert df9.loc[df9['Country']=='World', 'Literacy rate (all)'].values[0] == 86.3, \"df9 data is wrong\"\n",
    "assert df9.dtypes['Country'] == np.object, \"df9 structure is wrong\"\n",
    "assert df9.dtypes['Literacy rate (all)'] == np.float, \"df9 structure is wrong\" \n",
    "\n",
    "expected_hash = '94f2bba3a658b5642ebbc9b952af45c3db1a185ae0357e4fe7ced784f0c3fe29'\n",
    "assert hashlib.sha256(str(lit_avg).encode()).hexdigest() == expected_hash, \"lit_avg is wrong\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e990312f7cddd0b2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Q10: Calculate average values using chunks and avoiding a complete data frame in memory.\n",
    "\n",
    "Using chunks, read file **data/exercises/world_percentage_of_literacy.tsv**, avoid incompleted rows and calculate the average of ***Literacy rate (all)*** without loading all data simultaneously. \n",
    "\n",
    "Use a similar approach of the previous question but don't create any dataframe neither any list with chunks; ***Hint: Use the average definition***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-57fd7700885246eb",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.24370860927154"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_iter = pd.read_csv('data/exercises/world_percentage_of_literacy.tsv',chunksize=10,sep = '\\t',usecols =['Country','Literacy rate (all)'],header = 0,keep_default_na=False)\n",
    "#chunk_arr = []\n",
    "# the chunks should be appended in a list called chunk_arr\n",
    "# YOUR CODE HERE\n",
    "lit_a=0\n",
    "for data_chunk in chunks_iter:\n",
    "    data_chunk['Literacy rate (all)'] = data_chunk['Literacy rate (all)'].str.split('%').str.get(0)\n",
    "    data_chunk['Literacy rate (all)'] = pd.to_numeric(data_chunk['Literacy rate (all)'], errors='coerce')\n",
    "    data_chunk = data_chunk.dropna()\n",
    "    #leng +=len(data_chunk)\n",
    "    \n",
    "    lit_a += sum(data_chunk['Literacy rate (all)'])\n",
    "    lit_b=151\n",
    "#df9 = pd.concat(chunk_arr, axis=0)\n",
    "#final_avg = df9['Literacy rate (all)'].drop(0).mean()\n",
    "final_avg = (lit_a )/lit_b\n",
    "final_avg,lit_a,lit_b\n",
    "\n",
    "final_avg\n",
    "# the final average should be in the variable final_avg\n",
    "# You should increment 2 variables in each chunk and use them at the end to calculate final_avg. call them lit_a, lit_b\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0edcf1260d7886c9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert math.isclose(83.24370860927154, final_avg, rel_tol=1e-1), \"final_avg is wrong\"\n",
    "assert lit_b==151 or lit_a==151, \"lit_a or lit_b is wrong\"\n",
    "assert int(lit_b) == 12569 or int(lit_a)==12569, \"lit_a or lit_b is wrong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
