{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLU7 - Regression with Linear Regression: Learning notebook\n",
    "\n",
    "In this notebook we will cover the following:\n",
    "    - What is regression?\n",
    "    - Simple Linear Regression\n",
    "    - Mean Squared Error\n",
    "    - Closed Form Solution - Ordinary Least Squares\n",
    "    - Multiple Linear Regression\n",
    "    - Scikit LinearRegression\n",
    "    - Gradient Descent basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is regression? \n",
    "\n",
    "A modeling task which objective is to create a (linear or non-linear) map between the **independent variables** (i.e. the columns in your pandas dataframe) and a set of **continuous dependent variables** (i.e. the variable you want to predict) by estimating a set of **parameters**. \n",
    "\n",
    "**Examples of regression tasks:**\n",
    "\n",
    "* predicting house prices (example range: \\[ 100k €; 500k € \\]);\n",
    "* predicting the rating that a user would assign to a movie (example range: [1 start; 7 stars]); \n",
    "* predicting the total sales for each day, in each shop of a shopping mall;\n",
    "* predicting emotional descriptors for a song;\n",
    "* predicting the trajectory of a fighter jet.\n",
    "\n",
    "**Predicting house prices:**\n",
    "\n",
    "Let's align the first 3 terms we used with an example: \n",
    "\n",
    "When predicting house prices...\n",
    "\n",
    "* the **independent variables** are the features related to the house like the number of rooms, the total area available, the crime rate of the neighborhood, the number of miles to the closest big city; \n",
    "* the **dependent variable** is the price of the house;\n",
    "* the **parameters** are a set of internal variables that will define the mapping between the previous variables.\n",
    "\n",
    "To predict the house prices, the regression model will take the independent variables and its internal parameters, perform a sequence of operations with those two and output the price of the house.\n",
    "\n",
    "Nowadays, there are *a lot* of algorithms to solve this task but we will focus on one of the easiest to understand: **linear regression**. It is one of the most used regression methods in the world to this day due to how easy it is to (1) interpret the model, (2) implement it and (3) implement extensions that deal with datasets with few data points, noise, and outliers. \n",
    "\n",
    "First, let's explore how **simple linear regression** works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Simple Linear Regression\n",
    "\n",
    "This model is a special case of linear regression where you have a single feature. The model is, simply, a line equation\n",
    "\n",
    "$$\\hat{y} = \\beta_0 + \\beta_1 \\cdot x$$\n",
    "\n",
    "* $\\hat{y}$ is the value predicted by the model; \n",
    "* $x$ is the input feature; \n",
    "* $\\beta_0$ is the y-axis value where $x=0$, usually called the *intercept*; \n",
    "* $\\beta_1$ tells you how much $\\hat{y}$ changes when $x$ changes, usually called the *coefficient*.\n",
    "\n",
    "The impact of $x$ in $\\hat{y}$ can be state as the following: _For each unit you increment in $x$, you increment $\\beta_1$ units in $\\hat{y}$._\n",
    "\n",
    "\n",
    "#### House pricing example:\n",
    "\n",
    "For example: \n",
    "\n",
    "$$HousePrice = 1.1 + 4 \\cdot NumberOfRooms$$\n",
    "\n",
    "means that the _price of the house increments 4 units (e.g. 1 unit = 10000€) each time I add a room to the house._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression = lambda x,b_0,b_1:b_0+b_1*x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 - Implementing and visualizing a simple linear model\n",
    "\n",
    "You can create a simple lambda function in order to implement this model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then use it by passing some data and parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_regression_simple(x, y, xlim, ylim):\n",
    "    origin = (0, 0)\n",
    "\n",
    "    # Set the x-axis and y-axis limits for the axes\n",
    "    plt.xlim(xlim)\n",
    "    plt.ylim(ylim)\n",
    "\n",
    "    # Plot axis for better visualization\n",
    "    plt.plot(origin, ylim, 'g:', xlim, origin, 'g:', linewidth=0.4)\n",
    "\n",
    "    # Plot linear model\n",
    "    plt.plot(x, y, 'b')\n",
    "    plt.show()\n",
    "\n",
    "# Base independent data\n",
    "x_lin = np.arange(-10, 10)\n",
    "\n",
    "# Parameters\n",
    "intercept = 0\n",
    "coefficient = 2\n",
    "\n",
    "# Dependent variable\n",
    "y_lin = linear_regression(x_lin, intercept, coefficient)\n",
    "plot_regression_simple(x_lin, y_lin, (-12, 12), (-25, 25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, imagine that we have some data with noise that we want to fit. Let's load it and visualize its shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4b9169ada0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('data/linear-learning-notebook.csv')\n",
    "df = df.sort_values('x')\n",
    "x_lin_df = df['x'].values\n",
    "y_lin_df = df['y'].values\n",
    "\n",
    "plt.plot(x_lin_df, y_lin_df, 'b.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the data looks linear, and you can easily see how good a model fits just by looking at it, right?\n",
    "\n",
    "Use the interactive demo to try it out below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f4f2afe18f42b8b16a7421566b84ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='b0', max=10.0, min=-10.0, step=0.01), FloatSlider(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from ipywidgets import FloatSlider, Dropdown\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def plot_simple_regression(b0=0, b1=1, xlim=(-5, 5), ylim=(-5, 5)):\n",
    "    y_pred = linear_regression(x_lin_df, b0, b1)\n",
    "    plt.xlim(xlim)\n",
    "    plt.ylim(ylim)\n",
    "    plt.plot(x_lin_df, y_lin_df, 'b.')\n",
    "    plt.plot(x_lin_df, y_pred, 'r-')\n",
    "    plt.plot([0, 0], ylim, 'g-', xlim, [0, 0], 'g-', linewidth=0.4)\n",
    "\n",
    "\n",
    "def simple_linear_regression_manual_demo_1(): \n",
    "    interact(plot_simple_regression, \n",
    "         b0=FloatSlider(min=-10, max=10, step=0.01, value=0), \n",
    "         b1=FloatSlider(min=-3, max=3, step=0.01, value=1), \n",
    "         xlim=fixed((-10, 10)), \n",
    "         ylim=fixed((-10, 10)));\n",
    "\n",
    "simple_linear_regression_manual_demo_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The green plot represents both the x and y-axes while the red line is the $\\hat{y}$ for each value of $x$. As you can see for yourself, if you decrease/increase $\\beta_0$, the value where y cross $\\hat{y}$ decreases/increases. If you increase/decrease $\\beta_1$, the slope of the line increases/decreases.\n",
    "\n",
    "If you were at all familiar with simple linear models before, this should all looking too easy for you. \n",
    "\n",
    "![easy](assets/easy_peasy.gif)\n",
    "\n",
    "However, you might also notice that, although you can get a somewhat good solution, you have no way of knowing exactly how good this solution is. Slight variations around your solution might seem just as adequate just by looking at the plot. \n",
    "\n",
    "So at this point, you might be thinking, there's gotta be a better way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 - Error measure for Linear Regression\n",
    "\n",
    "Here is where error measures come in. By finding a way of measuring the error in our models, we can more easily find a model that produces the least error. So let's dive into that.\n",
    "\n",
    "The main goal of modeling the data is getting our estimates to be as close to the labels as possible. So, if for each sample, my model outputs a value $\\hat{y_i}$ and we know its true label is $y_i$, then a direct definition of how much the model is wrong would follow:\n",
    "\n",
    "$$ e_i = y - \\hat{y_i} $$\n",
    "\n",
    "But this would only consider one sample, and as we know, the observations might contain noise. So we need to consider all of our observations together and their aggregated error. There are actually several ways of doing this, but the error we will present here is called Mean Squared Error - a standard metric used for linear regressions.\n",
    "\n",
    "$$MSE(y, \\hat{y}) = \\frac{1}{N} \\sum_{n=1}^N (y_n - \\hat{y}_n)^2 $$\n",
    "\n",
    "where, as stated above, $\\hat{y}$ is just the output of our linear model:\n",
    "\n",
    "$$\\hat{y} = \\beta_0 + \\beta_1 \\cdot x$$\n",
    "\n",
    "This is what we usually call a **cost function** or **error function**, representing the error between the true label of our samples and the predictions of our model. The better our model is , the lower this metric should be. We normally use the notation $J$ to refer to the cost function:\n",
    "\n",
    "$$J(y, \\hat{y}) = MSE = \\frac{1}{N} \\sum_{n=1}^N (y_n - \\hat{y}_n)^2 $$\n",
    "\n",
    "\n",
    "We can implement this metric with a lambda function also:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression_mse = lambda y, y_hat: ((y - y_hat)**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how the metric increases when our inputs are further apart and decreases when they are close together. In particular, if the prediction matches the label, then the metric is just zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small error measure for close inputs: 0.0024999999999999988\n",
      "Big error measure for distant inputs: 93.62125000000002\n",
      "Null error measure for equal inputs: 0.0\n"
     ]
    }
   ],
   "source": [
    "labels = np.array([0.2, 0.45])\n",
    "close_estimates = np.array([0.25, 0.5])\n",
    "far_estimates = np.array([10., 10.])\n",
    "\n",
    "print('Small error measure for close inputs: {}'.format(linear_regression_mse(labels, close_estimates)))\n",
    "print('Big error measure for distant inputs: {}'.format(linear_regression_mse(labels, far_estimates)))\n",
    "print('Null error measure for equal inputs: {}'.format(linear_regression_mse(labels, labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, it should make sense to you that decreasing this metric will lead to a better model. \n",
    "\n",
    "\n",
    "Try to use this metric in the following demo, to find the linear model that fits our data the best, and notice that it goes up as you change towards a worse model, and down as you slide towards a better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "773c9b3618094dddba785cd7b043f4c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='b0', max=10.0, min=-10.0, step=0.01), FloatSlider(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from ipywidgets import FloatSlider, Dropdown\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def plot_regression(b0=0, b1=1, xlim=(-5, 5), ylim=(-5, 5)):\n",
    "    y_pred = linear_regression(x_lin_df, b0, b1)\n",
    "    plt.xlim(xlim)\n",
    "    plt.ylim(ylim)\n",
    "    plt.plot(x_lin_df, y_lin_df, 'b.')\n",
    "    plt.plot(x_lin_df, y_pred, 'r-')\n",
    "    plt.plot([0, 0], ylim, 'g-', xlim, [0, 0], 'g-', linewidth=0.4)\n",
    "    return \"Mean Squared Error (MSE): {}\".format(linear_regression_mse(y_lin_df, y_pred))\n",
    "\n",
    "\n",
    "def simple_linear_regression_manual_demo_2(): \n",
    "    interact(plot_regression, \n",
    "         b0=FloatSlider(min=-10, max=10, step=0.01, value=0), \n",
    "         b1=FloatSlider(min=-3, max=3, step=0.01, value=1), \n",
    "         xlim=fixed((-10, 10)), \n",
    "         ylim=fixed((-10, 10)));\n",
    "\n",
    "simple_linear_regression_manual_demo_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So by now you should be convinced that the metric we gave you works.\n",
    "\n",
    "But ok, doing this manually sucks. So, humans developed optimization algorithms to allow machines to adjust $\\beta_0$ and $\\beta_1$ according to some dataset. There are a few ways of doing this:\n",
    "\n",
    "1. Closed form solution through normal equations;\n",
    "2. Iterative methods using gradients;\n",
    "3. Evolutionary methods like genetic algorithms or particle swarm; \n",
    "4. Bayesian optimization.\n",
    "\n",
    "We will explore the first method here, since it is the standard form of solving simple regression problems, and will introduce the gradient descent method also. Gradient descent methods are quite usefull because they provide a, somehow, universal approach to optimization tasks and are really simple to grasp. Although we will use a simple version in this Learning Unit,  you will learn more about it on the next SLU for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 -  Closed form solution of Simple Linear Regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In any optimization problem, our goal is to minimize the error. This is, if our error function has a global minima with respect to the parameters of the model, those are the parameters we want to find. Take the plot below:\n",
    "\n",
    "![cost-function-decrease](assets/cost-function-decrease.jpg)\n",
    "\n",
    "Assuming our function is convex, the problem of getting the minimum can be solved by looking for the point where the derivative is zero. This is exactly what we will do in both the closed form solution and in iterative methods. So, depending on our error function we use, we need to find ways of derivating with respect to each weight in our equations. \n",
    "\n",
    "This sounds like a lot. So if you are not familiar with these concepts at all, you might start to despair.\n",
    "\n",
    "![cost-function-decrease](assets/derivative-panic.gif)\n",
    "\n",
    "\n",
    "But don't worry, we know this is a bootcamp, we're not gonna ask you to learn derivatives over the night. In the same way we provide you with the error measure, we'll also give you the derivatives with respect to the weights.\n",
    "\n",
    "### 1.3.1 - Derivative of error function\n",
    "\n",
    "The derivatives of the error function with respect to our weights are actually very simple expressions. If you are interested in how to get there, you can take a look at the deduction in [this notebook](bonus/Derivatives%20and%20closed%20form%20for%20simple%20linear%20model.ipynb). But for now, just know that we are not tricking you:\n",
    "\n",
    "\n",
    "First we have the derivative of the intercept:\n",
    "\n",
    "$$\\frac{d J}{d \\beta_0} = -\\frac{1}{N} \\sum_{i=1}^N [2 (y_i - \\hat{y_i})] $$\n",
    "\n",
    "And then the derivative of the coefficient:\n",
    "\n",
    "$$ \\frac{d J}{d \\beta_1} = -\\frac{1}{N}\\sum_{i=1}^N [2( y_i - \\hat{y_i})x_i] $$\n",
    "\n",
    "We could also easily implement them as lambda functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_derivative_b0 = lambda y, y_hat: (2*(y - y_hat)).mean()\n",
    "mse_derivative_b1 = lambda y, y_hat, x: (2*(y - y_hat)*x).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 - Closed Form Solution\n",
    "\n",
    "Let's move on to the final part. After all, the goal of all these equations is just to get a solution for our model, right? \n",
    "\n",
    "As we explained before, the closed form solution comes from looking for the point where the derivatives are zero. Once again, we will only show you the final result of doing that, but please look to [this notebook](bonus/Derivatives%20and%20closed%20form%20for%20simple%20linear%20model.ipynb) if you want to see how to get there, step by step. The solution for the simple linear regression is then:\n",
    "\n",
    "$$ \\frac{d J}{d \\beta_0} = 0 \\rightarrow \\beta_0 = \\bar{y} - \\beta_1 \\bar{x} $$ \n",
    "\n",
    "$$ \\frac{d J}{d \\beta_1} = 0 \\rightarrow  \\beta_1 = \\frac{\\sum_{i}^{N}{(x_i - \\bar{x})(y_i - \\bar{y})}}{\\sum_{i}^{N}{(x_i - \\bar{x})^2}} = \\frac{cov(x, y)}{var(x)}$$\n",
    "\n",
    "with cov(x,y) and var(x) are, respectively, the covariance and variance of the samples and $\\bar{y} = \\frac{1}{N}\\sum_{i}^{N}{y_i}$ and $\\bar{x} = \\frac{1}{N}\\sum_{i}^{N}{x_i}$ are the means of the sample.\n",
    "\n",
    "Let's try it out for our previous problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('data/linear-learning-notebook.csv')\n",
    "df = df.sort_values('x')\n",
    "x_lin_df = df['x'].values\n",
    "y_lin_df = df['y'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first compute the means of our sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = x_lin_df.mean()\n",
    "y_mean = y_lin_df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compute the coefficient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: -1.144592552399212\n"
     ]
    }
   ],
   "source": [
    "top = np.sum((x_lin_df - x_mean)*(y_lin_df - y_mean))\n",
    "bottom = np.sum((x_lin_df - x_mean)**2)\n",
    "beta_1 = top/bottom\n",
    "\n",
    "print('Coefficient: {}'.format(beta_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we compute the intercept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: -0.4517184116834487\n"
     ]
    }
   ],
   "source": [
    "beta_0 = y_mean - beta_1 * x_mean\n",
    "\n",
    "print('Intercept: {}'.format(beta_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot below the data and the solution found, together with the error measure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.7232679595171865\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXhU1f3H8feXTRQVFfChCohrEZWwBCGIgiyuKFVbixaKYokrKq4V9x33Yl1xrYrigqhVq6IIaAlgAggiVK36w60VrbQWFUS+vz/OhIaQfW5y5858Xs+TJ8lk5twvGj5zOPcs5u6IiEhyNYq7ABERSY+CXEQk4RTkIiIJpyAXEUk4BbmISMI1ieOirVu39o4dO8ZxaRGRxCopKfnK3duUfzyWIO/YsSPFxcVxXFpEJLHM7P8qelxDKyIiCacgFxFJOAW5iEjCKchFRBJOQS4iknCRBLmZjTWzJWb2jpk9ZmbNo2hXRESql3aQm9n2wOlAvrvvCTQGhqXbroiI1ExUQytNgE3NrAmwGfB5RO2KNJhVa1axas2quMsQqbW0g9zdPwNuBJYDXwD/dvdXyj/PzArNrNjMilesWJHuZUUit+yrZSz7alncZYjUWhRDK1sDQ4Edge2AFmY2vPzz3H2iu+e7e36bNhutMBURkTqKYmhlEPCRu69w9x+Bp4E+EbQrIiI1EEWQLwd6m9lmZmbAQGBpBO2KiEgNRDFGPhd4CpgPLE61OTHddkVEpGYi2f3Q3S8FLo2iLRERqR2t7BQRSTgFuYhIwinIRUQSTkEuIpJwCnIRkYRTkIuIJJyCXEQk4RTkIiIJpyAXEUk4BbmISMIpyEVEEk5BLiKScApyEZGEU5CLiCScgjxqf/kLfPBB3FWISA6JJMjNbCsze8rMlpnZUjMriKLdxPnxRzj5ZOjWDR55JO5qRCRHRNUjnwC85O6dgDxy9ai3pk3hjTdCkI8YASNHwrffxl2ViGS5tIPczFoC+wH3Abj7GndfmW67idW+PUyfDpdeGnrlPXpASUncVYlIFouiR74jsAJ4wMwWmNm9Ztai/JPMrNDMis2seMWKFRFcNoM1aQKXXRYC/bvvoKAAbrkF3OOuTESyUBRB3gToDtzp7t2AVcDvyz/J3Se6e76757dp0yaCy2amoiK49trwmX794O234ZBD4KyzYMgQ+PLLuEsUkSwTRZB/Cnzq7nNT3z9FCPacU1QEAwfCxReHz0VFQKtWMHUq3HYbvPYa5OWFzzVoa/0bgohIFdIOcnf/B/CJmf089dBA4N10202iGTNgzRr46afwecaM1A/M4NRTYe5c2GorGDwYxo0Ls1wqUOEbQgXPUdCLCEQ3a2UMMMnMFgFdgWsiajdR+veHZs2gcePwuX//ck/Iy4PiYjjhhJDC++0HH320UTuVviGk1CToRSR3RBLk7r4wNf7dxd1/4e7fRNFu0hQUhFGTK68Mnwsqmk3fogXccw9Mngzvvgtdu8ITT2zwlOreEKoLehHJLVrZGbGCArjggkpCvKxf/xoWLoTOncPXo0fDqlXr2yj7hgAbDqNU2/MXkZzSJO4CctqOO8KsWWHO+fjx8Oab8Pjj0KULBQUh0EuHUdasCaFd2tN/7bXQE+/fvwZvGiKS1dQjj1vTpnDNNTBtGqxcCXvvDbffvn7OeWXDKDXu+YtI1lOQx2z97JPNBsKiRaH7fdppcMQR8PXXGkYRkWppaCVGGw+btKHgz3+GCRPg/PMhL4+CSZN47bV+GkYRkUqpRx6jCodNGjWCsWNDym+2GQwYQMHLl3HBuWsbJMQ1P10kedQjj1HpsElpj3yDYZPSzbbGjIHLLw93Nx99NGzKVU8qu7EqIplNPfIYVTvvfIst4MEHwy6KCxeGBUVTp9ZbPZqfLpJMCvKY1Wj2yW9+AwsWwM47w5FHwimnwPffR16LbqyKJJOCPCl22QX++lc45xy4807o1SusDI1QjVamikjGUZAnSbNmcMMN4VzQf/4T8vNh4sRI9znX/HSR5FGQJ9FBB4V9zvv2hRNPDEv8V+buoUwiuU5BnlRt28JLL8F114UboF27wuzZGzxFUwlFcoOCPMkaNYLzzgt7tDRqFLbFvfpq+OknbXUrkkMU5NmgV68wq+Xoo+Gii2DwYIqf+1xTCUVyhII8W7RsCZMmwf33w9y5nHRnF4Y2fl5TCUVyQGRBbmaNzWyBmT0fVZtSS2Zw/PFQUkLTju2YsuYwinqdyfS/rNYsFJEsFmWP/AxgaYTtSV116gRz5sDpp9Nz9gR6jy2A996LuyoRqSeRBLmZtQMOBe6Noj2JQPPmYRfF556D5cuhe/ew3D/COecikhmi6pH/ATgPWFfZE8ys0MyKzax4xYoVEV1WqnXYYWHOec+eYdhl+HD4z3/irkpEIpR2kJvZEOBLdy+p6nnuPjF1QHN+mzZt0r2sVKCyeeNFy7dn/KBXWT76ynCUXLdu8NZb8RQpIpGLoke+D3C4mX0MTAYGmNkjEbQrtVDZvPHSxy+6tDGdHrmId26fCWvXQp8+Ybn/ukr/ESUiCZF2kLv7Be7ezt07AsOA6e4+PO3KpFYq24K2/ON//tc+YUvcoUPDYqJDDgn7tohIYmkeeZaobAvaCh/femt48km46y6YORO6dIFXXomtdhFJT6RB7u4z3H1IlG1KzVS2BW2lW9OahQ23iouhTRs48MDQQ1+zJrY/g4jUjY56yyIFBRVvP1vZ4wDssUe48XnWWWHMfMYMeOyxcIiFiCSChlYENt00HFbx1FPw/vthVsujj8ZdlYjUkIJc/ueoo8Kc8y5dwvFyxx8P//1v3FWJSDUU5LKhDh3C8MrFF8Of/gQ9eoSdFUUkYynIZWNNmsAVV8D06bBqFfTuHZb7a3m/SEZSkEvl+vcPc84PPBDOPDMs99f2CiIZR0EuVWvdGp59Fm69FaZNg7w8eP31erucjqcTqT0FeQ6qdViawZgxMG8ebLllas3/RWGpf8R16Xg6kdpTkOeYiROhX7+Qw7UOy7w8KCkJs1muvjqcEfrxx5HVVtk2AyJSNQV5DikqglNPhR9/DHtlrV5dh7Bs0QLuuy8sGlqyBLp2Dcv9I1DZNgMiUjUFeQ6ZMWPDzQ4bN04jLIcNC9MSO3UKhz4XFsJ336VVX6XbCYhIlRTkOaR/f9hkE2jUKMwwvO22NMNyp53gjTfg/PPhnnsgPx8WL06rxoICuOAChbhIbSjIc0hpj/eqq2DWrNCJTlvTpjB+fNg98ZtvwklEd9yhOeciDUibZuWYKjfQSsfgwWF5/8iRYSB+2rQwlr7NNvVwMREpSz1yiURREVx737YUXfQC3HQTvPBCmOXyxhtxlyaS9aI4s7O9mb1uZu+a2RIzOyOKwiQ5Npj/PbgRRQVnhQebNw8D85dfHuYUVvF6LQISqbsoeuRrgbPdvTPQGzjVzDpH0K4kRIXzv3v0gPnz4dhj4bLLYMAA+OSTjV4b9SIgvSlILorizM4v3H1+6utvgaXA9um2K8lR6fzvLbaAhx+Ghx4KC4ny8sJy/zLSWQRUPrS1MlRyVaQ3O82sI9ANmFvBzwqBQoAOHTpEeVmJWelsmBkzQohvdDN1xAgWbNKbtmOH8bNf/CLcDL3xRmjefP2bwJo1tVsEVBraa9aEN5BRo8Lj5d8UNI1RckFkQW5mmwNTgDPd/T/lf+7uE4GJAPn5+ZqblmWqmg1TVAQDj9sVVs/m2ibjOOP2m8P8x8cfp6Bg96rfBCpRtif/009w991hJmST1G+0VoZKLokkyM2sKSHEJ7n701G0Kdljfeiu24Sz7SZ+NnIgR794XBhHv/VWCk44gYICq1WbpT35H34IU9bdQ6CPHh3OxqjNm4JI0kUxa8WA+4Cl7n5z+iVJtik/ht7+xEPCnPM+fULyDhsGK1fWqs3S4ZwTTwyrVUvb/u1vtTJUco95mivwzKwv8AawGCjdyWOcu79Y2Wvy8/O9uLg4retKshQVVTB8sm4dXH992Iqxfftw4HMdErjCtuug5PMSAHps16PujYjUIzMrcff8jR5PN8jrQkEuG5gzB445JkxPvPLKsHdLo4Zfq6Ygl0xXWZBrZafEr3fvsJPiUUfBuHFhuf/nn8ddlUhiKMglcnValLPVVjB5Mtx7b3hhXh68WOnonIiUoSCXSKW1KMcMTjghLB7abjs49FA466xwAkYEdWnFp2QrBblEKpLj2nbfHebOhdNOg1tuCbNb3nuvzjVpxadkOwW5RCqy49qaN4c//hGeeSacC9q9e1jqXwc6C1SynYJcIhX5cW1Dh4Y55z16hL3OR4yAb7+t9mVlh1J0FqhkOx0sIZGL/PCKdu1g+nS45pqwk2JRUbgxmr/RLCxgw31YmjULbyh12QZAJCnUI5dkaNw4DHLPnBkSuk+fcIBF2dOkUyoaStFZoJLNFOSSKEWN+3LLyIV83WcInHNOmNnyz39u8BwNpUiuUZBLYpQOmZx77Ta0nzuFD8+5I3S38/LCGaEpkY/Ti2Q4BbkkxgZDJj8aj29zMrz1FrRqBQccEJb2//gjoKEUyS0KckmMCodM9twzhHlhYdiAq29f+PDDmCsVaVgKckmMSodMNtssnCzxxBPwt79Bt25hVotIjlCQS6JUOWTyq1+FOed77hl2Uxw1ClatavAaRRqaglyyRlERXPvoDhSNnwkXXggPPhgWEi1cmH672qdFMlhUR70dBEwAGgP3uvv4KNoVqakNFwE14bXXrqJgwAAYPhx69YIbboAxY8LGXHVuV7NgJDNFcdRbY+B24GCgM3CMmXVOt12R6pTtKVe4n8qAAbBoUZjRcsYZYbn/V1/V6hrap0WSIIoe+d7AB+7+IYCZTQaGAu9G0PYGVq1ZxbKvlkXdrCTQosVw8klhtmHTiXD2OdCkPfiP0KQptO0OJaVnU9x1KUz+Odw6AQbuDlddBT02Xt6/dMXSjR5r272KdkXqoFPrTrRo1iLSNqMI8u2BT8p8/ynQq/yTzKwQKATo0KFDBJeVXFZSHEJ83brw+d8r4c67wuM98qHLXmWebBZufnbvBheMg5NOglEnQOFoaFz1X4Eue1XRrkiGiOLw5V8CB7n771LfjwB6uftplb1GZ3ZKuuo8dv3f/4ax8gcfhH32gUmTYIcdAJ3ZKZmvPs/s/AxoX+b7dqnHROpNnZfhb745PPBACPBFi6BrV5gypV5rFalvUQytvAXsamY7EgJ8GHBsBO2KVCmt7XKPPTbMZjnmGPjlL+HEE3nn0BG8tag5awZoZookS9o9cndfC5wGvAwsBZ5w9yXptitS73beGd58E847D+6+m01P+i0v3/mBjoOTxIlkQZC7v+juu7n7zu5+dRRtijSIZs3guuuYfPzLtPSVPLjutxz3w13MeD29e0ciDUkrO0WAHUYfwHHNHmMB3bnDT6Zw2q/gm2/iLkukRhTkIoQx8WvubsWyU27l49NuoNWbz4Z9zt98M+7SRKqlIBdJ6bIXHD+qER3/eA7Mnh2GXfr1C1Njfvop7vJEKqUgF6lIz54wf36Y1XLJJWHS+qefxl2VSIUU5JJ1otqtsGjJllzb+WE+uOhBKC4OQy3PPRdJjSJRimT3Q5FMUdsVn6UbbvXvD812qKgd48pmI/nrAwV0u25Y2HhrzJhwGlHz5vX9xxGpEfXIJavUZrfC0rC++OLwedHiytt56cPdwgvOPBP++Efo3RuWaQM3yQwKcskqFZ7rWYnyYV1SZvufitopmr8J1257C0tveB4++ywcWnH//ZDmfkUi6dLQimSV0j1YSodLqhpWKQ3r0mGYsjvblm8H/jdkc2WzQ5k1+W3yJ4yAE06AV14JZ4a2bFlvfy6RqijIJevUdA+W8mFddoy8fDvXXrth733aku348fJXWN3kOvo9dQk2bx489ljYv0WkgWloRXJalYc5l1F+qKVVKxh4QGMGvTaOAY1n8cP366BvXxg/PmySLtKAFOQiNVB+29yvv/5fD/2Nn/pwx+iFcMQR4V3hwAPhiy/iLllyiIZWRGqo/JBN2fH1goO3gssfh8GDw/mgeXnwpz/BwQfHV7DkDPXIReqgwoMtzGD06LB4qG1bOOQQOPvskPYi9Ug9cpE6qvSmaufOMHcunHMO3HwzzJwJkyfDLrs0eI2SG9LqkZvZDWa2zMwWmdlUM9sqqsJEMl2VWwFsuincfjtMnQoffgjdusEjjzR4jZIb0h1amQbs6e5dgPeAC9IvSSTzlV8VWum+Lr/4Bbz9dgjyESNg5Ej49tsGrVWyX1pB7u6vpI56A5hDOHhZJOvVZisA2reH6dPhsstCr7xHDygpaZhCJSdEebNzFPCXyn5oZoVmVmxmxStWrIjwsiINrzZbAQDQpAlceim8/jp8/30YXL/5Zs05l0hUG+Rm9qqZvVPBx9Ayz7kQWAtMqqwdd5/o7vnunt+mTZtoqheJSYWzVmpiv/1g4UI49NAwo2XIEPjyy3qtVbJftbNW3H1QVT83s+OAIcBAd+0eJLmjplsBbKRVK4rOfZr/rLuTwS+dRaO8PHj4YRhU5V81kUqlO2vlIOA84HB3/y6akkSyW1ERDBxkHPrCKfS2eXzXfGs44ICwKvTHH+MuTxIo3THy24AtgGlmttDM7oqgJpGsVvZG6fy1XbjjuLfgd78L+7Tsuy989FHcJUrCpDtrZRd3b+/uXVMfJ0VVmEi2Kn+jdJ8DWsDEifD44+Gwiq5dw9cNIKpj8SReWtkp0sDKbp/bqtX/pi4WHH007L13OPB52DCYNg0mTIAWLeqljtoeiyeZS0EuEoPSwNw4SDvCrFlhquL48fDXv4beeZcukddQ0Vx4BXkyadMskZhUuqioaVO45prQI1+5MvTSb7st8iPlaj0XXjKWglwkJtUG6cCBYXn/wIEwZkzY7/zrryO7fp3nwkvG0dCKSExqdL7ottvCn/8cxsrPPz/scz5pEvTrF1kNCvDkU49cJEY1OmquUSMYOzbcndx0UxgwIIyhr11bxYuqptkq2UVBLpIUPXrA/PkwfDhccQXsvz8sX77+xzUN5xrv3CiJoSAXSZIttghHyD38cNizpWtXmDq1VuFcq50bJREU5CIZrNJe9vDhsGAB7LQTHHkkm4w9hUarv69ROGu2SvbRzU6RDFXtgp1ddoHZs2HcOLrfdBNz7A2ObTSZD5rtUWU41+gmqySKeuQiGapGQyDNmsGNN8KLL/Lzlv+kpHFPFo+ZSEHvquec1+gmqySGglwkQ9VqCOTgg2m6dBFN+/dl5+tPhKOPDouJJCcoyEUyVK0X7LRtCy+9BNddB888E26Ezp7dILVKvBTkIhms1kMgjRrBeefBm2+Gr/fbD66+OozPSNZSkItko169wqyWo4+Giy6CwYPhs8/irkrqiYJcJFu1bBmW899/P8ydG5b3P/983FVJPYgkyM3sbDNzM2sdRXsiEhEzOP54KCmBdu3gsMPgjDNg9eq4K5MIpR3kZtYeOABYXt1zRSQmnTrBnDlw+ulw663Quzf87W9xVyURiaJHfgvhAOZoN0sWkWg1bx52UXzuOfjkE+jeHR54YP0+59pIK7nSWtlpZkOBz9z9bTOr7rmFQCFAhw4d0rmsiKTjsMPCPufDh8OoUTBtGvNG3cXAw7fUsW8JVW2P3MxeNbN3KvgYCowDLqnJhdx9orvnu3t+mzZt0q1bRNKx/fbw6qtw1VXwxBPs+utu5K2ep420EqraIHf3Qe6+Z/kP4ENgR+BtM/sYaAfMN7O29VuyiESicWO48EKYOZPNmq5l1rp9ON+uZ5Om67SRVsLUeYzc3Re7+7bu3tHdOwKfAt3d/R+RVSci9W+ffXj7TwtZvNNQxvv5fNblYAp21F/jJNE8cpEsU9ublkVF0P+Iren50ZOc3OhuNl8wK8w5f/nl+i1UIhNZkKd65l9F1Z6I1F5dTv+ZMSNMK1/nxl3rCsn3Yr7bfFs46CA499wwaC4ZTT1ykSxSl9N/+vcP27KUWrxuD24fOQ9OPjlskdu3L/z97/VUsURBQS6SRepy+k9BAdx+OzRtGgJ9k02g7+BN4Y47YMoUeP996NYtLPeXjKQTgkSySF1P/ykshL32quB1Rx4J+fnwm9+EeefTpsFtt8Hmm9e4pqIinUZU38y94Rdk5ufne3FxcYNfV6QqJZ+XANBjux4xVxKNSAN07dqwMfqVV8Kuu8LkyaGXXoMaqjyuTmrFzErcPb/84xpaEclCdbnpWaUmTeDyy2H6dFi1KuzVMmHC+uX9lalszF7bAURLQS6Shepy07NG+veHhQvhwAPhzDPDcv8VK6p8evkx+8jfZERBLpKN6nLTs8Zat4Znnw27KE6bFuacv/56hU+t6Li6enuTyWEKcpEsVOvzPsuo0bCHGYwZA/PmwZZbhq71RReFsfQKail7XF29vsnkKM1aEclSBQW1v7FY65uTeXnh0IrTTw9ng06fDo8+Ch07VllXXWbWSOXUIxeR9eo07NGiBdx3Hzz2GCxZAl27wpNPVvmSWh8qLVVSkIvIemkNewwbFg587tQpHPpcWAjffVdPlUpZCnIRWS+dsXUAdtoJ3ngDfv97uPfesJho8eJ6qVX+R0EuIhtIe9ijadNwt/SVV+Cbb6Bnz7Dcv54XH+by3HQFuYjUj0GDwpFyAwbAqafCUUfBv/5VL5fK9bnpCnIRqT/bbgvPPw833RQ+5+XBrFmRXybX56anHeRmNsbMlpnZEjO7PoqiRCSLNGoEZ50VusnNm8P++8Nll1U457yucn1uelrzyM1sf2AokOfuq81s22jKEpGs06MHzJ8fhllK922ZNAnat0+76Vyfm55uj/xkYLy7rwZw9y/TL0lEkqhGNxu32AIeeih8LFgQhlqeeSaS6+fy3PR0g3w3YF8zm2tmM82sZ2VPNLNCMys2s+IVVWyyIyLJU+ubjSNGhN75TjvBEUeEXvr33zdIrdmo2iA3s1fN7J0KPoYShma2AXoD5wJPmJlV1I67T3T3fHfPb9OmTaR/CBGJV51uNu66K8yeHcbP77gDevWCd9+t50qzU7VB7u6D3H3PCj6eBT4FnvZgHrAOaF3fRYtIZqnzzcZmzcKMlhdfhH/8Iywguueeep9znm3SHVp5BtgfwMx2A5oBX6VblIgkS9orQg8+OMw532efsLT/17+GlSvrpdZslG6Q3w/sZGbvAJOBkR7H2XEiEru0bzb+7Gfw8sswfjxMnRo238q1lT11lFaQu/sadx+eGmrp7u7ToypMRHJQo0Zw/vlhvxYz2HdfuOaaMPguldLKThHJPL17hyPlfvlLuPBCOOAA+PzzuKvKWApyEclMLVuGPc7vuw/mzAlzzl94Ie6qMpKCXEQylxmMGgXFxbDddjBkCIwdC6tXx11ZRlGQi0jm2313mDs3nBP6hz9Anz7w3ntxV5UxFOQikgzNm8Ott8Kzz8LHH0P37mGpvyjIRSRhDj88zDnPz4eRI2H4cPj227iripWCXESSp127sPLoiivCDdFu3cI4eo5SkItIMjVuHHbpmjkzbPDSp09Y7r9uXdyVNTgFuYgkW9++Yc75kCFhzvnf/x53RQ0urYMlREQywjbbwJQpYffEXXeNu5oGpx65iCTWBodZmMEee8RdUizUIxeRRCo9zGLNmrAbbp12XcwS6pGLSCLV6TCLLKUgF5FEqvNhFllIQysikkilh1nMmBFCPFeHVSDNIDezrsBdQHNgLXBK6sg3EZF6V1CQ2wFeKt2hleuBy929K3BJ6nsREWlA6Qa5A1umvm4JaOd3EZEGlu4Y+ZnAy2Z2I+FNoU9lTzSzQqAQoEOHDmleViR6nVp3irsEkTqx6s5KNrNXgbYV/OhCYCAw092nmNnRQKG7D6ruovn5+V6cwxvciIjUhZmVuHt++cer7ZFXFcxm9hBwRurbJ4F761yhiEgaiopydwZLukMrnwP9gBnAAOD9dAsSEamtXF/lmW6QjwYmmFkT4AdSY+AiIg2polWeCvIacvc3gR4R1SIiUielqzxLe+S5tspTKztFJPFyfZWnglxEskIur/LUplkiIgmnIBcRSTgFuYhIwinIRUQSTkEuIpJwCnIRkYSrdtOsermo2Qrg/+r48tbAVxGWExXVVTuqq3ZUV+1kal2QXm07uHub8g/GEuTpMLPiinb/ipvqqh3VVTuqq3YytS6on9o0tCIiknAKchGRhEtikE+Mu4BKqK7aUV21o7pqJ1PrgnqoLXFj5CIisqEk9shFRKQMBbmISMIlMsjNrKuZzTGzhWZWbGZ7x11TKTMbY2bLzGyJmV0fdz1lmdnZZuZm1jruWgDM7IbUf6tFZjbVzLaKuZ6DzOxvZvaBmf0+zlpKmVl7M3vdzN5N/U6dUf2rGo6ZNTazBWb2fNy1lDKzrczsqdTv1lIzy4jNbc1sbOr/4Ttm9piZNY+q7UQGOXA9cLm7dwUuSX0fOzPbHxgK5Ln7HsCNMZe0npm1Bw4AlsddSxnTgD3dvQvwHnBBXIWYWWPgduBgoDNwjJl1jqueMtYCZ7t7Z6A3cGqG1FXqDGBp3EWUMwF4yd07AXlkQH1mtj1wOpDv7nsCjYFhUbWf1CB3YMvU1y0Jh0BngpOB8e6+GsDdv4y5nrJuAc4j/LfLCO7+iruvTX07B2gXYzl7Ax+4+4fuvgaYTHhTjpW7f+Hu81Nff0sIpe3jrSows3bAocC9cddSysxaAvsB9wG4+xp3XxlvVes1ATZNnXG8GRHmVlKD/EzgBjP7hNDrja0nV85uwL5mNtfMZppZz7gLAjCzocBn7v523LVUYRTwlxivvz3wSZnvPyVDArOUmXUEugFz461kvT8QOgfr4i6kjB2BFcADqSGfe82sRdxFuftnhKxaDnwB/NvdX4mq/Yw96s3MXgXaVvCjC4GBwFh3n2JmRxPefQdlQF1NgG0I/wTuCTxhZjt5A8zxrKaucYRhlQZXVV3u/mzqORcShhAmNWRtSWJmmwNTgDPd/T8ZUM8Q4Et3LzGz/nHXU0YToDswxt3nmtkE4PfAxXEWZWZbE/6FtyOwEnjSzIa7+yNRtJ+xQe7ulQazmT1EGJsDeJIG/KddNXWdDDydCu55ZraOsEHOirjqMrO9CDBZmPcAAAGESURBVL88b5sZhOGL+Wa2t7v/I666ytR3HDAEGNgQb3hV+AxoX+b7dqnHYmdmTQkhPsndn467npR9gMPN7BCgObClmT3i7sNjrutT4FN3L/1Xy1OEII/bIOAjd18BYGZPA32ASII8qUMrnwP9Ul8PAN6PsZayngH2BzCz3YBmxLwDm7svdvdt3b2ju3ck/KJ3b4gQr46ZHUT4p/nh7v5dzOW8BexqZjuaWTPCjajnYq4JC+++9wFL3f3muOsp5e4XuHu71O/UMGB6BoQ4qd/rT8zs56mHBgLvxlhSqeVAbzPbLPX/dCAR3oTN2B55NUYDE1I3DX4ACmOup9T9wP1m9g6wBhgZcy8z090GbAJMS/1rYY67nxRHIe6+1sxOA14mzCi4392XxFFLOfsAI4DFZrYw9dg4d38xxpoy3RhgUuoN+UPg+JjrITXM8xQwnzCMuIAIl+prib6ISMIldWhFRERSFOQiIgmnIBcRSTgFuYhIwinIRUQSTkEuIpJwCnIRkYT7f3Rwt8xvHymZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = linear_regression(x_lin_df, beta_0, beta_1)\n",
    "plt.plot(x_lin_df, y_lin_df, 'b.')\n",
    "plt.plot(x_lin_df, y_pred, 'r-')\n",
    "plt.plot([0, 0], [-8, 8], 'g-', [-8, 8], [0, 0], 'g-', linewidth=0.4)\n",
    "\n",
    "print(\"Mean Squared Error (MSE): {}\".format(linear_regression_mse(y_lin_df, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it, we've implemented a closed form of solving the simple linear regression. This form can be extended for the multiple linear regression problem you are going to see below. It is also known as **Ordinary Least Squares**, since it minimizes the squared error, and it is actually what is implemented (with a bit more detail) inside scikitlearn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Multiple Linear Regression\n",
    "\n",
    "The simple linear regression is a good example to get you started, but most phenomena in our world is dependent on several factors. For example, house prices depend on things like (1) number of rooms, (2) distance to malls, (3) distance to parks, (4) how old the house is, etc. As such, it would be naive, at best, to create a univariate linear model to predict the house prices. So, let's expand our simple linear regression into *multiple* linear regression:\n",
    "\n",
    "$$\\hat{y} = \\beta_0 + \\beta_1 \\cdot x_1 + \\beta_2 \\cdot x_2 + \\beta_3 \\cdot x_3 + \\beta_4 \\cdot x_4 + \\beta_5 \\cdot x_5$$ \n",
    "\n",
    "This can also be written in a collapsed form:\n",
    "\n",
    "$$\\hat{y} = \\beta_0 + \\sum_{i=1}^{5} \\beta_i \\cdot x_i$$\n",
    "\n",
    "And the model generalizes to the following:\n",
    "\n",
    "$$\\hat{y} = \\beta_0 + \\sum_{i=1}^{N} \\beta_i \\cdot x_i$$\n",
    "\n",
    "with an arbitrary number of weights, which correspond to the input features. We can also write it as the combination of matrices:\n",
    "\n",
    "$$\\hat{y} = \\beta_0 + X\\vec{\\beta} $$\n",
    "\n",
    "Where $X$ is a matrix with shape (num_samples, num_features) and $\\vec{\\beta}$ the vector of coefficients. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Implementing and visualizing a multiple linear model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is still a simple model, and we can implement it with a lambda function again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_linear_regression = lambda x, betas: betas[0] + np.matmul(x, betas[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple linear regressions are a not as easy to visualize, since they have multiple inputs that affect the output, which, instead of a line, results in a **hyperplane**. However, there is a particular case that we can model and visualize quite easily - the polynomial regression.\n",
    "\n",
    "Polynomial functions are defined as follows:\n",
    "\n",
    "$$\\hat{y} = \\beta_0 + \\beta_1 x +  \\beta_2 x^2 + ... +  \\beta_n x^n $$\n",
    "\n",
    "where $n$ is the order of our polynomial function.\n",
    "\n",
    "You might be wondering how we can model these functions, which are clearly not linear, with a linear model. The main thing you need to understand is that, even though the inputs are not linear, the model is linear with respect to the coefficients, this is, we can easily assume each power of $x$ as a different input:\n",
    "\n",
    "$$ x = x_1 $$\n",
    "$$ x^2 = x_2 $$\n",
    "$$...$$\n",
    "$$ x^n = x_n $$\n",
    "\n",
    "And have the same model from above\n",
    "\n",
    "$$\\hat{y} = \\beta_0 + \\sum_{i=1}^{N} \\beta_i \\cdot x_i$$\n",
    "\n",
    "Run the next cell to see how a polynomial model can be represented as a multiple linear model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_polynomial_regression_multiple(x, y, xlim, ylim):\n",
    "    origin = (0, 0)\n",
    "\n",
    "    plt.xlim(xlim)\n",
    "    plt.ylim(ylim)\n",
    "\n",
    "    # Plot axis for better visuzlization\n",
    "    plt.plot(origin, ylim, 'g:', xlim, origin, 'g:', linewidth=0.4)\n",
    "\n",
    "    # Plot linear model\n",
    "    plt.plot(x, y, 'b')\n",
    "    plt.show()\n",
    "\n",
    "# Base independent variables\n",
    "x_pln = np.arange(-10, 10, 0.1).reshape(-1, 1)\n",
    "x_pln_2 = x_pln ** 2\n",
    "x_pln_3 = x_pln ** 3\n",
    "\n",
    "# Organize input in a matrix\n",
    "X_pln = np.concatenate((x_pln, x_pln_2, x_pln_3), axis=1)\n",
    "\n",
    "# Parameters\n",
    "betas_pln = [1, -2, .025, .3]\n",
    "\n",
    "# Dependent variable\n",
    "y_pln = multiple_linear_regression(X_pln, np.array(betas_pln))\n",
    "plot_regression_simple(x_pln.flatten(), y_pln, [-10, 10], [-10, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's follow the same procedure we followed for the simple model and imagine that we have some data with noise that we want to fit. Let's load it and visualize its shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4b9155d3c8>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('data/polynomial-learning-notebook.csv')\n",
    "df = df.sort_values('x')\n",
    "\n",
    "x_pln_df = df['x'].values\n",
    "y_pln_df = df['y'].values\n",
    "X_pln_df = df.drop(columns='y').values\n",
    "\n",
    "plt.plot(x_pln_df, y_pln_df, 'b.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to do the same as before , and find the weights manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6eeea8a7094c8e92afcc2218ff65be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='b0', max=10.0, min=-10.0, step=0.01), FloatSlider(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_polynomial_regression(b0=0, b1=1, b2=0, b3=0, xlim=(-20, 20), ylim=(-20, 20)):\n",
    "    betas = np.array([b0, b1, b2, b3])\n",
    "    y_pred = multiple_linear_regression(X_pln_df, betas)\n",
    "    plt.xlim(xlim)\n",
    "    plt.ylim(ylim)\n",
    "    plt.plot(x_pln_df, y_pln_df, 'b.')\n",
    "    plt.plot(x_pln_df, y_pred, 'r-')\n",
    "    plt.plot([0, 0], ylim, 'g-', xlim, [0, 0], 'g-', linewidth=0.4)\n",
    "\n",
    "def polynomial_regression_manual_demo_1(): \n",
    "    interact(plot_polynomial_regression, \n",
    "         b0=FloatSlider(min=-10, max=10, step=0.01, value=0), \n",
    "         b1=FloatSlider(min=-5, max=5, step=0.01, value=1), \n",
    "         b2=FloatSlider(min=-1, max=1, step=0.01, value=0), \n",
    "         b3=FloatSlider(min=-1, max=1, step=0.01, value=0), \n",
    "         xlim=fixed((-20, 20)), \n",
    "         ylim=fixed((-20, 20)));\n",
    "\n",
    "polynomial_regression_manual_demo_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it is much harder now to find these features manually. Let's see if having an error measure this time helps at all:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Error measure for Multiple Linear Regression\n",
    "\n",
    "Using the same logic as before, we still want a way to measure how well our model fits. Notice that, even though our model has several inputs and corresponding increase in parameters, it still produces a single output. \n",
    "\n",
    "This means that we can still define the error as\n",
    "\n",
    "$$ e_i = y - \\hat{y_i} $$\n",
    "\n",
    "So we will use the same cost function as before:\n",
    "\n",
    "$$MSE(y, \\hat{y}) = \\frac{1}{N} \\sum_{n=1}^N (y_n - \\hat{y}_n)^2 $$\n",
    "\n",
    "The only different being how the estimate $\\hat{y}$ is produced. Use it in the interactive demo as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ebfc890bce1458aad18a9ab82dbc06b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='b0', max=10.0, min=-10.0, step=0.01), FloatSlider(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_polynomial_regression(b0=0, b1=1, b2=0, b3=0, xlim=(-20, 20), ylim=(-20, 20)):\n",
    "    betas = np.array([b0, b1, b2, b3])\n",
    "    y_pred = multiple_linear_regression(X_pln_df, betas)\n",
    "    plt.xlim(xlim)\n",
    "    plt.ylim(ylim)\n",
    "    plt.plot(x_pln_df, y_pln_df, 'b.')\n",
    "    plt.plot(x_pln_df, y_pred, 'r-')\n",
    "    plt.plot([0, 0], ylim, 'g-', xlim, [0, 0], 'g-', linewidth=0.4)\n",
    "    return \"Mean Squared Error (MSE): {}\".format(linear_regression_mse(y_pln_df, y_pred))\n",
    "\n",
    "def polynomial_regression_manual_demo_1(): \n",
    "    interact(plot_polynomial_regression, \n",
    "         b0=FloatSlider(min=-10, max=10, step=0.01, value=0), \n",
    "         b1=FloatSlider(min=-5, max=5, step=0.01, value=1), \n",
    "         b2=FloatSlider(min=-1, max=1, step=0.01, value=0), \n",
    "         b3=FloatSlider(min=-0.5, max=0.5, step=0.005, value=0), \n",
    "         xlim=fixed((-20, 20)), \n",
    "         ylim=fixed((-20, 20)));\n",
    "\n",
    "polynomial_regression_manual_demo_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is still very hard to have to handle so many levers. So for the multiple linear regression, automatic methods are even more important. We'll follow with an extension of the closed form solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - Closed form solution of Multiple Linear Regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 - Derivative of error function\n",
    "\n",
    "The derivatives of the error function with respect to our weights are very similar to the ones in the simple scenario. We built another notebook so you can see how to deduct them, so consult [this notebook](bonus/Derivatives%20and%20closed%20form%20for%20multiple%20linear%20model.ipynb) if you are interested in that. \n",
    "\n",
    "The derivative of the intercept remains the same:\n",
    "\n",
    "$$\\frac{d J}{d \\beta_0} = -\\frac{1}{N} \\sum_{i=1}^N [2 (y_i - \\hat{y_i})] $$\n",
    "\n",
    "Then, for the coefficients, the expression is still very similar to the one before. The only detail you need to pay attention to, is that the input multiplied in the derivative is just the one corresponding to the feature that the weight refers to:\n",
    "\n",
    "$$ \\frac{d J}{d \\beta_k} = -\\frac{1}{N}\\sum_{i=1}^N [2( y_i - \\hat{y_i})x_{k_i}] $$ \n",
    "\n",
    "for $ k \\in [1, K] $ , where K is the number of features of our model.\n",
    "\n",
    "Once again, we can implement them as lambda functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_derivative_b0 = lambda y, y_hat: -(2*(y - y_hat)).mean()\n",
    "mse_derivative_bk = lambda y, y_hat, x_k: -(2*(y - y_hat)*x_k).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 - Closed Form Solution\n",
    "\n",
    "For this closed form solution, it is usefull to make use of matrix notation. We can take our initial model, defined above:\n",
    "\n",
    "$$\\hat{y} = \\beta_0 + X\\boldsymbol{\\beta} $$\n",
    "\n",
    "Or even go a step further an write:\n",
    "\n",
    "$$\\hat{y} = X' \\vec{\\beta}$$\n",
    "\n",
    "If we consider a new matrix $X'$ of inputs which is simply the concatenation of a column of ones to our previous inputs matrix:\n",
    "\n",
    "$$ X' = [\\vec{1} | X]$$\n",
    "\n",
    "Once again, the closed form solution comes from looking for the point where the derivatives are zero but we will only show you the final result of doing that. Look to [this notebook](bonus/Derivatives%20and%20closed%20form%20for%20simple%20linear%20model.ipynb) if you want to see how to get there, step by step. The solution for the multiple linear regression is then:\n",
    "\n",
    "$$ \\vec{\\beta} = (X^TX)^{-1}(X^T\\vec{y})$$\n",
    "\n",
    "\n",
    "Where $X$ is our matrix of samples extended to add a 1 component in each sample, $X = [\\vec{1} | X] $ , $\\vec{y}$ is the output vector, and $\\vec{\\beta}$ the weight vector with weights $\\beta_0$ and $\\beta_1$\n",
    "\n",
    "Try it out for the previous example. Let's load the data again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/polynomial-learning-notebook.csv')\n",
    "df = df.sort_values('x')\n",
    "\n",
    "x_pln_df = df['x'].values\n",
    "y_pln_df = df['y'].values\n",
    "X_pln_df = df.drop(columns='y').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-16.500835</td>\n",
       "      <td>272.277569</td>\n",
       "      <td>-4492.807348</td>\n",
       "      <td>-11.705434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-16.413606</td>\n",
       "      <td>269.406474</td>\n",
       "      <td>-4421.931826</td>\n",
       "      <td>-14.654880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-15.112092</td>\n",
       "      <td>228.375336</td>\n",
       "      <td>-3451.229172</td>\n",
       "      <td>0.301304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-13.664511</td>\n",
       "      <td>186.718864</td>\n",
       "      <td>-2551.421999</td>\n",
       "      <td>4.906526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-13.369245</td>\n",
       "      <td>178.736706</td>\n",
       "      <td>-2389.574768</td>\n",
       "      <td>8.195226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x         x_2          x_3          y\n",
       "0 -16.500835  272.277569 -4492.807348 -11.705434\n",
       "2 -16.413606  269.406474 -4421.931826 -14.654880\n",
       "1 -15.112092  228.375336 -3451.229172   0.301304\n",
       "3 -13.664511  186.718864 -2551.421999   4.906526\n",
       "7 -13.369245  178.736706 -2389.574768   8.195226"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pln_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's extend our inputs to have a column of ones: \n",
    "\n",
    "$$ X' = [\\vec{1} | X] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_extended = np.concatenate((np.ones((X_pln_df.shape[0], 1)), X_pln_df), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply the closed form solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.58366246 -2.95329261  0.01443483  0.01440652]\n"
     ]
    }
   ],
   "source": [
    "inv_xx = np.linalg.inv(np.matmul(X_extended.T, X_extended))\n",
    "xy = np.matmul(X_extended.T, y_pln_df)\n",
    "betas = np.matmul(inv_xx, xy)\n",
    "\n",
    "print('Coefficients: {}'.format(betas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's plot the solution we achieved and the error associated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 7.293313137336586\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = multiple_linear_regression(X_pln_df, betas)\n",
    "plt.plot(x_pln_df, y_pln_df, 'b.')\n",
    "plt.plot(x_pln_df, y_pred, 'r-')\n",
    "plt.plot([0, 0], [-21, 21], 'g-', [-16, 16], [0, 0], 'g-', linewidth=0.4)\n",
    "\n",
    "print(\"Mean Squared Error (MSE): {}\".format(linear_regression_mse(y_pln_df, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do an extra example, with a diabetes dataset. This contains several features of individuals and a quantitative measure of disease progression. Load the diabetes dataset below, read its description and look into the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - age     age in years\n",
      "      - sex\n",
      "      - bmi     body mass index\n",
      "      - bp      average blood pressure\n",
      "      - s1      tc, T-Cells (a type of white blood cells)\n",
      "      - s2      ldl, low-density lipoproteins\n",
      "      - s3      hdl, high-density lipoproteins\n",
      "      - s4      tch, thyroid stimulating hormone\n",
      "      - s5      ltg, lamotrigine\n",
      "      - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6   medv  \n",
       "0 -0.002592  0.019908 -0.017646  151.0  \n",
       "1 -0.039493 -0.068330 -0.092204   75.0  \n",
       "2 -0.002592  0.002864 -0.025930  141.0  \n",
       "3  0.034309  0.022692 -0.009362  206.0  \n",
       "4 -0.002592 -0.031991 -0.046641  135.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "data = load_diabetes()\n",
    "print(data['DESCR'])\n",
    "\n",
    "X_db = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "y_db = pd.Series(data['target'], name='medv')\n",
    "\n",
    "pd.concat((X_db, y_db), axis=1).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply our closed form solution and see what output and error we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature coefficients: \n",
      "age    -10.012198\n",
      "sex   -239.819089\n",
      "bmi    519.839787\n",
      "bp     324.390428\n",
      "s1    -792.184162\n",
      "s2     476.745838\n",
      "s3     101.044570\n",
      "s4     177.064176\n",
      "s5     751.279321\n",
      "s6      67.625386\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Intercept: 152.13348416289648\n",
      "\n",
      "\n",
      "\n",
      "Targets for the first 5 rows: \n",
      "\n",
      " [151.  75. 141. 206. 135.]\n",
      "\n",
      "Predictions for the first 5 rows: \n",
      "\n",
      " [206.11706979  68.07234761 176.88406035 166.91796559 128.45984241]\n",
      "Mean Squared Error (MSE): 2859.6903987680657\n"
     ]
    }
   ],
   "source": [
    "X_extended = np.concatenate((np.ones((X_db.values.shape[0], 1)), X_db.values), axis=1)\n",
    "\n",
    "inv_xx = np.linalg.inv(np.matmul(X_extended.T, X_extended))\n",
    "xy = np.matmul(X_extended.T, y_db.values)\n",
    "betas = np.matmul(inv_xx, xy)\n",
    "\n",
    "y_pred = multiple_linear_regression(X_db.values, betas)\n",
    "\n",
    "print('Feature coefficients: ')\n",
    "print(pd.Series(betas[1:], X_db.columns))\n",
    "print('\\n')\n",
    "\n",
    "print('Intercept: {}'.format(betas[0]))\n",
    "print('\\n')\n",
    "\n",
    "print('\\nTargets for the first 5 rows: \\n\\n', y_db.head(5).values)\n",
    "print('\\nPredictions for the first 5 rows: \\n\\n', y_pred[:5])\n",
    "print(\"Mean Squared Error (MSE): {}\".format(linear_regression_mse(y_db.values, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty simple, hein? The extended model is just an extension of the simple one. The more features you have, the more you include in the sum! And we still have a simple closed form solution!\n",
    "\n",
    "But there is a **very important assumption** that this model does: there is no multicollinearity in your data. \n",
    " <em>What the hell does that even mean?</em>, you might ask. This term comes from linear algebra and this is what it means: \n",
    "\n",
    "_If you have a feature $x_i$ which the values can be obtained through a **linear combination** of other features, then we have multicollinearity._\n",
    "\n",
    "Let me give you some of the reasons this is a problem: \n",
    "1. When people use linear regressions, after the parameter estimation phase, they use the coefficients as a way to measure **how important a feature is**. When you use collinear features, the magnitude of the weights gets's lowered for all features that are in that collinear relationship. That might be misleading because collinear features are, essentially, one feature.\n",
    "2. Collinear features add no value to the model, it is like cloning the same feature and concatenating it to the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Linear Regression with Scikitlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After learning the basics of linear regression and how to implement the closed form solutions, it is time to learn how to use linear regression with Scikit Learn. \n",
    "\n",
    "[Scikit Learn][sklearn] is an industry standard for data science and machine learning and we will be using it extensively throughout the academy. Scikit Learn has several implementations of linear regression:\n",
    "* [*sklearn.linear_model.LinearRegression*][LinearRegression]: uses normal equations to estimate the best intercept and coefficients. Normal equations are the closed form solution for linear regression, meaning that you know exactly the number of steps and the guarantees about the solution. If you want to know more about this, [read this blog post][normal_eq].\n",
    "* [*sklearn.linear_model.SGDRegressor*][SGDRegressor]: SGD Regressor is a model that is optimized (trained) using SGD (Stochastic Gradient Descent) for regression tasks. It's basically a linear model that is updated along the way with a decaying learning rate. (go to [Section 4](#grad_desc) to learn more about it)\n",
    "\n",
    "[SGDRegressor]: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html#sklearn.linear_model.SGDRegressor\n",
    "[LinearRegression]: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression\n",
    "[sklearn]: http://scikit-learn.org\n",
    "[normal_eq]: https://eli.thegreenplace.net/2014/derivation-of-the-normal-equation-for-linear-regression\n",
    "\n",
    "For simplicity and because you're new to this world, let's try by implementing the first one *LinearRegression*.\n",
    "\n",
    "Let's start by applying this to the polynomial example from the previous examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-16.5008354 , -16.41360638, -15.11209237, -13.66451113,\n",
       "       -13.36924477, -12.67165836, -12.14314635, -11.37644107,\n",
       "       -11.23973784, -10.97690475, -10.67149005, -10.09348594,\n",
       "        -9.97010186,  -9.70579162,  -9.64050596,  -9.14900462,\n",
       "        -8.40412205,  -7.79029954,  -7.35719393,  -6.73979508,\n",
       "        -6.55749187,  -6.49931373,  -5.79281121,  -5.78036102,\n",
       "        -5.30599573,  -5.1261307 ,  -5.03312842,  -4.11149956,\n",
       "        -3.57064864,  -2.89545828,  -2.68114304,  -2.19684664,\n",
       "        -1.97795051,  -1.14996548,  -0.6944872 ,  -0.64662463,\n",
       "         0.02248541,   0.0398363 ,   0.32521117,   0.84560809,\n",
       "         1.16596893,   1.81603921,   2.17885095,   2.27947194,\n",
       "         3.44749926,   3.59561724,   4.03715026,   4.06472586,\n",
       "         4.21467032,   4.4085518 ,   5.0845349 ,   5.22960577,\n",
       "         6.359208  ,   6.88382742,   6.94724496,   7.30192332,\n",
       "         8.04946477,   8.09253617,   8.24863934,   8.69389025,\n",
       "         9.24259757,   9.47437788,  10.13683133,  10.28899669,\n",
       "        11.29427036,  11.68644633,  12.00897936,  12.141792  ,\n",
       "        12.61901483,  12.68676751,  12.76602737,  14.27056601,\n",
       "        14.99838525,  15.7210248 ,  15.79547716])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/polynomial-learning-notebook.csv')\n",
    "df = df.sort_values('x')\n",
    "\n",
    "x_pln_df = df['x'].values\n",
    "y_pln_df = df['y'].values\n",
    "X_pln_df  = df.drop(columns='y').values\n",
    "df.head()\n",
    "df['x'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.65008354e+01,  2.72277569e+02, -4.49280735e+03],\n",
       "       [-1.64136064e+01,  2.69406474e+02, -4.42193183e+03],\n",
       "       [-1.51120924e+01,  2.28375336e+02, -3.45122917e+03],\n",
       "       [-1.36645111e+01,  1.86718864e+02, -2.55142200e+03],\n",
       "       [-1.33692448e+01,  1.78736706e+02, -2.38957477e+03],\n",
       "       [-1.26716584e+01,  1.60570926e+02, -2.03469991e+03],\n",
       "       [-1.21431463e+01,  1.47456003e+02, -1.79057983e+03],\n",
       "       [-1.13764411e+01,  1.29423412e+02, -1.47237781e+03],\n",
       "       [-1.12397378e+01,  1.26331707e+02, -1.41993527e+03],\n",
       "       [-1.09769047e+01,  1.20492438e+02, -1.32263401e+03],\n",
       "       [-1.06714900e+01,  1.13880700e+02, -1.21527675e+03],\n",
       "       [-1.00934859e+01,  1.01878458e+02, -1.02830879e+03],\n",
       "       [-9.97010186e+00,  9.94029312e+01, -9.91057350e+02],\n",
       "       [-9.70579162e+00,  9.42023910e+01, -9.14308777e+02],\n",
       "       [-9.64050596e+00,  9.29393552e+01, -8.95982408e+02],\n",
       "       [-9.14900462e+00,  8.37042855e+01, -7.65810895e+02],\n",
       "       [-8.40412205e+00,  7.06292675e+01, -5.93576984e+02],\n",
       "       [-7.79029954e+00,  6.06887670e+01, -4.72783673e+02],\n",
       "       [-7.35719393e+00,  5.41283025e+01, -3.98232418e+02],\n",
       "       [-6.73979508e+00,  4.54248377e+01, -3.06154098e+02],\n",
       "       [-6.55749187e+00,  4.30006997e+01, -2.81976739e+02],\n",
       "       [-6.49931373e+00,  4.22410790e+01, -2.74538025e+02],\n",
       "       [-5.79281121e+00,  3.35566617e+01, -1.94387406e+02],\n",
       "       [-5.78036102e+00,  3.34125735e+01, -1.93136737e+02],\n",
       "       [-5.30599573e+00,  2.81535907e+01, -1.49382832e+02],\n",
       "       [-5.12613070e+00,  2.62772159e+01, -1.34700443e+02],\n",
       "       [-5.03312842e+00,  2.53323817e+01, -1.27501130e+02],\n",
       "       [-4.11149956e+00,  1.69044286e+01, -6.95025508e+01],\n",
       "       [-3.57064864e+00,  1.27495317e+01, -4.55240979e+01],\n",
       "       [-2.89545828e+00,  8.38367864e+00, -2.42745917e+01],\n",
       "       [-2.68114304e+00,  7.18852801e+00, -1.92734719e+01],\n",
       "       [-2.19684664e+00,  4.82613518e+00, -1.06022789e+01],\n",
       "       [-1.97795051e+00,  3.91228821e+00, -7.73831244e+00],\n",
       "       [-1.14996548e+00,  1.32242061e+00, -1.52073805e+00],\n",
       "       [-6.94487197e-01,  4.82312466e-01, -3.34959833e-01],\n",
       "       [-6.46624632e-01,  4.18123414e-01, -2.70368899e-01],\n",
       "       [ 2.24854073e-02,  5.05593541e-04,  1.13684767e-05],\n",
       "       [ 3.98363031e-02,  1.58693104e-03,  6.32174660e-05],\n",
       "       [ 3.25211169e-01,  1.05762305e-01,  3.43950828e-02],\n",
       "       [ 8.45608089e-01,  7.15053040e-01,  6.04654635e-01],\n",
       "       [ 1.16596893e+00,  1.35948355e+00,  1.58511558e+00],\n",
       "       [ 1.81603921e+00,  3.29799841e+00,  5.98929441e+00],\n",
       "       [ 2.17885095e+00,  4.74739145e+00,  1.03438584e+01],\n",
       "       [ 2.27947194e+00,  5.19599230e+00,  1.18441186e+01],\n",
       "       [ 3.44749926e+00,  1.18852511e+01,  4.09743945e+01],\n",
       "       [ 3.59561724e+00,  1.29284633e+01,  4.64858056e+01],\n",
       "       [ 4.03715026e+00,  1.62985822e+01,  6.57998256e+01],\n",
       "       [ 4.06472586e+00,  1.65219963e+01,  6.71573856e+01],\n",
       "       [ 4.21467032e+00,  1.77634459e+01,  7.48670684e+01],\n",
       "       [ 4.40855180e+00,  1.94353289e+01,  8.56816543e+01],\n",
       "       [ 5.08453490e+00,  2.58524952e+01,  1.31447914e+02],\n",
       "       [ 5.22960577e+00,  2.73487765e+01,  1.43023319e+02],\n",
       "       [ 6.35920800e+00,  4.04395264e+01,  2.57163360e+02],\n",
       "       [ 6.88382742e+00,  4.73870800e+01,  3.26204481e+02],\n",
       "       [ 6.94724496e+00,  4.82642125e+01,  3.35303307e+02],\n",
       "       [ 7.30192332e+00,  5.33180842e+01,  3.89324563e+02],\n",
       "       [ 8.04946477e+00,  6.47938831e+01,  5.21556080e+02],\n",
       "       [ 8.09253617e+00,  6.54891416e+01,  5.29973247e+02],\n",
       "       [ 8.24863934e+00,  6.80400510e+01,  5.61237841e+02],\n",
       "       [ 8.69389025e+00,  7.55837277e+01,  6.57116633e+02],\n",
       "       [ 9.24259757e+00,  8.54256098e+01,  7.89554534e+02],\n",
       "       [ 9.47437788e+00,  8.97638362e+01,  8.50456505e+02],\n",
       "       [ 1.01368313e+01,  1.02755349e+02,  1.04161365e+03],\n",
       "       [ 1.02889967e+01,  1.05863453e+02,  1.08922871e+03],\n",
       "       [ 1.12942704e+01,  1.27560543e+02,  1.44070326e+03],\n",
       "       [ 1.16864463e+01,  1.36573028e+02,  1.59605336e+03],\n",
       "       [ 1.20089794e+01,  1.44215585e+02,  1.73188199e+03],\n",
       "       [ 1.21417920e+01,  1.47423113e+02,  1.78998077e+03],\n",
       "       [ 1.26190148e+01,  1.59239535e+02,  2.00944605e+03],\n",
       "       [ 1.26867675e+01,  1.60954070e+02,  2.04198687e+03],\n",
       "       [ 1.27660274e+01,  1.62971455e+02,  2.08049805e+03],\n",
       "       [ 1.42705660e+01,  2.03649054e+02,  2.90618727e+03],\n",
       "       [ 1.49983852e+01,  2.24951560e+02,  3.37391016e+03],\n",
       "       [ 1.57210248e+01,  2.47150621e+02,  3.88546104e+03],\n",
       "       [ 1.57954772e+01,  2.49497099e+02,  3.94092572e+03]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pln_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use the LinearRegression from scikitlearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-11.70543425, -14.65488014,   0.30130431,   4.90652642,\n",
       "         8.19522622,  14.44707991,   9.80487187,  15.8513732 ,\n",
       "        13.05492693,  10.77245924,  11.9359571 ,  16.54479586,\n",
       "        12.42213512,  18.64130179,  20.10723881,  12.96427067,\n",
       "        15.28065253,  16.35527266,  14.84535978,  19.18572417,\n",
       "        16.93906501,  12.81669434,  11.29745667,  13.04352891,\n",
       "        15.9569733 ,  10.53489919,  17.86974077,  14.20188056,\n",
       "         9.8106083 ,  12.3856922 ,   7.63318392,   2.23569203,\n",
       "         4.28388671,  -1.82791439,  -2.0720385 ,   3.44035275,\n",
       "        -0.53009043,   1.0313154 ,  -4.78222398,  -7.18151729,\n",
       "        -1.11247524,  -6.60049052,  -9.34491575,  -4.16511022,\n",
       "        -5.32343996,  -7.05126147, -10.89445756, -11.24814292,\n",
       "        -8.91046013, -11.370442  , -13.47246494, -12.41719553,\n",
       "       -11.21958558, -14.2216333 , -16.93324604, -18.86187599,\n",
       "       -21.14281405, -19.03457486, -19.27634615, -16.85059034,\n",
       "       -16.43555218, -15.06056954, -13.23873465, -11.27191513,\n",
       "        -8.50221096,  -9.66290174, -11.80793774, -13.07924477,\n",
       "        -4.06676333,  -5.64160335,  -1.55220815,   1.33094247,\n",
       "         8.39195858,   8.68966711,  15.5974777 ])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pln_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_pln_df, y_pln_df)\n",
    "coefficients = lr.coef_\n",
    "intercept = lr.intercept_\n",
    "betas = np.concatenate((np.array([intercept]), coefficients))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the solution as we did before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 7.293313137336586\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = multiple_linear_regression(X_pln_df, betas)\n",
    "plt.plot(x_pln_df, y_pln_df, 'b.')\n",
    "plt.plot(x_pln_df, y_pred, 'r-')\n",
    "plt.plot([0, 0], [-21, 21], 'g-', [-16, 16], [0, 0], 'g-', linewidth=0.4)\n",
    "\n",
    "print(\"Mean Squared Error (MSE): {}\".format(linear_regression_mse(y_pln_df, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the same for the diabetes example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6   medv  \n",
       "0 -0.002592  0.019908 -0.017646  151.0  \n",
       "1 -0.039493 -0.068330 -0.092204   75.0  \n",
       "2 -0.002592  0.002864 -0.025930  141.0  \n",
       "3  0.034309  0.022692 -0.009362  206.0  \n",
       "4 -0.002592 -0.031991 -0.046641  135.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "data = load_diabetes()\n",
    "\n",
    "X_db = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "y_db = pd.Series(data['target'], name='medv')\n",
    "\n",
    "pd.concat((X_db, y_db), axis=1).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      151.0\n",
       "1       75.0\n",
       "2      141.0\n",
       "3      206.0\n",
       "4      135.0\n",
       "       ...  \n",
       "437    178.0\n",
       "438    104.0\n",
       "439    132.0\n",
       "440    220.0\n",
       "441     57.0\n",
       "Name: medv, Length: 442, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's experiment with the first linear regression implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature coefficients: \n",
      "age    -10.012198\n",
      "sex   -239.819089\n",
      "bmi    519.839787\n",
      "bp     324.390428\n",
      "s1    -792.184162\n",
      "s2     476.745838\n",
      "s3     101.044570\n",
      "s4     177.064176\n",
      "s5     751.279321\n",
      "s6      67.625386\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Intercept: 152.1334841628965\n",
      "\n",
      "\n",
      "\n",
      "Targets for the first 5 rows: \n",
      "\n",
      " [151.  75. 141. 206. 135.]\n",
      "\n",
      "Predictions for the first 5 rows: \n",
      "\n",
      " [206.11706979  68.07234761 176.88406035 166.91796559 128.45984241]\n",
      "Mean Squared Error (MSE): 2859.6903987680657\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_db, y_db)\n",
    "coefficients = lr.coef_\n",
    "intercept = lr.intercept_\n",
    "\n",
    "print('Feature coefficients: ')\n",
    "print(pd.Series(coefficients, X_db.columns))\n",
    "print('\\n')\n",
    "\n",
    "print('Intercept: {}'.format(intercept))\n",
    "print('\\n')\n",
    "\n",
    "print('\\nTargets for the first 5 rows: \\n\\n', y_db.head(5).values)\n",
    "print('\\nPredictions for the first 5 rows: \\n\\n', lr.predict(X_db.head(5)))\n",
    "print(\"Mean Squared Error (MSE): {}\".format(linear_regression_mse(y_db.values, lr.predict(X_db))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: normalization\n",
    "\n",
    "In our example, notice that this dataset is already normalized (run cell below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.420000e+02</td>\n",
       "      <td>4.420000e+02</td>\n",
       "      <td>4.420000e+02</td>\n",
       "      <td>4.420000e+02</td>\n",
       "      <td>4.420000e+02</td>\n",
       "      <td>4.420000e+02</td>\n",
       "      <td>4.420000e+02</td>\n",
       "      <td>4.420000e+02</td>\n",
       "      <td>4.420000e+02</td>\n",
       "      <td>4.420000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-3.639623e-16</td>\n",
       "      <td>1.309912e-16</td>\n",
       "      <td>-8.013951e-16</td>\n",
       "      <td>1.289818e-16</td>\n",
       "      <td>-9.042540e-17</td>\n",
       "      <td>1.301121e-16</td>\n",
       "      <td>-4.563971e-16</td>\n",
       "      <td>3.863174e-16</td>\n",
       "      <td>-3.848103e-16</td>\n",
       "      <td>-3.398488e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "      <td>4.761905e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.072256e-01</td>\n",
       "      <td>-4.464164e-02</td>\n",
       "      <td>-9.027530e-02</td>\n",
       "      <td>-1.123996e-01</td>\n",
       "      <td>-1.267807e-01</td>\n",
       "      <td>-1.156131e-01</td>\n",
       "      <td>-1.023071e-01</td>\n",
       "      <td>-7.639450e-02</td>\n",
       "      <td>-1.260974e-01</td>\n",
       "      <td>-1.377672e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.729927e-02</td>\n",
       "      <td>-4.464164e-02</td>\n",
       "      <td>-3.422907e-02</td>\n",
       "      <td>-3.665645e-02</td>\n",
       "      <td>-3.424784e-02</td>\n",
       "      <td>-3.035840e-02</td>\n",
       "      <td>-3.511716e-02</td>\n",
       "      <td>-3.949338e-02</td>\n",
       "      <td>-3.324879e-02</td>\n",
       "      <td>-3.317903e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.383060e-03</td>\n",
       "      <td>-4.464164e-02</td>\n",
       "      <td>-7.283766e-03</td>\n",
       "      <td>-5.670611e-03</td>\n",
       "      <td>-4.320866e-03</td>\n",
       "      <td>-3.819065e-03</td>\n",
       "      <td>-6.584468e-03</td>\n",
       "      <td>-2.592262e-03</td>\n",
       "      <td>-1.947634e-03</td>\n",
       "      <td>-1.077698e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.807591e-02</td>\n",
       "      <td>5.068012e-02</td>\n",
       "      <td>3.124802e-02</td>\n",
       "      <td>3.564384e-02</td>\n",
       "      <td>2.835801e-02</td>\n",
       "      <td>2.984439e-02</td>\n",
       "      <td>2.931150e-02</td>\n",
       "      <td>3.430886e-02</td>\n",
       "      <td>3.243323e-02</td>\n",
       "      <td>2.791705e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.107267e-01</td>\n",
       "      <td>5.068012e-02</td>\n",
       "      <td>1.705552e-01</td>\n",
       "      <td>1.320442e-01</td>\n",
       "      <td>1.539137e-01</td>\n",
       "      <td>1.987880e-01</td>\n",
       "      <td>1.811791e-01</td>\n",
       "      <td>1.852344e-01</td>\n",
       "      <td>1.335990e-01</td>\n",
       "      <td>1.356118e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age           sex           bmi            bp            s1  \\\n",
       "count  4.420000e+02  4.420000e+02  4.420000e+02  4.420000e+02  4.420000e+02   \n",
       "mean  -3.639623e-16  1.309912e-16 -8.013951e-16  1.289818e-16 -9.042540e-17   \n",
       "std    4.761905e-02  4.761905e-02  4.761905e-02  4.761905e-02  4.761905e-02   \n",
       "min   -1.072256e-01 -4.464164e-02 -9.027530e-02 -1.123996e-01 -1.267807e-01   \n",
       "25%   -3.729927e-02 -4.464164e-02 -3.422907e-02 -3.665645e-02 -3.424784e-02   \n",
       "50%    5.383060e-03 -4.464164e-02 -7.283766e-03 -5.670611e-03 -4.320866e-03   \n",
       "75%    3.807591e-02  5.068012e-02  3.124802e-02  3.564384e-02  2.835801e-02   \n",
       "max    1.107267e-01  5.068012e-02  1.705552e-01  1.320442e-01  1.539137e-01   \n",
       "\n",
       "                 s2            s3            s4            s5            s6  \n",
       "count  4.420000e+02  4.420000e+02  4.420000e+02  4.420000e+02  4.420000e+02  \n",
       "mean   1.301121e-16 -4.563971e-16  3.863174e-16 -3.848103e-16 -3.398488e-16  \n",
       "std    4.761905e-02  4.761905e-02  4.761905e-02  4.761905e-02  4.761905e-02  \n",
       "min   -1.156131e-01 -1.023071e-01 -7.639450e-02 -1.260974e-01 -1.377672e-01  \n",
       "25%   -3.035840e-02 -3.511716e-02 -3.949338e-02 -3.324879e-02 -3.317903e-02  \n",
       "50%   -3.819065e-03 -6.584468e-03 -2.592262e-03 -1.947634e-03 -1.077698e-03  \n",
       "75%    2.984439e-02  2.931150e-02  3.430886e-02  3.243323e-02  2.791705e-02  \n",
       "max    1.987880e-01  1.811791e-01  1.852344e-01  1.335990e-01  1.356118e-01  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_db.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not always the case, so you should always check if your dataset is normalized, and, if not, you should always normalize your dataset into a unified scale (e.g. range [0; 1]). The reasons why:\n",
    "\n",
    "1. Depending on what optimization algorithm you use, if feature $f_1$ has a domain of [-4.1; 3] and feature $f_2$ has a domain of [-1.1; 100000], the impact in the gradient can lead to problems in the convergence to the global minima (i.e. you probably won't get accurate results for your predictions). There are optimization algorithms that can avoid this issue but still suffer from the issue (2).\n",
    "2. If two features are using different ranges, it will be hard to compare features in terms of feature importance. If a feature ($f_1$) has a domain of [-0.1; 0.1] and another ($f_2$) has domain of [0; 1000], it doesn't make sense to look at the influence in the prediction through the same lens as the ones we use in the introduction to simple linear regression (i.e. an increase of 1 unit in $x$ increases $\\beta_1$ units in $\\hat{y}$). Due to the fact that feature $f_1$ never goes to -1 or +1, that interpretation wouldn't make sense and, as such, we would have two options:\n",
    "    1. normalize the resulting coefficients accordingly to the scale;\n",
    "    2. or normalize the inputs into the same scale.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary: Linear Regression Pros & Cons\n",
    "\n",
    "**PROS**\n",
    "* Really easy to understand\n",
    "* Fast optimization\n",
    "* Easy to extend the model: you haven't seen how this is true but there is a thing called _Generalized Linear Model (GLM)_. Once you get a good grip on linear regression, you should visit the [scikit learn page on GLMs](http://scikit-learn.org/stable/modules/linear_model.html).\n",
    "\n",
    "**CONS**\n",
    "* Sensible to outliers, even though there are extensions that are able to deal (partially) with this issue.\n",
    "* Assumes that there is no multicollinearity.\n",
    "* Feature scaling is required.\n",
    "* Monotonicity assumption: for the model, the relation between each feature and the output. \n",
    "* Categorical encoding: this might get tricky when the number of uniques is big and part of those uniques have few occurrences.\n",
    "\n",
    "\n",
    "#### Notes\n",
    "\n",
    "At this point, if you already knew linear regression in detail before the academy, you might be wondering: <em>\"Where is the error component in the linear regression formula?\"</em>. The reason is quite simple: since we wanted you to approach this subject from a more practical standpoint than theoretical.\n",
    "\n",
    "Also, we didn't include all assumptions made by the linear regression model. For a hands-on approach to the assumptions, check this [blog post by Selva Prabhakaran](http://r-statistics.co/Assumptions-of-Linear-Regression.html).\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've already covered:\n",
    "\n",
    "* how to implement a model for a simple linear regression\n",
    "* how to implement a model for a multiple linear regression\n",
    "* one simple error function we can use\n",
    "* the closed form solution for the linear regression problem \n",
    "* the scikitlearn model for the LinearRegression\n",
    "\n",
    "You are probably just trying to take it all in as fast as you can. \n",
    "\n",
    "![too-much-info](assets/too-much-information.gif)\n",
    "\n",
    "But do not despair, we're almost at the end of the notebook. The last topic we will introduce is the gradient descent methods. We will only do a slight introduction, since you will learn more about it in other units:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='grad_desc'> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 -  Gradient Descent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent is a well known and studied method for iterative optimization of both linear and non-linear models. You can use it to estimate the parameters for linear regression, neural networks, probabilistic graphical models, k-means and many more!\n",
    "\n",
    "The essential component of the gradient descent algorithm is the **update rule**. Let $f$ be a differentiable function and $\\omega$ one of parameters of $f$. Then, in order to minimize the value outputted by $f(\\omega)$, we will use, iteratively, the following\n",
    "\n",
    "$$\\omega = \\omega - \\alpha \\frac{\\partial f(\\omega)}{\\partial \\omega}$$\n",
    "\n",
    "where $\\frac{\\partial f}{\\partial \\omega}$ is the [partial derivative of $f$ with respect to $\\omega$](https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/partial-derivative-and-gradient-articles/a/introduction-to-partial-derivatives) and $\\alpha$ is the learning rate. So, what gradient descent does is using the partial derivative as a _heuristic_ to the direction where the minimum is located and the multiplication between the learning rate and the partial derivative gives you a _velocity_ factor that you will use in order to update $\\omega$. There are two ways to increase the _velocity_ : \n",
    "(1) higher learning rates, (2) big gradients. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the derivatives from above,\n",
    "\n",
    "$$\\frac{d J}{d \\beta_0} = -\\frac{1}{N} \\sum_{i=1}^N [2 (y_i - \\hat{y_i})] $$\n",
    "\n",
    "$$ \\frac{d J}{d \\beta_k} = -\\frac{1}{N}\\sum_{i=1}^N [2( y_i - \\hat{y_i})x_{k_i}] $$ \n",
    "\n",
    "\n",
    "They will come in handy now, let's implement them as lambda functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_derivative_b0 = lambda y, y_hat: -(2*(y - y_hat)).mean()\n",
    "mse_derivative_bk = lambda y, y_hat, x_k: -(2*(y - y_hat)*x_k).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use these derivatives and implement the update rule. We have:\n",
    "\n",
    "1. _For epoch in 1...epochs:_\n",
    "    1. $\\beta_0 = \\beta_0 - \\alpha \\frac{\\partial J}{\\partial \\beta_0} = \\beta_0 - \\alpha (-\\frac{1}{N} \\sum_{n=1}^N 2 (y_n - \\hat{y}_n))$ \n",
    "    2. _For i in 1..K:_\n",
    "        1. $\\beta_i = \\beta_i - \\alpha \\frac{\\partial J}{\\partial \\beta_i} = \\beta_i - \\alpha (-\\frac{1}{N} \\sum_{n=1}^N 2 (y_n - \\hat{y}_n) x_n)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_multiple_linear_regression(x, y, betas, learning_rate, epochs, clip=False):\n",
    "    \n",
    "    betas_ = betas.copy().reshape(-1, 1)\n",
    "    for epoch in range(epochs): \n",
    "        y_hat = multiple_linear_regression(x, betas_.flatten())\n",
    "        dJ_dbetas = np.zeros((x.shape[1] + 1, 1))\n",
    "        dJ_dbetas[0] = mse_derivative_b0(y, y_hat)\n",
    "        \n",
    "        for col in range(x.shape[1]): \n",
    "            dJ_dbetas[col+1] = mse_derivative_bk(y, y_hat, x[:, col])\n",
    "        \n",
    "        # We add this to avoid increasingly bigger derivatives\n",
    "        if clip == True:\n",
    "            dJ_dbetas = np.clip(dJ_dbetas, -1, 1)\n",
    "            \n",
    "        betas_ = betas_ - learning_rate * dJ_dbetas\n",
    "\n",
    "    return betas_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 - Gradient Descent for simple linear regression\n",
    "\n",
    "Let's try to run the gradient descent for our linear example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "df = pd.read_csv('data/linear-learning-notebook.csv')\n",
    "df = df.sort_values('x')\n",
    "x_lin_df = df['x'].values\n",
    "y_lin_df = df['y'].values\n",
    "\n",
    "betas = gradient_descent_multiple_linear_regression(\n",
    "    x_lin_df.reshape(-1, 1), \n",
    "    y_lin_df, \n",
    "    np.random.rand(2), \n",
    "    0.01, \n",
    "    100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.735460228566117\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = linear_regression(x_lin_df, betas[0], betas[1])\n",
    "plt.plot(x_lin_df, y_lin_df, 'b.')\n",
    "plt.plot(x_lin_df, y_pred, 'r-')\n",
    "plt.plot([0, 0], [-8, 8], 'g-', [-8, 8], [0, 0], 'g-', linewidth=0.4)\n",
    "\n",
    "print(\"Mean Squared Error (MSE): {}\".format(linear_regression_mse(y_lin_df, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 - Gradient Descent for multiple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "df = pd.read_csv('data/polynomial-learning-notebook.csv')\n",
    "df = df.sort_values('x')\n",
    "x_pln_df = df['x'].values\n",
    "X_pln_df = df.drop(columns='y').values\n",
    "y_pln_df = df['y'].values\n",
    "\n",
    "betas = gradient_descent_multiple_linear_regression(\n",
    "    X_pln_df, \n",
    "    y_pln_df, \n",
    "    np.random.rand(4), \n",
    "    0.001, \n",
    "    5000, \n",
    "    clip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 14.943329615243453\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = multiple_linear_regression(X_pln_df, betas.flatten())\n",
    "plt.plot(x_pln_df, y_pln_df, 'b.')\n",
    "plt.plot(x_pln_df, y_pred, 'r-')\n",
    "plt.plot([0, 0], [-20, 20], 'g-', [-20, 20], [0, 0], 'g-', linewidth=0.4)\n",
    "\n",
    "print(\"Mean Squared Error (MSE): {}\".format(linear_regression_mse(y_pln_df, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 - Gradient Descent for multiple linear regression: diabetes example\n",
    "\n",
    "Finally let's run Gradient Descent for the previous complex example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "data = load_diabetes()\n",
    "\n",
    "X_db = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "y_db = pd.Series(data['target'], name='medv')\n",
    "\n",
    "pd.concat((X_db, y_db), axis=1).head(5)\n",
    "\n",
    "betas = gradient_descent_multiple_linear_regression(\n",
    "    X_db.values, \n",
    "    y_db.values, \n",
    "    np.random.rand(X_db.shape[1]+1), \n",
    "    0.1, \n",
    "    5000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the coefficients and the intercept and compare them and the error with the previous methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature coefficients: \n",
      "age      6.477416\n",
      "sex   -197.604938\n",
      "bmi    487.727762\n",
      "bp     302.664704\n",
      "s1     -41.672774\n",
      "s2    -106.719363\n",
      "s3    -206.725952\n",
      "s4     128.485965\n",
      "s5     407.329775\n",
      "s6     117.104678\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Intercept: 152.1334841628963\n",
      "\n",
      "\n",
      "\n",
      "Targets for the first 5 rows: \n",
      "\n",
      " [151.  75. 141. 206. 135.]\n",
      "\n",
      "Predictions for the first 5 rows: \n",
      "\n",
      " [199.31724465  71.17863611 172.67029998 160.45809677 127.52635757]\n",
      "Mean Squared Error (MSE): 2899.0843162762653\n"
     ]
    }
   ],
   "source": [
    "betas = betas.flatten()\n",
    "y_pred = multiple_linear_regression(X_db.values, betas)\n",
    "\n",
    "print('Feature coefficients: ')\n",
    "print(pd.Series(betas[1:], X_db.columns))\n",
    "print('\\n')\n",
    "\n",
    "print('Intercept: {}'.format(betas[0]))\n",
    "print('\\n')\n",
    "\n",
    "print('\\nTargets for the first 5 rows: \\n\\n', y_db.head(5).values)\n",
    "print('\\nPredictions for the first 5 rows: \\n\\n', y_pred[:5])\n",
    "print(\"Mean Squared Error (MSE): {}\".format(linear_regression_mse(y_db.values, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that is it! Congratulations, you've just learned your first predictive model! You've learned how to perform linear regressions with simple and multiple input models, and are now able to solve them through closed form solutions and even through a simple iterative methods. Now go on and apply what you've learned in the exercises. In the next units you will see other types of tasks and models and all sorts of other advanced topics.\n",
    "\n",
    "![im-ready](assets/im-ready.gif)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
